{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc5d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from multiprocessing import Lock, Manager\n",
    "from multiprocessing.pool import Pool\n",
    "from multiprocessing import cpu_count\n",
    "import time\n",
    "\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38083a",
   "metadata": {},
   "source": [
    "### first step: generate data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f606aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d  = 20\n",
    "\n",
    "nrep = 10\n",
    "beta = np.random.randn(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a18da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomSamplesOnNSphere(N , numberOfSamples, R = 1):\n",
    "    X = np.random.default_rng().normal(size=(numberOfSamples , N))\n",
    "    return R / np.sqrt(np.sum(X**2, 1, keepdims=True)) * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ebd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_y(x,beta):\n",
    "    # x is numpy array with (n,d) ,beta is (d) and fixed\n",
    "    N = x.shape[0]\n",
    "    d = x.shape[1]\n",
    "    e = np.random.normal(0, 0.5,size = N)\n",
    "    vector = np.einsum('i,ij -> j', beta,x.T)\n",
    "    fx = np.sqrt(4/10)*vector + np.sqrt(4/10)*(np.sqrt(1/2)*(vector**2-1))+ \\\n",
    "        np.sqrt(2/10)*(np.sqrt(1/10)*(vector**4 - 6*vector**2 + 3))\n",
    "    y = fx + e\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710a68e",
   "metadata": {},
   "source": [
    "### second step: model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb8533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data_tensor, data_target):\n",
    "        self.data_target = data_target\n",
    "        self.data_tensor = data_tensor \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_target.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.data_target[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329f29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(nn.Module):\n",
    "    def __init__(self, input_dim, Nd = 100, drop_rate = 0.0, ):\n",
    "        super(Model_1,self).__init__()\n",
    "        self.model_name = '2 layer linear nn'\n",
    "        \n",
    "        self.hidden_dim = Nd//input_dim\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_dim,self.hidden_dim)\n",
    "        self.act = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(self.hidden_dim,1)\n",
    "\n",
    "        # torch.set_num_threads(1)\n",
    "\n",
    "#         for p in self.linear1.parameters():\n",
    "#             nn.init.normal_(p,mean=0.0,std = 0.001)\n",
    "#         for p in self.linear2.parameters():\n",
    "#             nn.init.normal_(p,mean=0.0,std = 0.001)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x_signal = self.linear1(x)\n",
    "        x_signal = self.act(x_signal)\n",
    "        out = self.linear2(x_signal)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aff79e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 20, N: 20,trainingerror: 0.000405, testerror: 0.091871\n",
      "Nd: 20, N: 24,trainingerror: 0.100220, testerror: 0.044182\n",
      "Nd: 20, N: 27,trainingerror: 0.224590, testerror: 0.054484\n",
      "Nd: 20, N: 32,trainingerror: 0.014981, testerror: 0.271509\n",
      "Nd: 20, N: 37,trainingerror: 0.006470, testerror: 0.078351\n",
      "Nd: 20, N: 43,trainingerror: 0.011678, testerror: 0.190608\n",
      "Nd: 20, N: 50,trainingerror: 0.017343, testerror: 0.064028\n",
      "Nd: 20, N: 58,trainingerror: 0.013329, testerror: 0.095668\n",
      "Nd: 20, N: 67,trainingerror: 0.074811, testerror: 0.057057\n",
      "Nd: 20, N: 78,trainingerror: 0.029137, testerror: 0.026431\n",
      "Nd: 20, N: 90,trainingerror: 0.026128, testerror: 0.043276\n",
      "Nd: 20, N: 104,trainingerror: 0.018467, testerror: 0.022341\n",
      "Nd: 20, N: 121,trainingerror: 0.024816, testerror: 0.054555\n",
      "Nd: 20, N: 141,trainingerror: 0.019663, testerror: 0.041708\n",
      "Nd: 20, N: 163,trainingerror: 0.039018, testerror: 0.072188\n",
      "Nd: 20, N: 190,trainingerror: 0.053318, testerror: 0.074687\n",
      "Nd: 20, N: 220,trainingerror: 0.084250, testerror: 0.081384\n",
      "Nd: 20, N: 256,trainingerror: 0.096689, testerror: 0.076836\n",
      "Nd: 20, N: 297,trainingerror: 0.042539, testerror: 0.059829\n",
      "Nd: 20, N: 345,trainingerror: 0.041038, testerror: 0.067901\n",
      "Nd: 24, N: 20,trainingerror: 0.016753, testerror: 0.074103\n",
      "Nd: 24, N: 24,trainingerror: 0.014374, testerror: 0.170020\n",
      "Nd: 24, N: 27,trainingerror: 0.034261, testerror: 0.057973\n",
      "Nd: 24, N: 32,trainingerror: 0.015653, testerror: 0.006569\n",
      "Nd: 24, N: 37,trainingerror: 0.022788, testerror: 0.111675\n",
      "Nd: 24, N: 43,trainingerror: 0.011905, testerror: 0.230965\n",
      "Nd: 24, N: 50,trainingerror: 0.245969, testerror: 0.065895\n",
      "Nd: 24, N: 58,trainingerror: 0.019342, testerror: 0.108495\n",
      "Nd: 24, N: 67,trainingerror: 0.057386, testerror: 0.096739\n",
      "Nd: 24, N: 78,trainingerror: 0.048697, testerror: 0.125808\n",
      "Nd: 24, N: 90,trainingerror: 0.045232, testerror: 0.492602\n",
      "Nd: 24, N: 104,trainingerror: 0.019807, testerror: 0.048672\n",
      "Nd: 24, N: 121,trainingerror: 0.057057, testerror: 0.046292\n",
      "Nd: 24, N: 141,trainingerror: 0.042520, testerror: 0.131917\n",
      "Nd: 24, N: 163,trainingerror: 0.029657, testerror: 0.081890\n",
      "Nd: 24, N: 190,trainingerror: 0.068050, testerror: 0.055260\n",
      "Nd: 24, N: 220,trainingerror: 0.043457, testerror: 0.030187\n",
      "Nd: 24, N: 256,trainingerror: 0.042016, testerror: 0.028643\n",
      "Nd: 24, N: 297,trainingerror: 0.037264, testerror: 0.045776\n",
      "Nd: 24, N: 345,trainingerror: 0.066891, testerror: 0.040582\n",
      "Nd: 27, N: 20,trainingerror: 0.001532, testerror: 0.048792\n",
      "Nd: 27, N: 24,trainingerror: 0.103716, testerror: 0.038776\n",
      "Nd: 27, N: 27,trainingerror: 0.007528, testerror: 0.533213\n",
      "Nd: 27, N: 32,trainingerror: 0.010912, testerror: 0.147003\n",
      "Nd: 27, N: 37,trainingerror: 0.005720, testerror: 0.081056\n",
      "Nd: 27, N: 43,trainingerror: 0.091106, testerror: 0.012827\n",
      "Nd: 27, N: 50,trainingerror: 0.078513, testerror: 0.133711\n",
      "Nd: 27, N: 58,trainingerror: 0.059159, testerror: 0.072760\n",
      "Nd: 27, N: 67,trainingerror: 0.018599, testerror: 0.049892\n",
      "Nd: 27, N: 78,trainingerror: 0.093140, testerror: 0.104071\n",
      "Nd: 27, N: 90,trainingerror: 0.026101, testerror: 0.475421\n",
      "Nd: 27, N: 104,trainingerror: 0.028867, testerror: 0.141139\n",
      "Nd: 27, N: 121,trainingerror: 0.106716, testerror: 0.256877\n",
      "Nd: 27, N: 141,trainingerror: 0.026282, testerror: 0.029300\n",
      "Nd: 27, N: 163,trainingerror: 0.039830, testerror: 0.041181\n",
      "Nd: 27, N: 190,trainingerror: 0.043321, testerror: 0.034921\n",
      "Nd: 27, N: 220,trainingerror: 0.052397, testerror: 0.028000\n",
      "Nd: 27, N: 256,trainingerror: 0.027027, testerror: 0.053029\n",
      "Nd: 27, N: 297,trainingerror: 0.041252, testerror: 0.035894\n",
      "Nd: 27, N: 345,trainingerror: 0.058731, testerror: 0.109213\n",
      "Nd: 32, N: 20,trainingerror: 0.088735, testerror: 0.228105\n",
      "Nd: 32, N: 24,trainingerror: 0.031033, testerror: 0.330596\n",
      "Nd: 32, N: 27,trainingerror: 0.185869, testerror: 0.111906\n",
      "Nd: 32, N: 32,trainingerror: 0.004990, testerror: 0.133053\n",
      "Nd: 32, N: 37,trainingerror: 0.008112, testerror: 0.054674\n",
      "Nd: 32, N: 43,trainingerror: 0.164010, testerror: 0.560688\n",
      "Nd: 32, N: 50,trainingerror: 0.018967, testerror: 0.251335\n",
      "Nd: 32, N: 58,trainingerror: 0.036224, testerror: 0.081326\n",
      "Nd: 32, N: 67,trainingerror: 0.025155, testerror: 0.078243\n",
      "Nd: 32, N: 78,trainingerror: 0.064758, testerror: 0.039150\n",
      "Nd: 32, N: 90,trainingerror: 0.045558, testerror: 0.109942\n",
      "Nd: 32, N: 104,trainingerror: 0.071635, testerror: 0.055533\n",
      "Nd: 32, N: 121,trainingerror: 0.022919, testerror: 0.040315\n",
      "Nd: 32, N: 141,trainingerror: 0.099786, testerror: 0.044414\n",
      "Nd: 32, N: 163,trainingerror: 0.027201, testerror: 0.041053\n",
      "Nd: 32, N: 190,trainingerror: 0.049574, testerror: 0.041725\n",
      "Nd: 32, N: 220,trainingerror: 0.039632, testerror: 0.083908\n",
      "Nd: 32, N: 256,trainingerror: 0.040424, testerror: 0.053043\n",
      "Nd: 32, N: 297,trainingerror: 0.070887, testerror: 0.092206\n",
      "Nd: 32, N: 345,trainingerror: 0.046539, testerror: 0.161532\n",
      "Nd: 37, N: 20,trainingerror: 0.000619, testerror: 0.029335\n",
      "Nd: 37, N: 24,trainingerror: 0.039879, testerror: 0.058788\n",
      "Nd: 37, N: 27,trainingerror: 0.104600, testerror: 0.040258\n",
      "Nd: 37, N: 32,trainingerror: 0.006161, testerror: 0.083543\n",
      "Nd: 37, N: 37,trainingerror: 0.004645, testerror: 0.146960\n",
      "Nd: 37, N: 43,trainingerror: 0.005037, testerror: 0.108840\n",
      "Nd: 37, N: 50,trainingerror: 0.075425, testerror: 0.098207\n",
      "Nd: 37, N: 58,trainingerror: 0.017080, testerror: 0.146912\n",
      "Nd: 37, N: 67,trainingerror: 0.015665, testerror: 0.117747\n",
      "Nd: 37, N: 78,trainingerror: 0.048819, testerror: 0.103184\n",
      "Nd: 37, N: 90,trainingerror: 0.049036, testerror: 0.208499\n",
      "Nd: 37, N: 104,trainingerror: 0.037203, testerror: 0.150401\n",
      "Nd: 37, N: 121,trainingerror: 0.181214, testerror: 0.130015\n",
      "Nd: 37, N: 141,trainingerror: 0.042502, testerror: 0.068812\n",
      "Nd: 37, N: 163,trainingerror: 0.037730, testerror: 0.046347\n",
      "Nd: 37, N: 190,trainingerror: 0.038102, testerror: 0.071796\n",
      "Nd: 37, N: 220,trainingerror: 0.065667, testerror: 0.060437\n",
      "Nd: 37, N: 256,trainingerror: 0.044666, testerror: 0.083196\n",
      "Nd: 37, N: 297,trainingerror: 0.038555, testerror: 0.057177\n",
      "Nd: 37, N: 345,trainingerror: 0.065460, testerror: 0.054693\n",
      "Nd: 43, N: 20,trainingerror: 0.001721, testerror: 0.062439\n",
      "Nd: 43, N: 24,trainingerror: 0.002133, testerror: 0.042653\n",
      "Nd: 43, N: 27,trainingerror: 0.013964, testerror: 0.777571\n",
      "Nd: 43, N: 32,trainingerror: 0.000005, testerror: 0.166753\n",
      "Nd: 43, N: 37,trainingerror: 0.017883, testerror: 0.228398\n",
      "Nd: 43, N: 43,trainingerror: 0.012511, testerror: 0.398723\n",
      "Nd: 43, N: 50,trainingerror: 0.005882, testerror: 0.042466\n",
      "Nd: 43, N: 58,trainingerror: 0.005996, testerror: 0.113922\n",
      "Nd: 43, N: 67,trainingerror: 0.007580, testerror: 0.181921\n",
      "Nd: 43, N: 78,trainingerror: 0.019218, testerror: 0.103052\n",
      "Nd: 43, N: 90,trainingerror: 0.021945, testerror: 0.084012\n",
      "Nd: 43, N: 104,trainingerror: 0.042011, testerror: 0.171076\n",
      "Nd: 43, N: 121,trainingerror: 0.031735, testerror: 0.332117\n",
      "Nd: 43, N: 141,trainingerror: 0.028595, testerror: 0.161981\n",
      "Nd: 43, N: 163,trainingerror: 0.020572, testerror: 0.129633\n",
      "Nd: 43, N: 190,trainingerror: 0.046167, testerror: 0.062461\n",
      "Nd: 43, N: 220,trainingerror: 0.071860, testerror: 0.042598\n",
      "Nd: 43, N: 256,trainingerror: 0.067971, testerror: 0.040912\n",
      "Nd: 43, N: 297,trainingerror: 0.035430, testerror: 0.061496\n",
      "Nd: 43, N: 345,trainingerror: 0.032810, testerror: 0.101940\n",
      "Nd: 50, N: 20,trainingerror: 0.000000, testerror: 0.009786\n",
      "Nd: 50, N: 24,trainingerror: 0.020407, testerror: 0.041515\n",
      "Nd: 50, N: 27,trainingerror: 0.008113, testerror: 0.448881\n",
      "Nd: 50, N: 32,trainingerror: 0.003604, testerror: 0.195964\n",
      "Nd: 50, N: 37,trainingerror: 0.004134, testerror: 0.135040\n",
      "Nd: 50, N: 43,trainingerror: 0.030983, testerror: 0.053640\n",
      "Nd: 50, N: 50,trainingerror: 0.001104, testerror: 0.759319\n",
      "Nd: 50, N: 58,trainingerror: 0.007048, testerror: 0.137754\n",
      "Nd: 50, N: 67,trainingerror: 0.003556, testerror: 0.042012\n",
      "Nd: 50, N: 78,trainingerror: 0.111262, testerror: 0.058113\n",
      "Nd: 50, N: 90,trainingerror: 0.014355, testerror: 0.052355\n",
      "Nd: 50, N: 104,trainingerror: 0.009952, testerror: 0.527644\n",
      "Nd: 50, N: 121,trainingerror: 0.016219, testerror: 0.085889\n",
      "Nd: 50, N: 141,trainingerror: 0.019397, testerror: 0.062342\n",
      "Nd: 50, N: 163,trainingerror: 0.032955, testerror: 0.067213\n",
      "Nd: 50, N: 190,trainingerror: 0.019967, testerror: 0.078430\n",
      "Nd: 50, N: 220,trainingerror: 0.039657, testerror: 0.046163\n",
      "Nd: 50, N: 256,trainingerror: 0.052560, testerror: 0.049560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 50, N: 297,trainingerror: 0.036145, testerror: 0.043745\n",
      "Nd: 50, N: 345,trainingerror: 0.092941, testerror: 0.037447\n",
      "Nd: 58, N: 20,trainingerror: 0.106903, testerror: 0.060653\n",
      "Nd: 58, N: 24,trainingerror: 0.003819, testerror: 0.275812\n",
      "Nd: 58, N: 27,trainingerror: 0.000008, testerror: 0.203637\n",
      "Nd: 58, N: 32,trainingerror: 0.003047, testerror: 0.100844\n",
      "Nd: 58, N: 37,trainingerror: 0.014272, testerror: 0.713995\n",
      "Nd: 58, N: 43,trainingerror: 0.035081, testerror: 0.177340\n",
      "Nd: 58, N: 50,trainingerror: 0.000653, testerror: 0.135516\n",
      "Nd: 58, N: 58,trainingerror: 0.009054, testerror: 0.077413\n",
      "Nd: 58, N: 67,trainingerror: 0.041456, testerror: 0.035466\n",
      "Nd: 58, N: 78,trainingerror: 0.014006, testerror: 0.783530\n",
      "Nd: 58, N: 90,trainingerror: 0.035512, testerror: 0.075347\n",
      "Nd: 58, N: 104,trainingerror: 0.016019, testerror: 0.044232\n",
      "Nd: 58, N: 121,trainingerror: 0.044509, testerror: 0.050335\n",
      "Nd: 58, N: 141,trainingerror: 0.023160, testerror: 0.147786\n",
      "Nd: 58, N: 163,trainingerror: 0.029900, testerror: 0.060500\n",
      "Nd: 58, N: 190,trainingerror: 0.090608, testerror: 0.116660\n",
      "Nd: 58, N: 220,trainingerror: 0.029851, testerror: 0.039893\n",
      "Nd: 58, N: 256,trainingerror: 0.044282, testerror: 0.034359\n",
      "Nd: 58, N: 297,trainingerror: 0.032205, testerror: 0.558686\n",
      "Nd: 58, N: 345,trainingerror: 0.022708, testerror: 0.034201\n",
      "Nd: 67, N: 20,trainingerror: 0.010013, testerror: 0.155601\n",
      "Nd: 67, N: 24,trainingerror: 0.000184, testerror: 0.382530\n",
      "Nd: 67, N: 27,trainingerror: 0.001165, testerror: 1.224594\n",
      "Nd: 67, N: 32,trainingerror: 0.000000, testerror: 0.104689\n",
      "Nd: 67, N: 37,trainingerror: 0.000253, testerror: 0.205983\n",
      "Nd: 67, N: 43,trainingerror: 0.018567, testerror: 0.159641\n",
      "Nd: 67, N: 50,trainingerror: 0.000359, testerror: 0.145356\n",
      "Nd: 67, N: 58,trainingerror: 0.000201, testerror: 0.105414\n",
      "Nd: 67, N: 67,trainingerror: 0.001452, testerror: 0.127682\n",
      "Nd: 67, N: 78,trainingerror: 0.003801, testerror: 0.263720\n",
      "Nd: 67, N: 90,trainingerror: 0.004710, testerror: 0.099330\n",
      "Nd: 67, N: 104,trainingerror: 0.018836, testerror: 0.417291\n",
      "Nd: 67, N: 121,trainingerror: 0.007964, testerror: 0.060250\n",
      "Nd: 67, N: 141,trainingerror: 0.039175, testerror: 0.092064\n",
      "Nd: 67, N: 163,trainingerror: 0.024365, testerror: 0.179074\n",
      "Nd: 67, N: 190,trainingerror: 0.113521, testerror: 0.029575\n",
      "Nd: 67, N: 220,trainingerror: 0.073216, testerror: 0.101454\n",
      "Nd: 67, N: 256,trainingerror: 0.025546, testerror: 0.071377\n",
      "Nd: 67, N: 297,trainingerror: 0.059397, testerror: 0.068895\n",
      "Nd: 67, N: 345,trainingerror: 0.049460, testerror: 0.143315\n",
      "Nd: 78, N: 20,trainingerror: 0.000000, testerror: 0.458744\n",
      "Nd: 78, N: 24,trainingerror: 0.000000, testerror: 1.661441\n",
      "Nd: 78, N: 27,trainingerror: 0.000000, testerror: 0.227169\n",
      "Nd: 78, N: 32,trainingerror: 0.000004, testerror: 0.235722\n",
      "Nd: 78, N: 37,trainingerror: 0.000000, testerror: 0.282654\n",
      "Nd: 78, N: 43,trainingerror: 0.002597, testerror: 0.046876\n",
      "Nd: 78, N: 50,trainingerror: 0.001838, testerror: 0.428284\n",
      "Nd: 78, N: 58,trainingerror: 0.012835, testerror: 0.028952\n",
      "Nd: 78, N: 67,trainingerror: 0.001964, testerror: 0.050601\n",
      "Nd: 78, N: 78,trainingerror: 0.006997, testerror: 0.364607\n",
      "Nd: 78, N: 90,trainingerror: 0.013006, testerror: 0.274795\n",
      "Nd: 78, N: 104,trainingerror: 0.003340, testerror: 0.056131\n",
      "Nd: 78, N: 121,trainingerror: 0.012475, testerror: 0.057143\n",
      "Nd: 78, N: 141,trainingerror: 0.020215, testerror: 0.044324\n",
      "Nd: 78, N: 163,trainingerror: 0.013845, testerror: 0.089077\n",
      "Nd: 78, N: 190,trainingerror: 0.027285, testerror: 0.115416\n",
      "Nd: 78, N: 220,trainingerror: 0.024460, testerror: 0.100122\n",
      "Nd: 78, N: 256,trainingerror: 0.021865, testerror: 0.066927\n",
      "Nd: 78, N: 297,trainingerror: 0.039331, testerror: 0.036402\n",
      "Nd: 78, N: 345,trainingerror: 0.025676, testerror: 0.070968\n",
      "Nd: 90, N: 20,trainingerror: 0.000000, testerror: 0.042183\n",
      "Nd: 90, N: 24,trainingerror: 0.000000, testerror: 0.584092\n",
      "Nd: 90, N: 27,trainingerror: 0.000000, testerror: 0.094571\n",
      "Nd: 90, N: 32,trainingerror: 0.001202, testerror: 0.148752\n",
      "Nd: 90, N: 37,trainingerror: 0.015336, testerror: 0.102989\n",
      "Nd: 90, N: 43,trainingerror: 0.003935, testerror: 0.109742\n",
      "Nd: 90, N: 50,trainingerror: 0.003018, testerror: 0.070804\n",
      "Nd: 90, N: 58,trainingerror: 0.000034, testerror: 0.020929\n",
      "Nd: 90, N: 67,trainingerror: 0.000549, testerror: 0.360161\n",
      "Nd: 90, N: 78,trainingerror: 0.007229, testerror: 0.082769\n",
      "Nd: 90, N: 90,trainingerror: 0.000818, testerror: 0.146109\n",
      "Nd: 90, N: 104,trainingerror: 0.002147, testerror: 0.112790\n",
      "Nd: 90, N: 121,trainingerror: 0.002663, testerror: 0.052041\n",
      "Nd: 90, N: 141,trainingerror: 0.005744, testerror: 0.056458\n",
      "Nd: 90, N: 163,trainingerror: 0.016458, testerror: 0.089356\n",
      "Nd: 90, N: 190,trainingerror: 0.018033, testerror: 0.050242\n",
      "Nd: 90, N: 220,trainingerror: 0.016673, testerror: 0.089412\n",
      "Nd: 90, N: 256,trainingerror: 0.019122, testerror: 0.124338\n",
      "Nd: 90, N: 297,trainingerror: 0.034159, testerror: 0.086538\n",
      "Nd: 90, N: 345,trainingerror: 0.023468, testerror: 0.046282\n",
      "Nd: 104, N: 20,trainingerror: 0.000006, testerror: 0.138855\n",
      "Nd: 104, N: 24,trainingerror: 0.002298, testerror: 0.054703\n",
      "Nd: 104, N: 27,trainingerror: 0.000000, testerror: 0.042814\n",
      "Nd: 104, N: 32,trainingerror: 0.000000, testerror: 0.695245\n",
      "Nd: 104, N: 37,trainingerror: 0.000306, testerror: 0.068361\n",
      "Nd: 104, N: 43,trainingerror: 0.000000, testerror: 0.044376\n",
      "Nd: 104, N: 50,trainingerror: 0.000003, testerror: 0.206902\n",
      "Nd: 104, N: 58,trainingerror: 0.000000, testerror: 0.080678\n",
      "Nd: 104, N: 67,trainingerror: 0.000439, testerror: 0.205570\n",
      "Nd: 104, N: 78,trainingerror: 0.001669, testerror: 0.217516\n",
      "Nd: 104, N: 90,trainingerror: 0.000246, testerror: 0.070081\n",
      "Nd: 104, N: 104,trainingerror: 0.013342, testerror: 0.201006\n",
      "Nd: 104, N: 121,trainingerror: 0.019661, testerror: 0.224593\n",
      "Nd: 104, N: 141,trainingerror: 0.002397, testerror: 0.087240\n",
      "Nd: 104, N: 163,trainingerror: 0.004471, testerror: 0.200763\n",
      "Nd: 104, N: 190,trainingerror: 0.015003, testerror: 0.359829\n",
      "Nd: 104, N: 220,trainingerror: 0.033675, testerror: 0.137511\n",
      "Nd: 104, N: 256,trainingerror: 0.012206, testerror: 0.136860\n",
      "Nd: 104, N: 297,trainingerror: 0.017039, testerror: 0.081344\n",
      "Nd: 104, N: 345,trainingerror: 0.034091, testerror: 0.107154\n",
      "Nd: 121, N: 20,trainingerror: 0.000000, testerror: 0.143370\n",
      "Nd: 121, N: 24,trainingerror: 0.000017, testerror: 0.083757\n",
      "Nd: 121, N: 27,trainingerror: 0.000037, testerror: 0.110867\n",
      "Nd: 121, N: 32,trainingerror: 0.000196, testerror: 0.099542\n",
      "Nd: 121, N: 37,trainingerror: 0.000125, testerror: 0.076364\n",
      "Nd: 121, N: 43,trainingerror: 0.000000, testerror: 0.077936\n",
      "Nd: 121, N: 50,trainingerror: 0.001489, testerror: 0.091602\n",
      "Nd: 121, N: 58,trainingerror: 0.011689, testerror: 0.073404\n",
      "Nd: 121, N: 67,trainingerror: 0.000000, testerror: 0.163438\n",
      "Nd: 121, N: 78,trainingerror: 0.000082, testerror: 0.064933\n",
      "Nd: 121, N: 90,trainingerror: 0.004953, testerror: 0.210255\n",
      "Nd: 121, N: 104,trainingerror: 0.000429, testerror: 0.043505\n",
      "Nd: 121, N: 121,trainingerror: 0.000137, testerror: 0.104906\n",
      "Nd: 121, N: 141,trainingerror: 0.000303, testerror: 0.039328\n",
      "Nd: 121, N: 163,trainingerror: 0.001280, testerror: 0.080757\n",
      "Nd: 121, N: 190,trainingerror: 0.006953, testerror: 0.178389\n",
      "Nd: 121, N: 220,trainingerror: 0.017778, testerror: 0.190333\n",
      "Nd: 121, N: 256,trainingerror: 0.010850, testerror: 0.075063\n",
      "Nd: 121, N: 297,trainingerror: 0.035306, testerror: 0.163486\n",
      "Nd: 121, N: 345,trainingerror: 0.017448, testerror: 0.067259\n",
      "Nd: 141, N: 20,trainingerror: 0.000000, testerror: 0.148631\n",
      "Nd: 141, N: 24,trainingerror: 0.000000, testerror: 0.035152\n",
      "Nd: 141, N: 27,trainingerror: 0.000000, testerror: 0.912084\n",
      "Nd: 141, N: 32,trainingerror: 0.000021, testerror: 0.081938\n",
      "Nd: 141, N: 37,trainingerror: 0.000368, testerror: 0.280364\n",
      "Nd: 141, N: 43,trainingerror: 0.000000, testerror: 0.048202\n",
      "Nd: 141, N: 50,trainingerror: 0.000000, testerror: 0.039629\n",
      "Nd: 141, N: 58,trainingerror: 0.000000, testerror: 0.061300\n",
      "Nd: 141, N: 67,trainingerror: 0.000000, testerror: 0.094361\n",
      "Nd: 141, N: 78,trainingerror: 0.000054, testerror: 0.176605\n",
      "Nd: 141, N: 90,trainingerror: 0.000000, testerror: 0.071290\n",
      "Nd: 141, N: 104,trainingerror: 0.000216, testerror: 0.242267\n",
      "Nd: 141, N: 121,trainingerror: 0.001087, testerror: 0.080047\n",
      "Nd: 141, N: 141,trainingerror: 0.000471, testerror: 0.088043\n",
      "Nd: 141, N: 163,trainingerror: 0.001444, testerror: 0.087284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 141, N: 190,trainingerror: 0.003799, testerror: 0.162492\n",
      "Nd: 141, N: 220,trainingerror: 0.004637, testerror: 0.076796\n",
      "Nd: 141, N: 256,trainingerror: 0.007021, testerror: 0.115917\n",
      "Nd: 141, N: 297,trainingerror: 0.011949, testerror: 0.097652\n",
      "Nd: 141, N: 345,trainingerror: 0.015975, testerror: 0.076312\n",
      "Nd: 163, N: 20,trainingerror: 0.000000, testerror: 0.037417\n",
      "Nd: 163, N: 24,trainingerror: 0.000000, testerror: 0.035233\n",
      "Nd: 163, N: 27,trainingerror: 0.000000, testerror: 0.068456\n",
      "Nd: 163, N: 32,trainingerror: 0.000000, testerror: 0.042432\n",
      "Nd: 163, N: 37,trainingerror: 0.000000, testerror: 0.025490\n",
      "Nd: 163, N: 43,trainingerror: 0.000000, testerror: 0.054384\n",
      "Nd: 163, N: 50,trainingerror: 0.000000, testerror: 0.045232\n",
      "Nd: 163, N: 58,trainingerror: 0.000000, testerror: 0.120367\n",
      "Nd: 163, N: 67,trainingerror: 0.000000, testerror: 0.389862\n",
      "Nd: 163, N: 78,trainingerror: 0.000000, testerror: 0.125895\n",
      "Nd: 163, N: 90,trainingerror: 0.000000, testerror: 0.087667\n",
      "Nd: 163, N: 104,trainingerror: 0.000000, testerror: 0.110167\n",
      "Nd: 163, N: 121,trainingerror: 0.000204, testerror: 0.108156\n",
      "Nd: 163, N: 141,trainingerror: 0.000014, testerror: 0.108805\n",
      "Nd: 163, N: 163,trainingerror: 0.002769, testerror: 0.283438\n",
      "Nd: 163, N: 190,trainingerror: 0.003246, testerror: 0.070849\n",
      "Nd: 163, N: 220,trainingerror: 0.003257, testerror: 0.114682\n",
      "Nd: 163, N: 256,trainingerror: 0.008217, testerror: 0.179750\n",
      "Nd: 163, N: 297,trainingerror: 0.005285, testerror: 0.087399\n",
      "Nd: 163, N: 345,trainingerror: 0.016172, testerror: 0.191690\n",
      "Nd: 190, N: 20,trainingerror: 0.000000, testerror: 0.089785\n",
      "Nd: 190, N: 24,trainingerror: 0.000000, testerror: 0.109718\n",
      "Nd: 190, N: 27,trainingerror: 0.000000, testerror: 0.010197\n",
      "Nd: 190, N: 32,trainingerror: 0.000000, testerror: 0.230217\n",
      "Nd: 190, N: 37,trainingerror: 0.000000, testerror: 0.081144\n",
      "Nd: 190, N: 43,trainingerror: 0.000000, testerror: 0.018729\n",
      "Nd: 190, N: 50,trainingerror: 0.000000, testerror: 0.092918\n",
      "Nd: 190, N: 58,trainingerror: 0.000000, testerror: 0.047686\n",
      "Nd: 190, N: 67,trainingerror: 0.000013, testerror: 0.074224\n",
      "Nd: 190, N: 78,trainingerror: 0.000000, testerror: 0.057938\n",
      "Nd: 190, N: 90,trainingerror: 0.000006, testerror: 0.089256\n",
      "Nd: 190, N: 104,trainingerror: 0.000000, testerror: 0.078017\n",
      "Nd: 190, N: 121,trainingerror: 0.000017, testerror: 0.077819\n",
      "Nd: 190, N: 141,trainingerror: 0.000107, testerror: 0.076778\n",
      "Nd: 190, N: 163,trainingerror: 0.000668, testerror: 0.124443\n",
      "Nd: 190, N: 190,trainingerror: 0.000356, testerror: 0.111378\n",
      "Nd: 190, N: 220,trainingerror: 0.001313, testerror: 0.099653\n",
      "Nd: 190, N: 256,trainingerror: 0.008591, testerror: 0.255497\n",
      "Nd: 190, N: 297,trainingerror: 0.005600, testerror: 0.091864\n",
      "Nd: 190, N: 345,trainingerror: 0.007053, testerror: 0.088607\n",
      "Nd: 220, N: 20,trainingerror: 0.000000, testerror: 0.078245\n",
      "Nd: 220, N: 24,trainingerror: 0.000000, testerror: 0.009944\n",
      "Nd: 220, N: 27,trainingerror: 0.000000, testerror: 0.053542\n",
      "Nd: 220, N: 32,trainingerror: 0.000000, testerror: 0.065394\n",
      "Nd: 220, N: 37,trainingerror: 0.000000, testerror: 0.113749\n",
      "Nd: 220, N: 43,trainingerror: 0.000000, testerror: 0.103485\n",
      "Nd: 220, N: 50,trainingerror: 0.000000, testerror: 0.153258\n",
      "Nd: 220, N: 58,trainingerror: 0.000000, testerror: 0.051770\n",
      "Nd: 220, N: 67,trainingerror: 0.000000, testerror: 0.053683\n",
      "Nd: 220, N: 78,trainingerror: 0.000000, testerror: 0.086165\n",
      "Nd: 220, N: 90,trainingerror: 0.000009, testerror: 0.047643\n",
      "Nd: 220, N: 104,trainingerror: 0.000043, testerror: 0.156877\n",
      "Nd: 220, N: 121,trainingerror: 0.000000, testerror: 0.061587\n",
      "Nd: 220, N: 141,trainingerror: 0.000002, testerror: 0.076505\n",
      "Nd: 220, N: 163,trainingerror: 0.000412, testerror: 0.074895\n",
      "Nd: 220, N: 190,trainingerror: 0.000969, testerror: 0.092790\n",
      "Nd: 220, N: 220,trainingerror: 0.000313, testerror: 0.125914\n",
      "Nd: 220, N: 256,trainingerror: 0.001256, testerror: 0.137394\n",
      "Nd: 220, N: 297,trainingerror: 0.007230, testerror: 0.126313\n",
      "Nd: 220, N: 345,trainingerror: 0.005429, testerror: 0.083392\n",
      "Nd: 256, N: 20,trainingerror: 0.000000, testerror: 0.118265\n",
      "Nd: 256, N: 24,trainingerror: 0.000000, testerror: 0.031209\n",
      "Nd: 256, N: 27,trainingerror: 0.000000, testerror: 0.060167\n",
      "Nd: 256, N: 32,trainingerror: 0.000000, testerror: 0.022306\n",
      "Nd: 256, N: 37,trainingerror: 0.000147, testerror: 0.087632\n",
      "Nd: 256, N: 43,trainingerror: 0.000000, testerror: 0.100045\n",
      "Nd: 256, N: 50,trainingerror: 0.000000, testerror: 0.191673\n",
      "Nd: 256, N: 58,trainingerror: 0.000000, testerror: 0.054091\n",
      "Nd: 256, N: 67,trainingerror: 0.000002, testerror: 0.079886\n",
      "Nd: 256, N: 78,trainingerror: 0.000592, testerror: 0.095732\n",
      "Nd: 256, N: 90,trainingerror: 0.000000, testerror: 0.024818\n",
      "Nd: 256, N: 104,trainingerror: 0.000000, testerror: 0.247880\n",
      "Nd: 256, N: 121,trainingerror: 0.000000, testerror: 0.103624\n",
      "Nd: 256, N: 141,trainingerror: 0.000002, testerror: 0.092048\n",
      "Nd: 256, N: 163,trainingerror: 0.007794, testerror: 0.165009\n",
      "Nd: 256, N: 190,trainingerror: 0.000078, testerror: 0.115708\n",
      "Nd: 256, N: 220,trainingerror: 0.001494, testerror: 0.088888\n",
      "Nd: 256, N: 256,trainingerror: 0.001518, testerror: 0.121067\n",
      "Nd: 256, N: 297,trainingerror: 0.001178, testerror: 0.089055\n",
      "Nd: 256, N: 345,trainingerror: 0.002334, testerror: 0.233444\n",
      "Nd: 297, N: 20,trainingerror: 0.000000, testerror: 0.024565\n",
      "Nd: 297, N: 24,trainingerror: 0.000000, testerror: 0.063809\n",
      "Nd: 297, N: 27,trainingerror: 0.000000, testerror: 0.075658\n",
      "Nd: 297, N: 32,trainingerror: 0.000000, testerror: 0.159931\n",
      "Nd: 297, N: 37,trainingerror: 0.000000, testerror: 0.103919\n",
      "Nd: 297, N: 43,trainingerror: 0.000000, testerror: 0.052910\n",
      "Nd: 297, N: 50,trainingerror: 0.000000, testerror: 0.092812\n",
      "Nd: 297, N: 58,trainingerror: 0.000000, testerror: 0.146464\n",
      "Nd: 297, N: 67,trainingerror: 0.000000, testerror: 0.089707\n",
      "Nd: 297, N: 78,trainingerror: 0.000000, testerror: 0.094076\n",
      "Nd: 297, N: 90,trainingerror: 0.000000, testerror: 0.086345\n",
      "Nd: 297, N: 104,trainingerror: 0.000000, testerror: 0.405639\n",
      "Nd: 297, N: 121,trainingerror: 0.000000, testerror: 0.110217\n",
      "Nd: 297, N: 141,trainingerror: 0.000000, testerror: 0.093422\n",
      "Nd: 297, N: 163,trainingerror: 0.000014, testerror: 0.065943\n",
      "Nd: 297, N: 190,trainingerror: 0.002391, testerror: 0.378155\n",
      "Nd: 297, N: 220,trainingerror: 0.000561, testerror: 0.105751\n",
      "Nd: 297, N: 256,trainingerror: 0.001469, testerror: 0.098812\n",
      "Nd: 297, N: 297,trainingerror: 0.001482, testerror: 0.119939\n",
      "Nd: 297, N: 345,trainingerror: 0.002639, testerror: 0.121716\n",
      "Nd: 345, N: 20,trainingerror: 0.000000, testerror: 0.056242\n",
      "Nd: 345, N: 24,trainingerror: 0.000000, testerror: 0.090622\n",
      "Nd: 345, N: 27,trainingerror: 0.000000, testerror: 0.093327\n",
      "Nd: 345, N: 32,trainingerror: 0.000000, testerror: 0.241923\n",
      "Nd: 345, N: 37,trainingerror: 0.000000, testerror: 0.370740\n",
      "Nd: 345, N: 43,trainingerror: 0.000000, testerror: 0.040255\n",
      "Nd: 345, N: 50,trainingerror: 0.000000, testerror: 0.026343\n",
      "Nd: 345, N: 58,trainingerror: 0.000000, testerror: 0.072603\n",
      "Nd: 345, N: 67,trainingerror: 0.000000, testerror: 0.226585\n",
      "Nd: 345, N: 78,trainingerror: 0.000000, testerror: 0.103508\n",
      "Nd: 345, N: 90,trainingerror: 0.000000, testerror: 0.077318\n",
      "Nd: 345, N: 104,trainingerror: 0.000000, testerror: 0.050672\n",
      "Nd: 345, N: 121,trainingerror: 0.000000, testerror: 0.087956\n",
      "Nd: 345, N: 141,trainingerror: 0.000000, testerror: 0.068541\n",
      "Nd: 345, N: 163,trainingerror: 0.000000, testerror: 0.118462\n",
      "Nd: 345, N: 190,trainingerror: 0.000005, testerror: 0.228884\n",
      "Nd: 345, N: 220,trainingerror: 0.000001, testerror: 0.097187\n",
      "Nd: 345, N: 256,trainingerror: 0.000015, testerror: 0.134712\n",
      "Nd: 345, N: 297,trainingerror: 0.000146, testerror: 0.130584\n",
      "Nd: 345, N: 345,trainingerror: 0.001193, testerror: 0.120151\n",
      "Nd: 400, N: 20,trainingerror: 0.000000, testerror: 0.218260\n",
      "Nd: 400, N: 24,trainingerror: 0.000000, testerror: 0.075038\n",
      "Nd: 400, N: 27,trainingerror: 0.000000, testerror: 0.213394\n",
      "Nd: 400, N: 32,trainingerror: 0.000000, testerror: 0.027758\n",
      "Nd: 400, N: 37,trainingerror: 0.000000, testerror: 0.032874\n",
      "Nd: 400, N: 43,trainingerror: 0.000000, testerror: 0.031513\n",
      "Nd: 400, N: 50,trainingerror: 0.000000, testerror: 0.056180\n",
      "Nd: 400, N: 58,trainingerror: 0.000000, testerror: 0.132685\n",
      "Nd: 400, N: 67,trainingerror: 0.000003, testerror: 0.069778\n",
      "Nd: 400, N: 78,trainingerror: 0.000000, testerror: 0.048033\n",
      "Nd: 400, N: 90,trainingerror: 0.000089, testerror: 0.235676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 400, N: 104,trainingerror: 0.000000, testerror: 0.115324\n",
      "Nd: 400, N: 121,trainingerror: 0.000000, testerror: 0.127764\n",
      "Nd: 400, N: 141,trainingerror: 0.000000, testerror: 0.131401\n",
      "Nd: 400, N: 163,trainingerror: 0.000000, testerror: 0.588170\n",
      "Nd: 400, N: 190,trainingerror: 0.000000, testerror: 0.094484\n",
      "Nd: 400, N: 220,trainingerror: 0.000000, testerror: 0.131124\n",
      "Nd: 400, N: 256,trainingerror: 0.000010, testerror: 0.186078\n",
      "Nd: 400, N: 297,trainingerror: 0.000018, testerror: 0.108028\n",
      "Nd: 400, N: 345,trainingerror: 0.000246, testerror: 0.170866\n",
      "Nd: 465, N: 20,trainingerror: 0.000000, testerror: 0.247778\n",
      "Nd: 465, N: 24,trainingerror: 0.000000, testerror: 0.035871\n",
      "Nd: 465, N: 27,trainingerror: 0.000000, testerror: 0.133380\n",
      "Nd: 465, N: 32,trainingerror: 0.000000, testerror: 0.069471\n",
      "Nd: 465, N: 37,trainingerror: 0.000000, testerror: 0.062718\n",
      "Nd: 465, N: 43,trainingerror: 0.000000, testerror: 0.063878\n",
      "Nd: 465, N: 50,trainingerror: 0.000000, testerror: 0.227986\n",
      "Nd: 465, N: 58,trainingerror: 0.000000, testerror: 0.058412\n",
      "Nd: 465, N: 67,trainingerror: 0.000000, testerror: 0.129048\n",
      "Nd: 465, N: 78,trainingerror: 0.000000, testerror: 0.333192\n",
      "Nd: 465, N: 90,trainingerror: 0.000000, testerror: 0.128396\n",
      "Nd: 465, N: 104,trainingerror: 0.000000, testerror: 0.067113\n",
      "Nd: 465, N: 121,trainingerror: 0.000000, testerror: 0.096852\n",
      "Nd: 465, N: 141,trainingerror: 0.000000, testerror: 0.071576\n",
      "Nd: 465, N: 163,trainingerror: 0.000000, testerror: 0.171396\n",
      "Nd: 465, N: 190,trainingerror: 0.000000, testerror: 0.108748\n",
      "Nd: 465, N: 220,trainingerror: 0.000000, testerror: 0.105554\n",
      "Nd: 465, N: 256,trainingerror: 0.000000, testerror: 0.079728\n",
      "Nd: 465, N: 297,trainingerror: 0.000002, testerror: 0.060605\n",
      "Nd: 465, N: 345,trainingerror: 0.000113, testerror: 0.128358\n",
      "Nd: 540, N: 20,trainingerror: 0.000000, testerror: 0.023323\n",
      "Nd: 540, N: 24,trainingerror: 0.000000, testerror: 0.121940\n",
      "Nd: 540, N: 27,trainingerror: 0.000000, testerror: 0.714663\n",
      "Nd: 540, N: 32,trainingerror: 0.000000, testerror: 0.112110\n",
      "Nd: 540, N: 37,trainingerror: 0.000000, testerror: 0.061950\n",
      "Nd: 540, N: 43,trainingerror: 0.000000, testerror: 0.042516\n",
      "Nd: 540, N: 50,trainingerror: 0.000000, testerror: 0.086956\n",
      "Nd: 540, N: 58,trainingerror: 0.000000, testerror: 0.137459\n",
      "Nd: 540, N: 67,trainingerror: 0.000000, testerror: 0.048549\n",
      "Nd: 540, N: 78,trainingerror: 0.000000, testerror: 0.043492\n",
      "Nd: 540, N: 90,trainingerror: 0.000000, testerror: 0.099103\n",
      "Nd: 540, N: 104,trainingerror: 0.000000, testerror: 0.048436\n",
      "Nd: 540, N: 121,trainingerror: 0.000000, testerror: 0.089274\n",
      "Nd: 540, N: 141,trainingerror: 0.000000, testerror: 0.065695\n",
      "Nd: 540, N: 163,trainingerror: 0.000000, testerror: 0.054609\n",
      "Nd: 540, N: 190,trainingerror: 0.000000, testerror: 0.116710\n",
      "Nd: 540, N: 220,trainingerror: 0.000000, testerror: 0.132196\n",
      "Nd: 540, N: 256,trainingerror: 0.000000, testerror: 0.091217\n",
      "Nd: 540, N: 297,trainingerror: 0.000308, testerror: 0.142933\n",
      "Nd: 540, N: 345,trainingerror: 0.000028, testerror: 0.130316\n",
      "Nd: 627, N: 20,trainingerror: 0.000000, testerror: 0.439069\n",
      "Nd: 627, N: 24,trainingerror: 0.000000, testerror: 0.050239\n",
      "Nd: 627, N: 27,trainingerror: 0.000000, testerror: 0.037473\n",
      "Nd: 627, N: 32,trainingerror: 0.000000, testerror: 0.060717\n",
      "Nd: 627, N: 37,trainingerror: 0.000000, testerror: 0.051766\n",
      "Nd: 627, N: 43,trainingerror: 0.000000, testerror: 0.085559\n",
      "Nd: 627, N: 50,trainingerror: 0.000000, testerror: 0.112974\n",
      "Nd: 627, N: 58,trainingerror: 0.000000, testerror: 0.382111\n",
      "Nd: 627, N: 67,trainingerror: 0.000000, testerror: 0.085059\n",
      "Nd: 627, N: 78,trainingerror: 0.000000, testerror: 0.174367\n",
      "Nd: 627, N: 90,trainingerror: 0.000000, testerror: 0.043540\n",
      "Nd: 627, N: 104,trainingerror: 0.000000, testerror: 0.192451\n",
      "Nd: 627, N: 121,trainingerror: 0.000000, testerror: 0.031789\n",
      "Nd: 627, N: 141,trainingerror: 0.000000, testerror: 0.136468\n",
      "Nd: 627, N: 163,trainingerror: 0.000000, testerror: 0.084305\n",
      "Nd: 627, N: 190,trainingerror: 0.000000, testerror: 0.094428\n",
      "Nd: 627, N: 220,trainingerror: 0.000000, testerror: 0.123837\n",
      "Nd: 627, N: 256,trainingerror: 0.000000, testerror: 0.160451\n",
      "Nd: 627, N: 297,trainingerror: 0.000004, testerror: 0.147702\n",
      "Nd: 627, N: 345,trainingerror: 0.000023, testerror: 0.073874\n",
      "Nd: 729, N: 20,trainingerror: 0.000000, testerror: 0.060237\n",
      "Nd: 729, N: 24,trainingerror: 0.000000, testerror: 0.217801\n",
      "Nd: 729, N: 27,trainingerror: 0.000000, testerror: 0.015222\n",
      "Nd: 729, N: 32,trainingerror: 0.000000, testerror: 0.800846\n",
      "Nd: 729, N: 37,trainingerror: 0.000000, testerror: 0.072978\n",
      "Nd: 729, N: 43,trainingerror: 0.000000, testerror: 0.045816\n",
      "Nd: 729, N: 50,trainingerror: 0.000000, testerror: 0.149203\n",
      "Nd: 729, N: 58,trainingerror: 0.000000, testerror: 0.083899\n",
      "Nd: 729, N: 67,trainingerror: 0.000000, testerror: 0.077563\n",
      "Nd: 729, N: 78,trainingerror: 0.000000, testerror: 0.234888\n",
      "Nd: 729, N: 90,trainingerror: 0.000000, testerror: 0.147643\n",
      "Nd: 729, N: 104,trainingerror: 0.000000, testerror: 0.106413\n",
      "Nd: 729, N: 121,trainingerror: 0.000000, testerror: 0.077225\n",
      "Nd: 729, N: 141,trainingerror: 0.000000, testerror: 0.123373\n",
      "Nd: 729, N: 163,trainingerror: 0.000000, testerror: 0.114828\n",
      "Nd: 729, N: 190,trainingerror: 0.000000, testerror: 0.072708\n",
      "Nd: 729, N: 220,trainingerror: 0.000011, testerror: 0.118681\n",
      "Nd: 729, N: 256,trainingerror: 0.000000, testerror: 0.067216\n",
      "Nd: 729, N: 297,trainingerror: 0.000000, testerror: 0.102546\n",
      "Nd: 729, N: 345,trainingerror: 0.000002, testerror: 0.092565\n",
      "Nd: 846, N: 20,trainingerror: 0.000000, testerror: 0.262539\n",
      "Nd: 846, N: 24,trainingerror: 0.000000, testerror: 0.099314\n",
      "Nd: 846, N: 27,trainingerror: 0.000000, testerror: 0.023604\n",
      "Nd: 846, N: 32,trainingerror: 0.000000, testerror: 0.196401\n",
      "Nd: 846, N: 37,trainingerror: 0.000000, testerror: 0.158239\n",
      "Nd: 846, N: 43,trainingerror: 0.000000, testerror: 0.127031\n",
      "Nd: 846, N: 50,trainingerror: 0.000000, testerror: 0.026591\n",
      "Nd: 846, N: 58,trainingerror: 0.000000, testerror: 0.065074\n",
      "Nd: 846, N: 67,trainingerror: 0.000000, testerror: 0.043517\n",
      "Nd: 846, N: 78,trainingerror: 0.000000, testerror: 0.062724\n",
      "Nd: 846, N: 90,trainingerror: 0.000000, testerror: 0.052169\n",
      "Nd: 846, N: 104,trainingerror: 0.000000, testerror: 0.086602\n",
      "Nd: 846, N: 121,trainingerror: 0.000000, testerror: 0.076882\n",
      "Nd: 846, N: 141,trainingerror: 0.000000, testerror: 0.131977\n",
      "Nd: 846, N: 163,trainingerror: 0.000000, testerror: 0.148043\n",
      "Nd: 846, N: 190,trainingerror: 0.000000, testerror: 0.086062\n",
      "Nd: 846, N: 220,trainingerror: 0.000000, testerror: 0.095680\n",
      "Nd: 846, N: 256,trainingerror: 0.000000, testerror: 0.116019\n",
      "Nd: 846, N: 297,trainingerror: 0.000020, testerror: 0.128047\n",
      "Nd: 846, N: 345,trainingerror: 0.000000, testerror: 0.105709\n",
      "Nd: 983, N: 20,trainingerror: 0.000000, testerror: 0.082643\n",
      "Nd: 983, N: 24,trainingerror: 0.000000, testerror: 0.142486\n",
      "Nd: 983, N: 27,trainingerror: 0.000000, testerror: 0.050033\n",
      "Nd: 983, N: 32,trainingerror: 0.000000, testerror: 0.060531\n",
      "Nd: 983, N: 37,trainingerror: 0.000000, testerror: 0.062317\n",
      "Nd: 983, N: 43,trainingerror: 0.000000, testerror: 0.208371\n",
      "Nd: 983, N: 50,trainingerror: 0.000000, testerror: 0.022808\n",
      "Nd: 983, N: 58,trainingerror: 0.000000, testerror: 0.053567\n",
      "Nd: 983, N: 67,trainingerror: 0.000000, testerror: 0.144805\n",
      "Nd: 983, N: 78,trainingerror: 0.000000, testerror: 0.295239\n",
      "Nd: 983, N: 90,trainingerror: 0.000000, testerror: 0.100372\n",
      "Nd: 983, N: 104,trainingerror: 0.000000, testerror: 0.078038\n",
      "Nd: 983, N: 121,trainingerror: 0.000000, testerror: 0.049452\n",
      "Nd: 983, N: 141,trainingerror: 0.000000, testerror: 0.064722\n",
      "Nd: 983, N: 163,trainingerror: 0.000000, testerror: 0.082702\n",
      "Nd: 983, N: 190,trainingerror: 0.000000, testerror: 0.100127\n",
      "Nd: 983, N: 220,trainingerror: 0.000002, testerror: 0.148976\n",
      "Nd: 983, N: 256,trainingerror: 0.000000, testerror: 0.102079\n",
      "Nd: 983, N: 297,trainingerror: 0.000054, testerror: 0.085496\n",
      "Nd: 983, N: 345,trainingerror: 0.000000, testerror: 0.089703\n",
      "Nd: 1142, N: 20,trainingerror: 0.000000, testerror: 0.035676\n",
      "Nd: 1142, N: 24,trainingerror: 0.000000, testerror: 0.152346\n",
      "Nd: 1142, N: 27,trainingerror: 0.000000, testerror: 0.060096\n",
      "Nd: 1142, N: 32,trainingerror: 0.000000, testerror: 0.246225\n",
      "Nd: 1142, N: 37,trainingerror: 0.000000, testerror: 0.073787\n",
      "Nd: 1142, N: 43,trainingerror: 0.000000, testerror: 0.038281\n",
      "Nd: 1142, N: 50,trainingerror: 0.000000, testerror: 0.032410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 1142, N: 58,trainingerror: 0.000000, testerror: 1.220790\n",
      "Nd: 1142, N: 67,trainingerror: 0.000000, testerror: 0.033496\n",
      "Nd: 1142, N: 78,trainingerror: 0.000000, testerror: 0.065189\n",
      "Nd: 1142, N: 90,trainingerror: 0.000000, testerror: 0.104392\n",
      "Nd: 1142, N: 104,trainingerror: 0.000000, testerror: 0.042503\n",
      "Nd: 1142, N: 121,trainingerror: 0.000000, testerror: 0.106017\n",
      "Nd: 1142, N: 141,trainingerror: 0.000000, testerror: 0.221750\n",
      "Nd: 1142, N: 163,trainingerror: 0.000000, testerror: 0.080945\n",
      "Nd: 1142, N: 190,trainingerror: 0.000000, testerror: 0.093762\n",
      "Nd: 1142, N: 220,trainingerror: 0.000000, testerror: 0.074612\n",
      "Nd: 1142, N: 256,trainingerror: 0.000000, testerror: 0.081426\n",
      "Nd: 1142, N: 297,trainingerror: 0.000000, testerror: 0.200997\n",
      "Nd: 1142, N: 345,trainingerror: 0.000000, testerror: 0.100631\n",
      "Nd: 1326, N: 20,trainingerror: 0.000000, testerror: 0.150917\n",
      "Nd: 1326, N: 24,trainingerror: 0.000000, testerror: 0.030536\n",
      "Nd: 1326, N: 27,trainingerror: 0.000000, testerror: 0.046151\n",
      "Nd: 1326, N: 32,trainingerror: 0.000000, testerror: 0.058472\n",
      "Nd: 1326, N: 37,trainingerror: 0.000000, testerror: 0.156174\n",
      "Nd: 1326, N: 43,trainingerror: 0.000000, testerror: 0.126045\n",
      "Nd: 1326, N: 50,trainingerror: 0.000000, testerror: 0.054670\n",
      "Nd: 1326, N: 58,trainingerror: 0.000000, testerror: 0.073186\n",
      "Nd: 1326, N: 67,trainingerror: 0.000000, testerror: 0.026706\n",
      "Nd: 1326, N: 78,trainingerror: 0.000000, testerror: 0.042423\n",
      "Nd: 1326, N: 90,trainingerror: 0.000000, testerror: 0.123966\n",
      "Nd: 1326, N: 104,trainingerror: 0.000000, testerror: 0.094418\n",
      "Nd: 1326, N: 121,trainingerror: 0.000045, testerror: 0.201193\n",
      "Nd: 1326, N: 141,trainingerror: 0.000000, testerror: 0.131084\n",
      "Nd: 1326, N: 163,trainingerror: 0.000000, testerror: 0.179896\n",
      "Nd: 1326, N: 190,trainingerror: 0.000000, testerror: 0.058337\n",
      "Nd: 1326, N: 220,trainingerror: 0.000000, testerror: 0.099487\n",
      "Nd: 1326, N: 256,trainingerror: 0.000000, testerror: 0.132063\n",
      "Nd: 1326, N: 297,trainingerror: 0.000000, testerror: 0.122263\n",
      "Nd: 1326, N: 345,trainingerror: 0.000001, testerror: 0.072722\n",
      "Nd: 1541, N: 20,trainingerror: 0.000000, testerror: 0.006703\n",
      "Nd: 1541, N: 24,trainingerror: 0.000000, testerror: 0.033137\n",
      "Nd: 1541, N: 27,trainingerror: 0.000000, testerror: 0.031081\n",
      "Nd: 1541, N: 32,trainingerror: 0.000000, testerror: 0.092070\n",
      "Nd: 1541, N: 37,trainingerror: 0.000000, testerror: 0.065314\n",
      "Nd: 1541, N: 43,trainingerror: 0.000000, testerror: 0.092092\n",
      "Nd: 1541, N: 50,trainingerror: 0.000000, testerror: 0.064319\n",
      "Nd: 1541, N: 58,trainingerror: 0.000000, testerror: 0.063138\n",
      "Nd: 1541, N: 67,trainingerror: 0.000000, testerror: 0.145042\n",
      "Nd: 1541, N: 78,trainingerror: 0.000000, testerror: 0.205502\n",
      "Nd: 1541, N: 90,trainingerror: 0.000000, testerror: 0.062614\n",
      "Nd: 1541, N: 104,trainingerror: 0.000126, testerror: 0.144124\n",
      "Nd: 1541, N: 121,trainingerror: 0.000000, testerror: 0.060156\n",
      "Nd: 1541, N: 141,trainingerror: 0.000001, testerror: 0.083376\n",
      "Nd: 1541, N: 163,trainingerror: 0.000000, testerror: 0.059859\n",
      "Nd: 1541, N: 190,trainingerror: 0.000011, testerror: 0.081192\n",
      "Nd: 1541, N: 220,trainingerror: 0.000001, testerror: 0.068408\n",
      "Nd: 1541, N: 256,trainingerror: 0.000000, testerror: 0.152388\n",
      "Nd: 1541, N: 297,trainingerror: 0.000000, testerror: 0.052850\n",
      "Nd: 1541, N: 345,trainingerror: 0.000091, testerror: 0.091496\n",
      "Nd: 1789, N: 20,trainingerror: 0.000000, testerror: 0.012129\n",
      "Nd: 1789, N: 24,trainingerror: 0.000000, testerror: 0.116776\n",
      "Nd: 1789, N: 27,trainingerror: 0.000000, testerror: 0.059575\n",
      "Nd: 1789, N: 32,trainingerror: 0.000000, testerror: 0.087323\n",
      "Nd: 1789, N: 37,trainingerror: 0.000000, testerror: 0.152390\n",
      "Nd: 1789, N: 43,trainingerror: 0.000000, testerror: 0.887139\n",
      "Nd: 1789, N: 50,trainingerror: 0.000000, testerror: 0.445935\n",
      "Nd: 1789, N: 58,trainingerror: 0.000000, testerror: 0.027797\n",
      "Nd: 1789, N: 67,trainingerror: 0.000000, testerror: 0.062967\n",
      "Nd: 1789, N: 78,trainingerror: 0.000000, testerror: 0.040536\n",
      "Nd: 1789, N: 90,trainingerror: 0.000000, testerror: 0.080373\n",
      "Nd: 1789, N: 104,trainingerror: 0.000000, testerror: 0.033159\n",
      "Nd: 1789, N: 121,trainingerror: 0.000000, testerror: 0.056201\n",
      "Nd: 1789, N: 141,trainingerror: 0.000000, testerror: 0.258702\n",
      "Nd: 1789, N: 163,trainingerror: 0.000000, testerror: 0.053513\n",
      "Nd: 1789, N: 190,trainingerror: 0.000000, testerror: 0.064776\n",
      "Nd: 1789, N: 220,trainingerror: 0.000000, testerror: 0.157851\n",
      "Nd: 1789, N: 256,trainingerror: 0.000001, testerror: 0.101785\n",
      "Nd: 1789, N: 297,trainingerror: 0.000000, testerror: 0.055706\n",
      "Nd: 1789, N: 345,trainingerror: 0.000114, testerror: 0.082019\n",
      "Nd: 2078, N: 20,trainingerror: 0.000000, testerror: 0.092432\n",
      "Nd: 2078, N: 24,trainingerror: 0.000000, testerror: 0.042725\n",
      "Nd: 2078, N: 27,trainingerror: 0.000000, testerror: 0.088449\n",
      "Nd: 2078, N: 32,trainingerror: 0.000000, testerror: 0.101648\n",
      "Nd: 2078, N: 37,trainingerror: 0.000000, testerror: 0.023795\n",
      "Nd: 2078, N: 43,trainingerror: 0.000000, testerror: 0.060325\n",
      "Nd: 2078, N: 50,trainingerror: 0.000000, testerror: 0.024422\n",
      "Nd: 2078, N: 58,trainingerror: 0.000000, testerror: 0.066156\n",
      "Nd: 2078, N: 67,trainingerror: 0.000027, testerror: 0.123369\n",
      "Nd: 2078, N: 78,trainingerror: 0.000000, testerror: 0.030681\n",
      "Nd: 2078, N: 90,trainingerror: 0.000000, testerror: 0.045543\n",
      "Nd: 2078, N: 104,trainingerror: 0.000000, testerror: 0.026976\n",
      "Nd: 2078, N: 121,trainingerror: 0.000000, testerror: 0.032015\n",
      "Nd: 2078, N: 141,trainingerror: 0.000000, testerror: 0.096723\n",
      "Nd: 2078, N: 163,trainingerror: 0.000000, testerror: 0.067627\n",
      "Nd: 2078, N: 190,trainingerror: 0.000005, testerror: 0.092701\n",
      "Nd: 2078, N: 220,trainingerror: 0.000000, testerror: 0.051153\n",
      "Nd: 2078, N: 256,trainingerror: 0.000003, testerror: 0.160829\n",
      "Nd: 2078, N: 297,trainingerror: 0.000000, testerror: 0.115320\n",
      "Nd: 2078, N: 345,trainingerror: 0.000000, testerror: 0.062356\n",
      "Nd: 2414, N: 20,trainingerror: 0.000000, testerror: 0.099139\n",
      "Nd: 2414, N: 24,trainingerror: 0.000000, testerror: 0.106285\n",
      "Nd: 2414, N: 27,trainingerror: 0.000000, testerror: 0.044626\n",
      "Nd: 2414, N: 32,trainingerror: 0.000000, testerror: 0.240320\n",
      "Nd: 2414, N: 37,trainingerror: 0.000000, testerror: 0.047758\n",
      "Nd: 2414, N: 43,trainingerror: 0.000000, testerror: 0.046556\n",
      "Nd: 2414, N: 50,trainingerror: 0.000000, testerror: 0.089932\n",
      "Nd: 2414, N: 58,trainingerror: 0.000000, testerror: 0.097772\n",
      "Nd: 2414, N: 67,trainingerror: 0.000000, testerror: 0.029411\n",
      "Nd: 2414, N: 78,trainingerror: 0.000000, testerror: 0.065060\n",
      "Nd: 2414, N: 90,trainingerror: 0.000004, testerror: 0.111290\n",
      "Nd: 2414, N: 104,trainingerror: 0.000033, testerror: 0.099348\n",
      "Nd: 2414, N: 121,trainingerror: 0.000000, testerror: 0.100730\n",
      "Nd: 2414, N: 141,trainingerror: 0.000703, testerror: 0.072996\n",
      "Nd: 2414, N: 163,trainingerror: 0.000001, testerror: 0.521026\n",
      "Nd: 2414, N: 190,trainingerror: 0.000000, testerror: 0.087932\n",
      "Nd: 2414, N: 220,trainingerror: 0.000000, testerror: 0.055594\n",
      "Nd: 2414, N: 256,trainingerror: 0.000000, testerror: 0.127792\n",
      "Nd: 2414, N: 297,trainingerror: 0.000000, testerror: 0.107735\n",
      "Nd: 2414, N: 345,trainingerror: 0.000002, testerror: 0.115169\n",
      "Nd: 2804, N: 20,trainingerror: 0.000000, testerror: 0.028508\n",
      "Nd: 2804, N: 24,trainingerror: 0.000000, testerror: 0.009477\n",
      "Nd: 2804, N: 27,trainingerror: 0.000000, testerror: 0.047731\n",
      "Nd: 2804, N: 32,trainingerror: 0.000000, testerror: 0.043874\n",
      "Nd: 2804, N: 37,trainingerror: 0.000000, testerror: 0.172029\n",
      "Nd: 2804, N: 43,trainingerror: 0.000000, testerror: 0.079527\n",
      "Nd: 2804, N: 50,trainingerror: 0.000000, testerror: 0.029359\n",
      "Nd: 2804, N: 58,trainingerror: 0.000000, testerror: 0.062569\n",
      "Nd: 2804, N: 67,trainingerror: 0.000000, testerror: 0.196533\n",
      "Nd: 2804, N: 78,trainingerror: 0.000000, testerror: 0.109143\n",
      "Nd: 2804, N: 90,trainingerror: 0.000000, testerror: 0.035612\n",
      "Nd: 2804, N: 104,trainingerror: 0.000002, testerror: 0.163484\n",
      "Nd: 2804, N: 121,trainingerror: 0.000000, testerror: 0.059224\n",
      "Nd: 2804, N: 141,trainingerror: 0.000000, testerror: 0.090050\n",
      "Nd: 2804, N: 163,trainingerror: 0.000010, testerror: 0.065546\n",
      "Nd: 2804, N: 190,trainingerror: 0.000005, testerror: 0.082512\n",
      "Nd: 2804, N: 220,trainingerror: 0.000000, testerror: 0.103068\n",
      "Nd: 2804, N: 256,trainingerror: 0.000000, testerror: 0.054005\n",
      "Nd: 2804, N: 297,trainingerror: 0.000000, testerror: 0.080401\n",
      "Nd: 2804, N: 345,trainingerror: 0.000001, testerror: 0.064140\n",
      "Nd: 3257, N: 20,trainingerror: 0.000000, testerror: 0.248088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 3257, N: 24,trainingerror: 0.000000, testerror: 0.044534\n",
      "Nd: 3257, N: 27,trainingerror: 0.000000, testerror: 0.011305\n",
      "Nd: 3257, N: 32,trainingerror: 0.000000, testerror: 0.031094\n",
      "Nd: 3257, N: 37,trainingerror: 0.000000, testerror: 0.135413\n",
      "Nd: 3257, N: 43,trainingerror: 0.000000, testerror: 0.016575\n",
      "Nd: 3257, N: 50,trainingerror: 0.000000, testerror: 0.096834\n",
      "Nd: 3257, N: 58,trainingerror: 0.000000, testerror: 0.070237\n",
      "Nd: 3257, N: 67,trainingerror: 0.000000, testerror: 0.279907\n",
      "Nd: 3257, N: 78,trainingerror: 0.000000, testerror: 0.072731\n",
      "Nd: 3257, N: 90,trainingerror: 0.000098, testerror: 0.050671\n",
      "Nd: 3257, N: 104,trainingerror: 0.000000, testerror: 0.080503\n",
      "Nd: 3257, N: 121,trainingerror: 0.000002, testerror: 0.133697\n",
      "Nd: 3257, N: 141,trainingerror: 0.000000, testerror: 0.097425\n",
      "Nd: 3257, N: 163,trainingerror: 0.000000, testerror: 0.112959\n",
      "Nd: 3257, N: 190,trainingerror: 0.000000, testerror: 0.034212\n",
      "Nd: 3257, N: 220,trainingerror: 0.000003, testerror: 0.200925\n",
      "Nd: 3257, N: 256,trainingerror: 0.000000, testerror: 0.050887\n",
      "Nd: 3257, N: 297,trainingerror: 0.000000, testerror: 0.086130\n",
      "Nd: 3257, N: 345,trainingerror: 0.000000, testerror: 0.157645\n",
      "Nd: 3783, N: 20,trainingerror: 0.000000, testerror: 0.013029\n",
      "Nd: 3783, N: 24,trainingerror: 0.000000, testerror: 0.164076\n",
      "Nd: 3783, N: 27,trainingerror: 0.000000, testerror: 0.022736\n",
      "Nd: 3783, N: 32,trainingerror: 0.000000, testerror: 0.086364\n",
      "Nd: 3783, N: 37,trainingerror: 0.000000, testerror: 0.065225\n",
      "Nd: 3783, N: 43,trainingerror: 0.000000, testerror: 0.047241\n",
      "Nd: 3783, N: 50,trainingerror: 0.000000, testerror: 0.289502\n",
      "Nd: 3783, N: 58,trainingerror: 0.000000, testerror: 0.033985\n",
      "Nd: 3783, N: 67,trainingerror: 0.000000, testerror: 0.071672\n",
      "Nd: 3783, N: 78,trainingerror: 0.000000, testerror: 0.064809\n",
      "Nd: 3783, N: 90,trainingerror: 0.000000, testerror: 0.130584\n",
      "Nd: 3783, N: 104,trainingerror: 0.000000, testerror: 0.034476\n",
      "Nd: 3783, N: 121,trainingerror: 0.000000, testerror: 0.053032\n",
      "Nd: 3783, N: 141,trainingerror: 0.000035, testerror: 0.054981\n",
      "Nd: 3783, N: 163,trainingerror: 0.000000, testerror: 0.212501\n",
      "Nd: 3783, N: 190,trainingerror: 0.000000, testerror: 0.056893\n",
      "Nd: 3783, N: 220,trainingerror: 0.000000, testerror: 0.105951\n",
      "Nd: 3783, N: 256,trainingerror: 0.000020, testerror: 0.076932\n",
      "Nd: 3783, N: 297,trainingerror: 0.000117, testerror: 0.043972\n",
      "Nd: 3783, N: 345,trainingerror: 0.000000, testerror: 0.072794\n",
      "Nd: 4395, N: 20,trainingerror: 0.000000, testerror: 0.314119\n",
      "Nd: 4395, N: 24,trainingerror: 0.000000, testerror: 0.020871\n",
      "Nd: 4395, N: 27,trainingerror: 0.000000, testerror: 0.099566\n",
      "Nd: 4395, N: 32,trainingerror: 0.000000, testerror: 0.410292\n",
      "Nd: 4395, N: 37,trainingerror: 0.000000, testerror: 0.117158\n",
      "Nd: 4395, N: 43,trainingerror: 0.000000, testerror: 0.163888\n",
      "Nd: 4395, N: 50,trainingerror: 0.000010, testerror: 0.064643\n",
      "Nd: 4395, N: 58,trainingerror: 0.000003, testerror: 0.122269\n",
      "Nd: 4395, N: 67,trainingerror: 0.000000, testerror: 0.102520\n",
      "Nd: 4395, N: 78,trainingerror: 0.000000, testerror: 0.145134\n",
      "Nd: 4395, N: 90,trainingerror: 0.000000, testerror: 0.075660\n",
      "Nd: 4395, N: 104,trainingerror: 0.000128, testerror: 0.038673\n",
      "Nd: 4395, N: 121,trainingerror: 0.000000, testerror: 0.091422\n",
      "Nd: 4395, N: 141,trainingerror: 0.000001, testerror: 0.093892\n",
      "Nd: 4395, N: 163,trainingerror: 0.000000, testerror: 0.069732\n",
      "Nd: 4395, N: 190,trainingerror: 0.000000, testerror: 0.167372\n",
      "Nd: 4395, N: 220,trainingerror: 0.000000, testerror: 0.083017\n",
      "Nd: 4395, N: 256,trainingerror: 0.000000, testerror: 0.090649\n",
      "Nd: 4395, N: 297,trainingerror: 0.000010, testerror: 0.091532\n",
      "Nd: 4395, N: 345,trainingerror: 0.000000, testerror: 0.068191\n",
      "Nd: 5105, N: 20,trainingerror: 0.000000, testerror: 0.199188\n",
      "Nd: 5105, N: 24,trainingerror: 0.000003, testerror: 0.120369\n",
      "Nd: 5105, N: 27,trainingerror: 0.000000, testerror: 0.097446\n",
      "Nd: 5105, N: 32,trainingerror: 0.000000, testerror: 0.041731\n",
      "Nd: 5105, N: 37,trainingerror: 0.000000, testerror: 0.086230\n",
      "Nd: 5105, N: 43,trainingerror: 0.000000, testerror: 0.134696\n",
      "Nd: 5105, N: 50,trainingerror: 0.000000, testerror: 0.068725\n",
      "Nd: 5105, N: 58,trainingerror: 0.000000, testerror: 0.156837\n",
      "Nd: 5105, N: 67,trainingerror: 0.000000, testerror: 0.135820\n",
      "Nd: 5105, N: 78,trainingerror: 0.000000, testerror: 0.108736\n",
      "Nd: 5105, N: 90,trainingerror: 0.000000, testerror: 0.289434\n",
      "Nd: 5105, N: 104,trainingerror: 0.000009, testerror: 0.311805\n",
      "Nd: 5105, N: 121,trainingerror: 0.000000, testerror: 0.110648\n",
      "Nd: 5105, N: 141,trainingerror: 0.000000, testerror: 0.248752\n",
      "Nd: 5105, N: 163,trainingerror: 0.000000, testerror: 0.085710\n",
      "Nd: 5105, N: 190,trainingerror: 0.000000, testerror: 0.080790\n",
      "Nd: 5105, N: 220,trainingerror: 0.000165, testerror: 0.180073\n",
      "Nd: 5105, N: 256,trainingerror: 0.000000, testerror: 0.082739\n",
      "Nd: 5105, N: 297,trainingerror: 0.000001, testerror: 0.093798\n",
      "Nd: 5105, N: 345,trainingerror: 0.000000, testerror: 0.055571\n",
      "Nd: 5930, N: 20,trainingerror: 0.000000, testerror: 0.026685\n",
      "Nd: 5930, N: 24,trainingerror: 0.000000, testerror: 0.127648\n",
      "Nd: 5930, N: 27,trainingerror: 0.000000, testerror: 0.068235\n",
      "Nd: 5930, N: 32,trainingerror: 0.000000, testerror: 0.065501\n",
      "Nd: 5930, N: 37,trainingerror: 0.000000, testerror: 0.155717\n",
      "Nd: 5930, N: 43,trainingerror: 0.000000, testerror: 0.186495\n",
      "Nd: 5930, N: 50,trainingerror: 0.000065, testerror: 0.141961\n",
      "Nd: 5930, N: 58,trainingerror: 0.000000, testerror: 0.209597\n",
      "Nd: 5930, N: 67,trainingerror: 0.000000, testerror: 0.027397\n",
      "Nd: 5930, N: 78,trainingerror: 0.000000, testerror: 0.063367\n",
      "Nd: 5930, N: 90,trainingerror: 0.000000, testerror: 0.080943\n",
      "Nd: 5930, N: 104,trainingerror: 0.000000, testerror: 0.052771\n",
      "Nd: 5930, N: 121,trainingerror: 0.000001, testerror: 0.075150\n",
      "Nd: 5930, N: 141,trainingerror: 0.000000, testerror: 0.119493\n",
      "Nd: 5930, N: 163,trainingerror: 0.000000, testerror: 0.102633\n",
      "Nd: 5930, N: 190,trainingerror: 0.000029, testerror: 0.157658\n",
      "Nd: 5930, N: 220,trainingerror: 0.000000, testerror: 0.102935\n",
      "Nd: 5930, N: 256,trainingerror: 0.000000, testerror: 0.079075\n",
      "Nd: 5930, N: 297,trainingerror: 0.000001, testerror: 0.072183\n",
      "Nd: 5930, N: 345,trainingerror: 0.000000, testerror: 0.099315\n",
      "Nd: 6888, N: 20,trainingerror: 0.000014, testerror: 0.050478\n",
      "Nd: 6888, N: 24,trainingerror: 0.000000, testerror: 0.020089\n",
      "Nd: 6888, N: 27,trainingerror: 0.000000, testerror: 0.065174\n",
      "Nd: 6888, N: 32,trainingerror: 0.000000, testerror: 0.226481\n",
      "Nd: 6888, N: 37,trainingerror: 0.000000, testerror: 0.256030\n",
      "Nd: 6888, N: 43,trainingerror: 0.000048, testerror: 0.166640\n",
      "Nd: 6888, N: 50,trainingerror: 0.000000, testerror: 0.168078\n",
      "Nd: 6888, N: 58,trainingerror: 0.000000, testerror: 0.152978\n",
      "Nd: 6888, N: 67,trainingerror: 0.000000, testerror: 0.298638\n",
      "Nd: 6888, N: 78,trainingerror: 0.000000, testerror: 0.045120\n",
      "Nd: 6888, N: 90,trainingerror: 0.000000, testerror: 0.071469\n",
      "Nd: 6888, N: 104,trainingerror: 0.000000, testerror: 0.098930\n",
      "Nd: 6888, N: 121,trainingerror: 0.000000, testerror: 0.096347\n",
      "Nd: 6888, N: 141,trainingerror: 0.000008, testerror: 0.102849\n",
      "Nd: 6888, N: 163,trainingerror: 0.000000, testerror: 0.047508\n",
      "Nd: 6888, N: 190,trainingerror: 0.000000, testerror: 0.232068\n",
      "Nd: 6888, N: 220,trainingerror: 0.000000, testerror: 0.101764\n",
      "Nd: 6888, N: 256,trainingerror: 0.000000, testerror: 0.128671\n",
      "Nd: 6888, N: 297,trainingerror: 0.000000, testerror: 0.051492\n",
      "Nd: 6888, N: 345,trainingerror: 0.000041, testerror: 0.116786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_trainingerror = np.zeros((40,20))\n",
    "result_testerror = np.zeros((40,20))    \n",
    "\n",
    "for i in range(20,60):\n",
    "    x_id = i /20\n",
    "    for j in range(20,40):\n",
    "        y_id = j/20\n",
    "        \n",
    "        N = int(np.ceil(np.e**(y_id * np.log(20))))\n",
    "        Nd = int(np.ceil(np.e**(x_id* np.log(20))))\n",
    "        \n",
    "        for nrepitition in range(nrep):\n",
    "            x = getRandomSamplesOnNSphere(d,N)\n",
    "            y = generate_y(x,beta)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,shuffle = True)\n",
    "            x_train = torch.FloatTensor(x_train)\n",
    "            x_test = torch.FloatTensor(x_test)\n",
    "            y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "            y_test = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "\n",
    "            train_dataset = dataset(x_train, y_train)\n",
    "            test_dataset = dataset(x_test, y_test)\n",
    "            train_dataloader = DataLoader(dataset= train_dataset, \n",
    "                                        batch_size = len(x_train), \n",
    "                                        shuffle= True, \n",
    "                                        drop_last= False)\n",
    "            test_dataloader = DataLoader(dataset= test_dataset, \n",
    "                                        batch_size = len(x_test), \n",
    "                                        shuffle= True, \n",
    "                                        drop_last= False)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            lr = 0.01\n",
    "\n",
    "            device = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n",
    "            model = Model_1(input_dim= d, Nd = Nd,drop_rate= 0.0).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr)\n",
    "            LOSS = 0\n",
    "            LOSS2 = 0\n",
    "            model.train()\n",
    "            \n",
    "            for epoch in range(500):\n",
    "\n",
    "                for index, (x, y) in enumerate(train_dataloader):\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.to(device)\n",
    "                        y = y.to(device)\n",
    "                    y_pred = model(x)\n",
    "                    loss = criterion(y_pred,y)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            #         for p in model.parameters():\n",
    "            #             # print(p.grad.norm())                 \n",
    "            #             torch.nn.utils.clip_grad_norm_(p, 10)  \n",
    "            #         optimizer.step()\n",
    "            LOSS += loss\n",
    "            model.eval()\n",
    "            loss2 = criterion(model(x_test), y_test)\n",
    "            \n",
    "            LOSS2 += loss2\n",
    "            \n",
    "        training_error = LOSS /nrep\n",
    "        test_error = LOSS2 /nrep\n",
    "        \n",
    "        result_trainingerror[i-20][j-20] = training_error\n",
    "        result_testerror[i-20][j-20] = test_error\n",
    "        \n",
    "        print('Nd: %d, N: %d,trainingerror: %f, testerror: %f'%(Nd,N, training_error, test_error))\n",
    "        \n",
    "    np.save('./result/trainingerror.npy',result_trainingerror)\n",
    "    np.save('./result/testerror.npy',result_testerror)    \n",
    "         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4defd70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 20, N: 20,trainingerror: 0.004552, testerror: 0.044726\n",
      "Nd: 20, N: 24,trainingerror: 0.001442, testerror: 0.020392\n",
      "Nd: 20, N: 27,trainingerror: 0.075265, testerror: 0.097042\n",
      "Nd: 20, N: 32,trainingerror: 0.001766, testerror: 0.266417\n",
      "Nd: 20, N: 37,trainingerror: 0.021868, testerror: 0.121627\n",
      "Nd: 20, N: 43,trainingerror: 0.015119, testerror: 0.138093\n",
      "Nd: 20, N: 50,trainingerror: 0.018621, testerror: 0.091048\n",
      "Nd: 20, N: 58,trainingerror: 0.030717, testerror: 0.200114\n",
      "Nd: 20, N: 67,trainingerror: 0.018278, testerror: 0.050591\n",
      "Nd: 20, N: 78,trainingerror: 0.019675, testerror: 0.030196\n",
      "Nd: 20, N: 90,trainingerror: 0.023439, testerror: 0.087436\n",
      "Nd: 20, N: 104,trainingerror: 0.052299, testerror: 0.100255\n",
      "Nd: 20, N: 121,trainingerror: 0.050665, testerror: 0.643702\n",
      "Nd: 20, N: 141,trainingerror: 0.026589, testerror: 0.058750\n",
      "Nd: 20, N: 163,trainingerror: 0.035355, testerror: 0.044255\n",
      "Nd: 20, N: 190,trainingerror: 0.063122, testerror: 0.065174\n",
      "Nd: 20, N: 220,trainingerror: 0.052959, testerror: 0.054165\n",
      "Nd: 20, N: 256,trainingerror: 0.079553, testerror: 0.050326\n",
      "Nd: 20, N: 297,trainingerror: 0.042020, testerror: 0.102934\n",
      "Nd: 20, N: 345,trainingerror: 0.062235, testerror: 0.053798\n",
      "Nd: 20, N: 400,trainingerror: 0.047272, testerror: 0.064597\n",
      "Nd: 20, N: 465,trainingerror: 0.028421, testerror: 0.102023\n",
      "Nd: 20, N: 540,trainingerror: 0.066471, testerror: 0.063113\n",
      "Nd: 20, N: 627,trainingerror: 0.053592, testerror: 0.058073\n",
      "Nd: 20, N: 729,trainingerror: 0.135634, testerror: 0.109235\n",
      "Nd: 20, N: 846,trainingerror: 0.125533, testerror: 0.088263\n",
      "Nd: 20, N: 983,trainingerror: 0.049989, testerror: 0.080449\n",
      "Nd: 20, N: 1142,trainingerror: 0.091871, testerror: 0.047533\n",
      "Nd: 20, N: 1326,trainingerror: 0.048821, testerror: 0.063814\n",
      "Nd: 20, N: 1541,trainingerror: 0.108367, testerror: 0.134471\n",
      "Nd: 20, N: 1789,trainingerror: 0.057814, testerror: 0.129013\n",
      "Nd: 20, N: 2078,trainingerror: 0.061431, testerror: 0.063141\n",
      "Nd: 20, N: 2414,trainingerror: 0.057098, testerror: 0.110091\n",
      "Nd: 20, N: 2804,trainingerror: 0.071287, testerror: 0.059282\n",
      "Nd: 20, N: 3257,trainingerror: 0.115479, testerror: 0.084531\n",
      "Nd: 20, N: 3783,trainingerror: 0.053289, testerror: 0.044278\n",
      "Nd: 20, N: 4395,trainingerror: 0.077587, testerror: 0.071707\n",
      "Nd: 20, N: 5105,trainingerror: 0.081675, testerror: 0.049489\n",
      "Nd: 20, N: 5930,trainingerror: 0.083764, testerror: 0.067340\n",
      "Nd: 20, N: 6888,trainingerror: 0.071566, testerror: 0.073185\n",
      "Nd: 24, N: 20,trainingerror: 0.063546, testerror: 0.047421\n",
      "Nd: 24, N: 24,trainingerror: 0.020469, testerror: 0.333863\n",
      "Nd: 24, N: 27,trainingerror: 0.136508, testerror: 0.043297\n",
      "Nd: 24, N: 32,trainingerror: 0.004456, testerror: 0.267478\n",
      "Nd: 24, N: 37,trainingerror: 0.040846, testerror: 0.081713\n",
      "Nd: 24, N: 43,trainingerror: 0.011738, testerror: 0.205597\n",
      "Nd: 24, N: 50,trainingerror: 0.067828, testerror: 0.574598\n",
      "Nd: 24, N: 58,trainingerror: 0.033385, testerror: 0.137822\n",
      "Nd: 24, N: 67,trainingerror: 0.612906, testerror: 0.199909\n",
      "Nd: 24, N: 78,trainingerror: 0.023869, testerror: 0.207602\n",
      "Nd: 24, N: 90,trainingerror: 0.060895, testerror: 0.083909\n",
      "Nd: 24, N: 104,trainingerror: 0.026235, testerror: 0.066388\n",
      "Nd: 24, N: 121,trainingerror: 0.031600, testerror: 0.038729\n",
      "Nd: 24, N: 141,trainingerror: 0.025260, testerror: 0.054422\n",
      "Nd: 24, N: 163,trainingerror: 0.188833, testerror: 0.045378\n",
      "Nd: 24, N: 190,trainingerror: 0.038556, testerror: 0.259105\n",
      "Nd: 24, N: 220,trainingerror: 0.056687, testerror: 0.038999\n",
      "Nd: 24, N: 256,trainingerror: 0.038561, testerror: 0.114230\n",
      "Nd: 24, N: 297,trainingerror: 0.104941, testerror: 0.051095\n",
      "Nd: 24, N: 345,trainingerror: 0.080317, testerror: 0.065868\n",
      "Nd: 24, N: 400,trainingerror: 0.110480, testerror: 0.082104\n",
      "Nd: 24, N: 465,trainingerror: 0.068532, testerror: 0.045542\n",
      "Nd: 24, N: 540,trainingerror: 0.139464, testerror: 0.088180\n",
      "Nd: 24, N: 627,trainingerror: 0.054776, testerror: 0.066705\n",
      "Nd: 24, N: 729,trainingerror: 0.055044, testerror: 0.040929\n",
      "Nd: 24, N: 846,trainingerror: 0.047683, testerror: 0.059014\n",
      "Nd: 24, N: 983,trainingerror: 0.051501, testerror: 0.034273\n",
      "Nd: 24, N: 1142,trainingerror: 0.144039, testerror: 0.127966\n",
      "Nd: 24, N: 1326,trainingerror: 0.121173, testerror: 0.131539\n",
      "Nd: 24, N: 1541,trainingerror: 0.118166, testerror: 0.136255\n",
      "Nd: 24, N: 1789,trainingerror: 0.044699, testerror: 0.067307\n",
      "Nd: 24, N: 2078,trainingerror: 0.049781, testerror: 0.057102\n",
      "Nd: 24, N: 2414,trainingerror: 0.060733, testerror: 0.063755\n",
      "Nd: 24, N: 2804,trainingerror: 0.076646, testerror: 0.075030\n",
      "Nd: 24, N: 3257,trainingerror: 0.054499, testerror: 0.054905\n",
      "Nd: 24, N: 3783,trainingerror: 0.116086, testerror: 0.108059\n",
      "Nd: 24, N: 4395,trainingerror: 0.061194, testerror: 0.051258\n",
      "Nd: 24, N: 5105,trainingerror: 0.053274, testerror: 0.048199\n",
      "Nd: 24, N: 5930,trainingerror: 0.104697, testerror: 0.122276\n",
      "Nd: 24, N: 6888,trainingerror: 0.104652, testerror: 0.107130\n",
      "Nd: 27, N: 20,trainingerror: 0.003371, testerror: 0.016730\n",
      "Nd: 27, N: 24,trainingerror: 0.013203, testerror: 0.054272\n",
      "Nd: 27, N: 27,trainingerror: 0.017356, testerror: 0.415647\n",
      "Nd: 27, N: 32,trainingerror: 0.016899, testerror: 0.071886\n",
      "Nd: 27, N: 37,trainingerror: 0.005588, testerror: 0.146785\n",
      "Nd: 27, N: 43,trainingerror: 0.015939, testerror: 0.061058\n",
      "Nd: 27, N: 50,trainingerror: 0.027606, testerror: 0.277151\n",
      "Nd: 27, N: 58,trainingerror: 0.058044, testerror: 0.098716\n",
      "Nd: 27, N: 67,trainingerror: 0.024671, testerror: 0.048416\n",
      "Nd: 27, N: 78,trainingerror: 0.024657, testerror: 0.701036\n",
      "Nd: 27, N: 90,trainingerror: 0.016884, testerror: 0.034835\n",
      "Nd: 27, N: 104,trainingerror: 0.040318, testerror: 0.038260\n",
      "Nd: 27, N: 121,trainingerror: 0.072535, testerror: 0.072211\n",
      "Nd: 27, N: 141,trainingerror: 0.031555, testerror: 0.031945\n",
      "Nd: 27, N: 163,trainingerror: 0.042638, testerror: 0.060270\n",
      "Nd: 27, N: 190,trainingerror: 0.033238, testerror: 0.040349\n",
      "Nd: 27, N: 220,trainingerror: 0.054337, testerror: 0.039652\n",
      "Nd: 27, N: 256,trainingerror: 0.095538, testerror: 0.074579\n",
      "Nd: 27, N: 297,trainingerror: 0.064170, testerror: 0.055736\n",
      "Nd: 27, N: 345,trainingerror: 0.054469, testerror: 0.042869\n",
      "Nd: 27, N: 400,trainingerror: 0.124471, testerror: 0.117362\n",
      "Nd: 27, N: 465,trainingerror: 0.043765, testerror: 0.101075\n",
      "Nd: 27, N: 540,trainingerror: 0.089507, testerror: 0.061060\n",
      "Nd: 27, N: 627,trainingerror: 0.042342, testerror: 0.061593\n",
      "Nd: 27, N: 729,trainingerror: 0.057926, testerror: 0.045982\n",
      "Nd: 27, N: 846,trainingerror: 0.074162, testerror: 0.047072\n",
      "Nd: 27, N: 983,trainingerror: 0.082067, testerror: 0.057830\n",
      "Nd: 27, N: 1142,trainingerror: 0.042303, testerror: 0.104195\n",
      "Nd: 27, N: 1326,trainingerror: 0.088382, testerror: 0.045069\n",
      "Nd: 27, N: 1541,trainingerror: 0.067559, testerror: 0.043489\n",
      "Nd: 27, N: 1789,trainingerror: 0.056924, testerror: 0.058490\n",
      "Nd: 27, N: 2078,trainingerror: 0.061641, testerror: 0.100200\n",
      "Nd: 27, N: 2414,trainingerror: 0.152943, testerror: 0.088272\n",
      "Nd: 27, N: 2804,trainingerror: 0.066400, testerror: 0.080066\n",
      "Nd: 27, N: 3257,trainingerror: 0.072513, testerror: 0.045257\n",
      "Nd: 27, N: 3783,trainingerror: 0.060443, testerror: 0.065120\n",
      "Nd: 27, N: 4395,trainingerror: 0.105328, testerror: 0.086594\n",
      "Nd: 27, N: 5105,trainingerror: 0.078784, testerror: 0.073529\n",
      "Nd: 27, N: 5930,trainingerror: 0.064670, testerror: 0.113959\n",
      "Nd: 27, N: 6888,trainingerror: 0.062978, testerror: 0.084119\n",
      "Nd: 32, N: 20,trainingerror: 0.089830, testerror: 0.046731\n",
      "Nd: 32, N: 24,trainingerror: 0.017241, testerror: 0.160499\n",
      "Nd: 32, N: 27,trainingerror: 0.040507, testerror: 0.132048\n",
      "Nd: 32, N: 32,trainingerror: 0.014470, testerror: 0.055075\n",
      "Nd: 32, N: 37,trainingerror: 0.019469, testerror: 0.069403\n",
      "Nd: 32, N: 43,trainingerror: 0.010782, testerror: 0.120139\n",
      "Nd: 32, N: 50,trainingerror: 0.075088, testerror: 0.055278\n",
      "Nd: 32, N: 58,trainingerror: 0.035256, testerror: 0.091150\n",
      "Nd: 32, N: 67,trainingerror: 0.080981, testerror: 0.285396\n",
      "Nd: 32, N: 78,trainingerror: 0.034061, testerror: 0.172992\n",
      "Nd: 32, N: 90,trainingerror: 0.032246, testerror: 0.025980\n",
      "Nd: 32, N: 104,trainingerror: 0.066668, testerror: 0.054926\n",
      "Nd: 32, N: 121,trainingerror: 0.021612, testerror: 0.047646\n",
      "Nd: 32, N: 141,trainingerror: 0.108646, testerror: 0.064570\n",
      "Nd: 32, N: 163,trainingerror: 0.059960, testerror: 0.091396\n",
      "Nd: 32, N: 190,trainingerror: 0.087616, testerror: 0.062268\n",
      "Nd: 32, N: 220,trainingerror: 0.040224, testerror: 0.049030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 32, N: 256,trainingerror: 0.135418, testerror: 0.067146\n",
      "Nd: 32, N: 297,trainingerror: 0.075468, testerror: 0.101089\n",
      "Nd: 32, N: 345,trainingerror: 0.175968, testerror: 0.146836\n",
      "Nd: 32, N: 400,trainingerror: 0.030552, testerror: 0.046610\n",
      "Nd: 32, N: 465,trainingerror: 0.045938, testerror: 0.084710\n",
      "Nd: 32, N: 540,trainingerror: 0.041407, testerror: 0.283031\n",
      "Nd: 32, N: 627,trainingerror: 0.049055, testerror: 0.033876\n",
      "Nd: 32, N: 729,trainingerror: 0.036314, testerror: 0.079573\n",
      "Nd: 32, N: 846,trainingerror: 0.043615, testerror: 0.049515\n",
      "Nd: 32, N: 983,trainingerror: 0.068589, testerror: 0.137938\n",
      "Nd: 32, N: 1142,trainingerror: 0.038721, testerror: 0.053285\n",
      "Nd: 32, N: 1326,trainingerror: 0.057049, testerror: 0.063397\n",
      "Nd: 32, N: 1541,trainingerror: 0.075427, testerror: 0.071384\n",
      "Nd: 32, N: 1789,trainingerror: 0.053370, testerror: 0.045159\n",
      "Nd: 32, N: 2078,trainingerror: 0.078734, testerror: 0.053068\n",
      "Nd: 32, N: 2414,trainingerror: 0.068218, testerror: 0.120624\n",
      "Nd: 32, N: 2804,trainingerror: 0.076074, testerror: 0.145244\n",
      "Nd: 32, N: 3257,trainingerror: 0.059074, testerror: 0.065541\n",
      "Nd: 32, N: 3783,trainingerror: 0.056722, testerror: 0.066117\n",
      "Nd: 32, N: 4395,trainingerror: 0.066948, testerror: 0.069658\n",
      "Nd: 32, N: 5105,trainingerror: 0.049341, testerror: 0.058264\n",
      "Nd: 32, N: 5930,trainingerror: 0.073491, testerror: 0.058529\n",
      "Nd: 32, N: 6888,trainingerror: 0.068703, testerror: 0.064993\n",
      "Nd: 37, N: 20,trainingerror: 0.024889, testerror: 0.044507\n",
      "Nd: 37, N: 24,trainingerror: 1.583950, testerror: 0.170460\n",
      "Nd: 37, N: 27,trainingerror: 0.003378, testerror: 0.058044\n",
      "Nd: 37, N: 32,trainingerror: 0.050922, testerror: 0.035940\n",
      "Nd: 37, N: 37,trainingerror: 0.107198, testerror: 0.135911\n",
      "Nd: 37, N: 43,trainingerror: 0.010018, testerror: 0.139339\n",
      "Nd: 37, N: 50,trainingerror: 0.045178, testerror: 0.209145\n",
      "Nd: 37, N: 58,trainingerror: 0.011451, testerror: 0.063743\n",
      "Nd: 37, N: 67,trainingerror: 0.035054, testerror: 0.082698\n",
      "Nd: 37, N: 78,trainingerror: 0.019534, testerror: 0.056954\n",
      "Nd: 37, N: 90,trainingerror: 0.021906, testerror: 0.523661\n",
      "Nd: 37, N: 104,trainingerror: 0.015311, testerror: 0.059538\n",
      "Nd: 37, N: 121,trainingerror: 0.030417, testerror: 0.073121\n",
      "Nd: 37, N: 141,trainingerror: 0.046966, testerror: 0.047273\n",
      "Nd: 37, N: 163,trainingerror: 0.065305, testerror: 0.052723\n",
      "Nd: 37, N: 190,trainingerror: 0.089086, testerror: 0.036015\n",
      "Nd: 37, N: 220,trainingerror: 0.058930, testerror: 0.028280\n",
      "Nd: 37, N: 256,trainingerror: 0.031975, testerror: 0.041710\n",
      "Nd: 37, N: 297,trainingerror: 0.064602, testerror: 0.026157\n",
      "Nd: 37, N: 345,trainingerror: 0.030805, testerror: 0.042138\n",
      "Nd: 37, N: 400,trainingerror: 0.034926, testerror: 0.066494\n",
      "Nd: 37, N: 465,trainingerror: 0.038858, testerror: 0.044621\n",
      "Nd: 37, N: 540,trainingerror: 0.074161, testerror: 0.054660\n",
      "Nd: 37, N: 627,trainingerror: 0.067378, testerror: 0.037327\n",
      "Nd: 37, N: 729,trainingerror: 0.066599, testerror: 0.058517\n",
      "Nd: 37, N: 846,trainingerror: 0.054533, testerror: 0.048094\n",
      "Nd: 37, N: 983,trainingerror: 0.046719, testerror: 0.060564\n",
      "Nd: 37, N: 1142,trainingerror: 0.109499, testerror: 0.049341\n",
      "Nd: 37, N: 1326,trainingerror: 0.144849, testerror: 0.062906\n",
      "Nd: 37, N: 1541,trainingerror: 0.088778, testerror: 0.066199\n",
      "Nd: 37, N: 1789,trainingerror: 0.060103, testerror: 0.050369\n",
      "Nd: 37, N: 2078,trainingerror: 0.050179, testerror: 0.064352\n",
      "Nd: 37, N: 2414,trainingerror: 0.074160, testerror: 0.085851\n",
      "Nd: 37, N: 2804,trainingerror: 0.064949, testerror: 0.049419\n",
      "Nd: 37, N: 3257,trainingerror: 0.054640, testerror: 0.038978\n",
      "Nd: 37, N: 3783,trainingerror: 0.067511, testerror: 0.055361\n",
      "Nd: 37, N: 4395,trainingerror: 0.060460, testerror: 0.058508\n",
      "Nd: 37, N: 5105,trainingerror: 0.118110, testerror: 0.104034\n",
      "Nd: 37, N: 5930,trainingerror: 0.056033, testerror: 0.062882\n",
      "Nd: 37, N: 6888,trainingerror: 0.063008, testerror: 0.041930\n",
      "Nd: 43, N: 20,trainingerror: 0.063139, testerror: 0.091389\n",
      "Nd: 43, N: 24,trainingerror: 0.000448, testerror: 0.167254\n",
      "Nd: 43, N: 27,trainingerror: 0.000001, testerror: 0.097866\n",
      "Nd: 43, N: 32,trainingerror: 0.000044, testerror: 0.051587\n",
      "Nd: 43, N: 37,trainingerror: 0.004457, testerror: 0.100470\n",
      "Nd: 43, N: 43,trainingerror: 0.001804, testerror: 0.164700\n",
      "Nd: 43, N: 50,trainingerror: 0.002963, testerror: 0.455611\n",
      "Nd: 43, N: 58,trainingerror: 0.002742, testerror: 0.105661\n",
      "Nd: 43, N: 67,trainingerror: 0.006476, testerror: 0.083586\n",
      "Nd: 43, N: 78,trainingerror: 0.044314, testerror: 0.344663\n",
      "Nd: 43, N: 90,trainingerror: 0.019405, testerror: 0.051805\n",
      "Nd: 43, N: 104,trainingerror: 0.019594, testerror: 0.050521\n",
      "Nd: 43, N: 121,trainingerror: 0.037786, testerror: 0.278990\n",
      "Nd: 43, N: 141,trainingerror: 0.018835, testerror: 0.081421\n",
      "Nd: 43, N: 163,trainingerror: 0.044470, testerror: 0.035747\n",
      "Nd: 43, N: 190,trainingerror: 0.019266, testerror: 0.065090\n",
      "Nd: 43, N: 220,trainingerror: 0.038665, testerror: 0.034227\n",
      "Nd: 43, N: 256,trainingerror: 0.022091, testerror: 0.152571\n",
      "Nd: 43, N: 297,trainingerror: 0.042223, testerror: 0.051352\n",
      "Nd: 43, N: 345,trainingerror: 0.036439, testerror: 0.088157\n",
      "Nd: 43, N: 400,trainingerror: 0.141358, testerror: 0.082728\n",
      "Nd: 43, N: 465,trainingerror: 0.051191, testerror: 0.041224\n",
      "Nd: 43, N: 540,trainingerror: 0.034979, testerror: 0.053626\n",
      "Nd: 43, N: 627,trainingerror: 0.040601, testerror: 0.055760\n",
      "Nd: 43, N: 729,trainingerror: 0.057151, testerror: 0.047540\n",
      "Nd: 43, N: 846,trainingerror: 0.049848, testerror: 0.194124\n",
      "Nd: 43, N: 983,trainingerror: 0.057950, testerror: 0.047156\n",
      "Nd: 43, N: 1142,trainingerror: 0.059101, testerror: 0.046667\n",
      "Nd: 43, N: 1326,trainingerror: 0.077962, testerror: 0.063408\n",
      "Nd: 43, N: 1541,trainingerror: 0.043598, testerror: 0.036934\n",
      "Nd: 43, N: 1789,trainingerror: 0.063468, testerror: 0.073979\n",
      "Nd: 43, N: 2078,trainingerror: 0.044081, testerror: 0.054921\n",
      "Nd: 43, N: 2414,trainingerror: 0.060932, testerror: 0.051264\n",
      "Nd: 43, N: 2804,trainingerror: 0.073457, testerror: 0.090418\n",
      "Nd: 43, N: 3257,trainingerror: 0.053244, testerror: 0.060611\n",
      "Nd: 43, N: 3783,trainingerror: 0.048796, testerror: 0.048869\n",
      "Nd: 43, N: 4395,trainingerror: 0.067090, testerror: 0.059812\n",
      "Nd: 43, N: 5105,trainingerror: 0.047956, testerror: 0.059655\n",
      "Nd: 43, N: 5930,trainingerror: 0.055962, testerror: 0.063961\n",
      "Nd: 43, N: 6888,trainingerror: 0.069072, testerror: 0.122997\n",
      "Nd: 50, N: 20,trainingerror: 0.000000, testerror: 0.108349\n",
      "Nd: 50, N: 24,trainingerror: 0.000050, testerror: 1.051305\n",
      "Nd: 50, N: 27,trainingerror: 0.040996, testerror: 0.170482\n",
      "Nd: 50, N: 32,trainingerror: 0.000000, testerror: 0.073764\n",
      "Nd: 50, N: 37,trainingerror: 0.006439, testerror: 0.170815\n",
      "Nd: 50, N: 43,trainingerror: 0.030990, testerror: 0.139796\n",
      "Nd: 50, N: 50,trainingerror: 0.006582, testerror: 0.028556\n",
      "Nd: 50, N: 58,trainingerror: 0.001317, testerror: 0.107793\n",
      "Nd: 50, N: 67,trainingerror: 0.027481, testerror: 0.036188\n",
      "Nd: 50, N: 78,trainingerror: 0.009743, testerror: 0.082593\n",
      "Nd: 50, N: 90,trainingerror: 0.059619, testerror: 0.056981\n",
      "Nd: 50, N: 104,trainingerror: 0.009528, testerror: 0.077019\n",
      "Nd: 50, N: 121,trainingerror: 0.035192, testerror: 0.081029\n",
      "Nd: 50, N: 141,trainingerror: 0.024517, testerror: 0.040994\n",
      "Nd: 50, N: 163,trainingerror: 0.020598, testerror: 0.030221\n",
      "Nd: 50, N: 190,trainingerror: 0.037815, testerror: 0.049576\n",
      "Nd: 50, N: 220,trainingerror: 0.040246, testerror: 0.044910\n",
      "Nd: 50, N: 256,trainingerror: 0.026960, testerror: 0.046073\n",
      "Nd: 50, N: 297,trainingerror: 0.019271, testerror: 0.248738\n",
      "Nd: 50, N: 345,trainingerror: 0.050247, testerror: 0.083478\n",
      "Nd: 50, N: 400,trainingerror: 0.064076, testerror: 0.134646\n",
      "Nd: 50, N: 465,trainingerror: 0.036010, testerror: 0.091310\n",
      "Nd: 50, N: 540,trainingerror: 0.033029, testerror: 0.121908\n",
      "Nd: 50, N: 627,trainingerror: 0.047299, testerror: 0.076774\n",
      "Nd: 50, N: 729,trainingerror: 0.051112, testerror: 0.040322\n",
      "Nd: 50, N: 846,trainingerror: 0.040603, testerror: 0.032740\n",
      "Nd: 50, N: 983,trainingerror: 0.039376, testerror: 0.108821\n",
      "Nd: 50, N: 1142,trainingerror: 0.071815, testerror: 0.063406\n",
      "Nd: 50, N: 1326,trainingerror: 0.055695, testerror: 0.055936\n",
      "Nd: 50, N: 1541,trainingerror: 0.052662, testerror: 0.042741\n",
      "Nd: 50, N: 1789,trainingerror: 0.051994, testerror: 0.092165\n",
      "Nd: 50, N: 2078,trainingerror: 0.044727, testerror: 0.054804\n",
      "Nd: 50, N: 2414,trainingerror: 0.065225, testerror: 0.043323\n",
      "Nd: 50, N: 2804,trainingerror: 0.044520, testerror: 0.055502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 50, N: 3257,trainingerror: 0.065162, testerror: 0.082657\n",
      "Nd: 50, N: 3783,trainingerror: 0.051512, testerror: 0.072338\n",
      "Nd: 50, N: 4395,trainingerror: 0.041818, testerror: 0.041024\n",
      "Nd: 50, N: 5105,trainingerror: 0.050864, testerror: 0.050534\n",
      "Nd: 50, N: 5930,trainingerror: 0.055303, testerror: 0.059875\n",
      "Nd: 50, N: 6888,trainingerror: 0.053910, testerror: 0.082031\n",
      "Nd: 58, N: 20,trainingerror: 0.000000, testerror: 0.028493\n",
      "Nd: 58, N: 24,trainingerror: 0.017589, testerror: 0.309471\n",
      "Nd: 58, N: 27,trainingerror: 0.018680, testerror: 0.123098\n",
      "Nd: 58, N: 32,trainingerror: 0.000000, testerror: 0.078967\n",
      "Nd: 58, N: 37,trainingerror: 0.000078, testerror: 0.246641\n",
      "Nd: 58, N: 43,trainingerror: 0.001109, testerror: 0.187677\n",
      "Nd: 58, N: 50,trainingerror: 0.001161, testerror: 0.045996\n",
      "Nd: 58, N: 58,trainingerror: 0.003052, testerror: 0.121493\n",
      "Nd: 58, N: 67,trainingerror: 0.009259, testerror: 0.103503\n",
      "Nd: 58, N: 78,trainingerror: 0.008490, testerror: 0.133413\n",
      "Nd: 58, N: 90,trainingerror: 0.007072, testerror: 0.025445\n",
      "Nd: 58, N: 104,trainingerror: 0.015898, testerror: 0.032845\n",
      "Nd: 58, N: 121,trainingerror: 0.037007, testerror: 0.272927\n",
      "Nd: 58, N: 141,trainingerror: 0.029531, testerror: 0.057180\n",
      "Nd: 58, N: 163,trainingerror: 0.028887, testerror: 0.776481\n",
      "Nd: 58, N: 190,trainingerror: 0.022324, testerror: 0.035054\n",
      "Nd: 58, N: 220,trainingerror: 0.035106, testerror: 0.061175\n",
      "Nd: 58, N: 256,trainingerror: 0.029107, testerror: 0.056170\n",
      "Nd: 58, N: 297,trainingerror: 0.025538, testerror: 0.044821\n",
      "Nd: 58, N: 345,trainingerror: 0.045590, testerror: 0.039234\n",
      "Nd: 58, N: 400,trainingerror: 0.024836, testerror: 0.049232\n",
      "Nd: 58, N: 465,trainingerror: 0.054749, testerror: 0.046515\n",
      "Nd: 58, N: 540,trainingerror: 0.064303, testerror: 0.052588\n",
      "Nd: 58, N: 627,trainingerror: 0.061018, testerror: 0.052596\n",
      "Nd: 58, N: 729,trainingerror: 0.044475, testerror: 0.041758\n",
      "Nd: 58, N: 846,trainingerror: 0.045918, testerror: 0.029413\n",
      "Nd: 58, N: 983,trainingerror: 0.077805, testerror: 0.048785\n",
      "Nd: 58, N: 1142,trainingerror: 0.048721, testerror: 0.051569\n",
      "Nd: 58, N: 1326,trainingerror: 0.036227, testerror: 0.101055\n",
      "Nd: 58, N: 1541,trainingerror: 0.056856, testerror: 0.076697\n",
      "Nd: 58, N: 1789,trainingerror: 0.047617, testerror: 0.060295\n",
      "Nd: 58, N: 2078,trainingerror: 0.036124, testerror: 0.036828\n",
      "Nd: 58, N: 2414,trainingerror: 0.033970, testerror: 0.041147\n",
      "Nd: 58, N: 2804,trainingerror: 0.045035, testerror: 0.048722\n",
      "Nd: 58, N: 3257,trainingerror: 0.043609, testerror: 0.080548\n",
      "Nd: 58, N: 3783,trainingerror: 0.039762, testerror: 0.037785\n",
      "Nd: 58, N: 4395,trainingerror: 0.051740, testerror: 0.045951\n",
      "Nd: 58, N: 5105,trainingerror: 0.059793, testerror: 0.053651\n",
      "Nd: 58, N: 5930,trainingerror: 0.037301, testerror: 0.042694\n",
      "Nd: 58, N: 6888,trainingerror: 0.044644, testerror: 0.037864\n",
      "Nd: 67, N: 20,trainingerror: 0.006066, testerror: 0.033340\n",
      "Nd: 67, N: 24,trainingerror: 0.000002, testerror: 0.032266\n",
      "Nd: 67, N: 27,trainingerror: 0.000348, testerror: 0.131131\n",
      "Nd: 67, N: 32,trainingerror: 0.000000, testerror: 0.328178\n",
      "Nd: 67, N: 37,trainingerror: 0.001496, testerror: 0.080715\n",
      "Nd: 67, N: 43,trainingerror: 0.000020, testerror: 0.080028\n",
      "Nd: 67, N: 50,trainingerror: 0.003980, testerror: 0.068660\n",
      "Nd: 67, N: 58,trainingerror: 0.004653, testerror: 0.150965\n",
      "Nd: 67, N: 67,trainingerror: 0.001256, testerror: 0.068147\n",
      "Nd: 67, N: 78,trainingerror: 0.000881, testerror: 0.128209\n",
      "Nd: 67, N: 90,trainingerror: 0.006451, testerror: 0.116920\n",
      "Nd: 67, N: 104,trainingerror: 0.012868, testerror: 0.138980\n",
      "Nd: 67, N: 121,trainingerror: 0.029081, testerror: 0.185695\n",
      "Nd: 67, N: 141,trainingerror: 0.073628, testerror: 0.104154\n",
      "Nd: 67, N: 163,trainingerror: 0.015500, testerror: 0.131011\n",
      "Nd: 67, N: 190,trainingerror: 0.024615, testerror: 0.046307\n",
      "Nd: 67, N: 220,trainingerror: 0.023933, testerror: 0.115708\n",
      "Nd: 67, N: 256,trainingerror: 0.019717, testerror: 0.086944\n",
      "Nd: 67, N: 297,trainingerror: 0.037630, testerror: 0.070592\n",
      "Nd: 67, N: 345,trainingerror: 0.038100, testerror: 0.054224\n",
      "Nd: 67, N: 400,trainingerror: 0.029666, testerror: 0.061612\n",
      "Nd: 67, N: 465,trainingerror: 0.026301, testerror: 0.069381\n",
      "Nd: 67, N: 540,trainingerror: 0.039605, testerror: 0.050186\n",
      "Nd: 67, N: 627,trainingerror: 0.066082, testerror: 0.045437\n",
      "Nd: 67, N: 729,trainingerror: 0.035261, testerror: 0.066860\n",
      "Nd: 67, N: 846,trainingerror: 0.036440, testerror: 0.052426\n",
      "Nd: 67, N: 983,trainingerror: 0.066460, testerror: 0.047968\n",
      "Nd: 67, N: 1142,trainingerror: 0.041052, testerror: 0.063999\n",
      "Nd: 67, N: 1326,trainingerror: 0.042200, testerror: 0.067927\n",
      "Nd: 67, N: 1541,trainingerror: 0.041869, testerror: 0.040096\n",
      "Nd: 67, N: 1789,trainingerror: 0.043708, testerror: 0.074426\n",
      "Nd: 67, N: 2078,trainingerror: 0.061498, testerror: 0.041952\n",
      "Nd: 67, N: 2414,trainingerror: 0.033829, testerror: 0.041444\n",
      "Nd: 67, N: 2804,trainingerror: 0.037206, testerror: 0.046172\n",
      "Nd: 67, N: 3257,trainingerror: 0.035934, testerror: 0.049758\n",
      "Nd: 67, N: 3783,trainingerror: 0.033171, testerror: 0.031862\n",
      "Nd: 67, N: 4395,trainingerror: 0.045002, testerror: 0.058648\n",
      "Nd: 67, N: 5105,trainingerror: 0.047828, testerror: 0.044925\n",
      "Nd: 67, N: 5930,trainingerror: 0.032307, testerror: 0.030739\n",
      "Nd: 67, N: 6888,trainingerror: 0.044115, testerror: 0.043318\n",
      "Nd: 78, N: 20,trainingerror: 0.000023, testerror: 0.028887\n",
      "Nd: 78, N: 24,trainingerror: 0.000000, testerror: 0.106807\n",
      "Nd: 78, N: 27,trainingerror: 0.001943, testerror: 0.089911\n",
      "Nd: 78, N: 32,trainingerror: 0.003360, testerror: 0.147122\n",
      "Nd: 78, N: 37,trainingerror: 0.000924, testerror: 0.061942\n",
      "Nd: 78, N: 43,trainingerror: 0.000499, testerror: 0.255188\n",
      "Nd: 78, N: 50,trainingerror: 0.006631, testerror: 0.214317\n",
      "Nd: 78, N: 58,trainingerror: 0.004341, testerror: 0.107981\n",
      "Nd: 78, N: 67,trainingerror: 0.001146, testerror: 0.123591\n",
      "Nd: 78, N: 78,trainingerror: 0.003597, testerror: 0.089745\n",
      "Nd: 78, N: 90,trainingerror: 0.006511, testerror: 0.273699\n",
      "Nd: 78, N: 104,trainingerror: 0.010715, testerror: 0.231426\n",
      "Nd: 78, N: 121,trainingerror: 0.012827, testerror: 0.092225\n",
      "Nd: 78, N: 141,trainingerror: 0.031955, testerror: 0.165643\n",
      "Nd: 78, N: 163,trainingerror: 0.036685, testerror: 0.054380\n",
      "Nd: 78, N: 190,trainingerror: 0.017709, testerror: 0.083011\n",
      "Nd: 78, N: 220,trainingerror: 0.021423, testerror: 0.079971\n",
      "Nd: 78, N: 256,trainingerror: 0.039024, testerror: 0.098311\n",
      "Nd: 78, N: 297,trainingerror: 0.067304, testerror: 0.427621\n",
      "Nd: 78, N: 345,trainingerror: 0.033427, testerror: 0.050249\n",
      "Nd: 78, N: 400,trainingerror: 0.039534, testerror: 0.071462\n",
      "Nd: 78, N: 465,trainingerror: 0.028545, testerror: 0.043172\n",
      "Nd: 78, N: 540,trainingerror: 0.032865, testerror: 0.061839\n",
      "Nd: 78, N: 627,trainingerror: 0.026916, testerror: 0.042160\n",
      "Nd: 78, N: 729,trainingerror: 0.025663, testerror: 0.133760\n",
      "Nd: 78, N: 846,trainingerror: 0.041158, testerror: 0.142253\n",
      "Nd: 78, N: 983,trainingerror: 0.056852, testerror: 0.092875\n",
      "Nd: 78, N: 1142,trainingerror: 0.029568, testerror: 0.070550\n",
      "Nd: 78, N: 1326,trainingerror: 0.054408, testerror: 0.043187\n",
      "Nd: 78, N: 1541,trainingerror: 0.079151, testerror: 0.068141\n",
      "Nd: 78, N: 1789,trainingerror: 0.039553, testerror: 0.059634\n",
      "Nd: 78, N: 2078,trainingerror: 0.070277, testerror: 0.047797\n",
      "Nd: 78, N: 2414,trainingerror: 0.032849, testerror: 0.045175\n",
      "Nd: 78, N: 2804,trainingerror: 0.053996, testerror: 0.072489\n",
      "Nd: 78, N: 3257,trainingerror: 0.037634, testerror: 0.037386\n",
      "Nd: 78, N: 3783,trainingerror: 0.055216, testerror: 0.045643\n",
      "Nd: 78, N: 4395,trainingerror: 0.050939, testerror: 0.046350\n",
      "Nd: 78, N: 5105,trainingerror: 0.042943, testerror: 0.039576\n",
      "Nd: 78, N: 5930,trainingerror: 0.053056, testerror: 0.059298\n",
      "Nd: 78, N: 6888,trainingerror: 0.058875, testerror: 0.057310\n",
      "Nd: 90, N: 20,trainingerror: 0.000000, testerror: 0.031996\n",
      "Nd: 90, N: 24,trainingerror: 0.000000, testerror: 0.272228\n",
      "Nd: 90, N: 27,trainingerror: 0.013388, testerror: 0.025312\n",
      "Nd: 90, N: 32,trainingerror: 0.000000, testerror: 0.154819\n",
      "Nd: 90, N: 37,trainingerror: 0.000000, testerror: 0.104917\n",
      "Nd: 90, N: 43,trainingerror: 0.000058, testerror: 0.114698\n",
      "Nd: 90, N: 50,trainingerror: 0.001162, testerror: 0.241633\n",
      "Nd: 90, N: 58,trainingerror: 0.000086, testerror: 0.449621\n",
      "Nd: 90, N: 67,trainingerror: 0.000477, testerror: 0.130373\n",
      "Nd: 90, N: 78,trainingerror: 0.013785, testerror: 0.124822\n",
      "Nd: 90, N: 90,trainingerror: 0.000906, testerror: 0.052304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 90, N: 104,trainingerror: 0.005529, testerror: 0.232546\n",
      "Nd: 90, N: 121,trainingerror: 0.011154, testerror: 0.138508\n",
      "Nd: 90, N: 141,trainingerror: 0.028418, testerror: 0.286925\n",
      "Nd: 90, N: 163,trainingerror: 0.013474, testerror: 0.089088\n",
      "Nd: 90, N: 190,trainingerror: 0.012321, testerror: 0.207343\n",
      "Nd: 90, N: 220,trainingerror: 0.013638, testerror: 0.110854\n",
      "Nd: 90, N: 256,trainingerror: 0.016003, testerror: 0.078131\n",
      "Nd: 90, N: 297,trainingerror: 0.035927, testerror: 0.103374\n",
      "Nd: 90, N: 345,trainingerror: 0.068670, testerror: 0.066773\n",
      "Nd: 90, N: 400,trainingerror: 0.022279, testerror: 0.055580\n",
      "Nd: 90, N: 465,trainingerror: 0.019777, testerror: 0.038717\n",
      "Nd: 90, N: 540,trainingerror: 0.026635, testerror: 0.054902\n",
      "Nd: 90, N: 627,trainingerror: 0.033915, testerror: 0.067722\n",
      "Nd: 90, N: 729,trainingerror: 0.030619, testerror: 0.045082\n",
      "Nd: 90, N: 846,trainingerror: 0.042003, testerror: 0.042036\n",
      "Nd: 90, N: 983,trainingerror: 0.033270, testerror: 0.094068\n",
      "Nd: 90, N: 1142,trainingerror: 0.038762, testerror: 0.069590\n",
      "Nd: 90, N: 1326,trainingerror: 0.030850, testerror: 0.036124\n",
      "Nd: 90, N: 1541,trainingerror: 0.035497, testerror: 0.039693\n",
      "Nd: 90, N: 1789,trainingerror: 0.035678, testerror: 0.036820\n",
      "Nd: 90, N: 2078,trainingerror: 0.044581, testerror: 0.067389\n",
      "Nd: 90, N: 2414,trainingerror: 0.038987, testerror: 0.155188\n",
      "Nd: 90, N: 2804,trainingerror: 0.043537, testerror: 0.042226\n",
      "Nd: 90, N: 3257,trainingerror: 0.042204, testerror: 0.045243\n",
      "Nd: 90, N: 3783,trainingerror: 0.038576, testerror: 0.034235\n",
      "Nd: 90, N: 4395,trainingerror: 0.064599, testerror: 0.055907\n",
      "Nd: 90, N: 5105,trainingerror: 0.034841, testerror: 0.034555\n",
      "Nd: 90, N: 5930,trainingerror: 0.043692, testerror: 0.057849\n",
      "Nd: 90, N: 6888,trainingerror: 0.053979, testerror: 0.052498\n",
      "Nd: 104, N: 20,trainingerror: 0.000005, testerror: 0.110839\n",
      "Nd: 104, N: 24,trainingerror: 0.000000, testerror: 0.064416\n",
      "Nd: 104, N: 27,trainingerror: 0.000000, testerror: 0.076926\n",
      "Nd: 104, N: 32,trainingerror: 0.000000, testerror: 0.332916\n",
      "Nd: 104, N: 37,trainingerror: 0.000003, testerror: 0.054871\n",
      "Nd: 104, N: 43,trainingerror: 0.003525, testerror: 0.045150\n",
      "Nd: 104, N: 50,trainingerror: 0.000002, testerror: 0.083438\n",
      "Nd: 104, N: 58,trainingerror: 0.000005, testerror: 0.154493\n",
      "Nd: 104, N: 67,trainingerror: 0.000014, testerror: 0.128598\n",
      "Nd: 104, N: 78,trainingerror: 0.000012, testerror: 0.122051\n",
      "Nd: 104, N: 90,trainingerror: 0.000269, testerror: 0.211309\n",
      "Nd: 104, N: 104,trainingerror: 0.000380, testerror: 0.153195\n",
      "Nd: 104, N: 121,trainingerror: 0.007669, testerror: 0.201762\n",
      "Nd: 104, N: 141,trainingerror: 0.005612, testerror: 0.157175\n",
      "Nd: 104, N: 163,trainingerror: 0.017602, testerror: 0.138202\n",
      "Nd: 104, N: 190,trainingerror: 0.024129, testerror: 0.074405\n",
      "Nd: 104, N: 220,trainingerror: 0.020985, testerror: 0.132760\n",
      "Nd: 104, N: 256,trainingerror: 0.028404, testerror: 0.117700\n",
      "Nd: 104, N: 297,trainingerror: 0.015935, testerror: 0.095679\n",
      "Nd: 104, N: 345,trainingerror: 0.017617, testerror: 0.063498\n",
      "Nd: 104, N: 400,trainingerror: 0.026759, testerror: 0.047646\n",
      "Nd: 104, N: 465,trainingerror: 0.034079, testerror: 0.082133\n",
      "Nd: 104, N: 540,trainingerror: 0.026712, testerror: 0.056504\n",
      "Nd: 104, N: 627,trainingerror: 0.044406, testerror: 0.043124\n",
      "Nd: 104, N: 729,trainingerror: 0.084081, testerror: 0.059260\n",
      "Nd: 104, N: 846,trainingerror: 0.028057, testerror: 0.060838\n",
      "Nd: 104, N: 983,trainingerror: 0.026310, testerror: 0.046780\n",
      "Nd: 104, N: 1142,trainingerror: 0.035056, testerror: 0.047889\n",
      "Nd: 104, N: 1326,trainingerror: 0.028931, testerror: 0.041384\n",
      "Nd: 104, N: 1541,trainingerror: 0.032174, testerror: 0.069624\n",
      "Nd: 104, N: 1789,trainingerror: 0.032515, testerror: 0.042777\n",
      "Nd: 104, N: 2078,trainingerror: 0.033047, testerror: 0.050872\n",
      "Nd: 104, N: 2414,trainingerror: 0.036773, testerror: 0.037133\n",
      "Nd: 104, N: 2804,trainingerror: 0.032621, testerror: 0.032443\n",
      "Nd: 104, N: 3257,trainingerror: 0.034847, testerror: 0.039363\n",
      "Nd: 104, N: 3783,trainingerror: 0.031538, testerror: 0.031803\n",
      "Nd: 104, N: 4395,trainingerror: 0.048419, testerror: 0.062888\n",
      "Nd: 104, N: 5105,trainingerror: 0.034593, testerror: 0.048009\n",
      "Nd: 104, N: 5930,trainingerror: 0.035906, testerror: 0.041751\n",
      "Nd: 104, N: 6888,trainingerror: 0.030636, testerror: 0.031968\n",
      "Nd: 121, N: 20,trainingerror: 0.000000, testerror: 0.068798\n",
      "Nd: 121, N: 24,trainingerror: 0.000011, testerror: 0.114001\n",
      "Nd: 121, N: 27,trainingerror: 0.000011, testerror: 0.021062\n",
      "Nd: 121, N: 32,trainingerror: 0.000000, testerror: 0.044643\n",
      "Nd: 121, N: 37,trainingerror: 0.000000, testerror: 0.032191\n",
      "Nd: 121, N: 43,trainingerror: 0.000000, testerror: 0.013010\n",
      "Nd: 121, N: 50,trainingerror: 0.000000, testerror: 0.281025\n",
      "Nd: 121, N: 58,trainingerror: 0.001264, testerror: 0.076644\n",
      "Nd: 121, N: 67,trainingerror: 0.000255, testerror: 0.057384\n",
      "Nd: 121, N: 78,trainingerror: 0.001342, testerror: 0.111843\n",
      "Nd: 121, N: 90,trainingerror: 0.000009, testerror: 0.168520\n",
      "Nd: 121, N: 104,trainingerror: 0.002824, testerror: 0.143557\n",
      "Nd: 121, N: 121,trainingerror: 0.000429, testerror: 0.118541\n",
      "Nd: 121, N: 141,trainingerror: 0.000425, testerror: 0.097728\n",
      "Nd: 121, N: 163,trainingerror: 0.045209, testerror: 0.145117\n",
      "Nd: 121, N: 190,trainingerror: 0.010969, testerror: 0.196737\n",
      "Nd: 121, N: 220,trainingerror: 0.011163, testerror: 0.240382\n",
      "Nd: 121, N: 256,trainingerror: 0.013882, testerror: 0.140333\n",
      "Nd: 121, N: 297,trainingerror: 0.013757, testerror: 0.088514\n",
      "Nd: 121, N: 345,trainingerror: 0.026348, testerror: 0.067310\n",
      "Nd: 121, N: 400,trainingerror: 0.025610, testerror: 0.106419\n",
      "Nd: 121, N: 465,trainingerror: 0.034364, testerror: 0.042085\n",
      "Nd: 121, N: 540,trainingerror: 0.030842, testerror: 0.081351\n",
      "Nd: 121, N: 627,trainingerror: 0.031906, testerror: 0.075619\n",
      "Nd: 121, N: 729,trainingerror: 0.027847, testerror: 0.124050\n",
      "Nd: 121, N: 846,trainingerror: 0.043135, testerror: 0.120433\n",
      "Nd: 121, N: 983,trainingerror: 0.029454, testerror: 0.059349\n",
      "Nd: 121, N: 1142,trainingerror: 0.034520, testerror: 0.041509\n",
      "Nd: 121, N: 1326,trainingerror: 0.045839, testerror: 0.121974\n",
      "Nd: 121, N: 1541,trainingerror: 0.032734, testerror: 0.058604\n",
      "Nd: 121, N: 1789,trainingerror: 0.035786, testerror: 0.031688\n",
      "Nd: 121, N: 2078,trainingerror: 0.069077, testerror: 0.076032\n",
      "Nd: 121, N: 2414,trainingerror: 0.032587, testerror: 0.033737\n",
      "Nd: 121, N: 2804,trainingerror: 0.031908, testerror: 0.029805\n",
      "Nd: 121, N: 3257,trainingerror: 0.030382, testerror: 0.031225\n",
      "Nd: 121, N: 3783,trainingerror: 0.037929, testerror: 0.052308\n",
      "Nd: 121, N: 4395,trainingerror: 0.031825, testerror: 0.051002\n",
      "Nd: 121, N: 5105,trainingerror: 0.030525, testerror: 0.038053\n",
      "Nd: 121, N: 5930,trainingerror: 0.033423, testerror: 0.033041\n",
      "Nd: 121, N: 6888,trainingerror: 0.034176, testerror: 0.038765\n",
      "Nd: 141, N: 20,trainingerror: 0.000000, testerror: 0.198980\n",
      "Nd: 141, N: 24,trainingerror: 0.000000, testerror: 0.132210\n",
      "Nd: 141, N: 27,trainingerror: 0.000000, testerror: 0.020060\n",
      "Nd: 141, N: 32,trainingerror: 0.000001, testerror: 0.076521\n",
      "Nd: 141, N: 37,trainingerror: 0.000000, testerror: 0.041983\n",
      "Nd: 141, N: 43,trainingerror: 0.000000, testerror: 0.122650\n",
      "Nd: 141, N: 50,trainingerror: 0.000007, testerror: 0.249278\n",
      "Nd: 141, N: 58,trainingerror: 0.000005, testerror: 0.167882\n",
      "Nd: 141, N: 67,trainingerror: 0.000258, testerror: 0.151959\n",
      "Nd: 141, N: 78,trainingerror: 0.000000, testerror: 0.090518\n",
      "Nd: 141, N: 90,trainingerror: 0.000030, testerror: 0.053000\n",
      "Nd: 141, N: 104,trainingerror: 0.000470, testerror: 0.141759\n",
      "Nd: 141, N: 121,trainingerror: 0.000270, testerror: 0.143719\n",
      "Nd: 141, N: 141,trainingerror: 0.000104, testerror: 0.112276\n",
      "Nd: 141, N: 163,trainingerror: 0.000233, testerror: 0.106776\n",
      "Nd: 141, N: 190,trainingerror: 0.003544, testerror: 0.077941\n",
      "Nd: 141, N: 220,trainingerror: 0.009635, testerror: 0.127037\n",
      "Nd: 141, N: 256,trainingerror: 0.007915, testerror: 0.096203\n",
      "Nd: 141, N: 297,trainingerror: 0.050237, testerror: 0.075212\n",
      "Nd: 141, N: 345,trainingerror: 0.021558, testerror: 0.061905\n",
      "Nd: 141, N: 400,trainingerror: 0.023158, testerror: 0.111913\n",
      "Nd: 141, N: 465,trainingerror: 0.021743, testerror: 0.059471\n",
      "Nd: 141, N: 540,trainingerror: 0.018544, testerror: 0.054914\n",
      "Nd: 141, N: 627,trainingerror: 0.027503, testerror: 0.057022\n",
      "Nd: 141, N: 729,trainingerror: 0.039806, testerror: 0.082945\n",
      "Nd: 141, N: 846,trainingerror: 0.023622, testerror: 0.046458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 141, N: 983,trainingerror: 0.034216, testerror: 0.057390\n",
      "Nd: 141, N: 1142,trainingerror: 0.030714, testerror: 0.044454\n",
      "Nd: 141, N: 1326,trainingerror: 0.028065, testerror: 0.031822\n",
      "Nd: 141, N: 1541,trainingerror: 0.028191, testerror: 0.038697\n",
      "Nd: 141, N: 1789,trainingerror: 0.026950, testerror: 0.041528\n",
      "Nd: 141, N: 2078,trainingerror: 0.029694, testerror: 0.034149\n",
      "Nd: 141, N: 2414,trainingerror: 0.025196, testerror: 0.032384\n",
      "Nd: 141, N: 2804,trainingerror: 0.026658, testerror: 0.030608\n",
      "Nd: 141, N: 3257,trainingerror: 0.030564, testerror: 0.030323\n",
      "Nd: 141, N: 3783,trainingerror: 0.049541, testerror: 0.055577\n",
      "Nd: 141, N: 4395,trainingerror: 0.034541, testerror: 0.037393\n",
      "Nd: 141, N: 5105,trainingerror: 0.029954, testerror: 0.044682\n",
      "Nd: 141, N: 5930,trainingerror: 0.032595, testerror: 0.027988\n",
      "Nd: 141, N: 6888,trainingerror: 0.034284, testerror: 0.039363\n",
      "Nd: 163, N: 20,trainingerror: 0.000000, testerror: 0.047492\n",
      "Nd: 163, N: 24,trainingerror: 0.000000, testerror: 0.060092\n",
      "Nd: 163, N: 27,trainingerror: 0.000000, testerror: 0.078079\n",
      "Nd: 163, N: 32,trainingerror: 0.000000, testerror: 0.034514\n",
      "Nd: 163, N: 37,trainingerror: 0.000000, testerror: 0.089519\n",
      "Nd: 163, N: 43,trainingerror: 0.000000, testerror: 0.055892\n",
      "Nd: 163, N: 50,trainingerror: 0.000013, testerror: 0.033090\n",
      "Nd: 163, N: 58,trainingerror: 0.000000, testerror: 0.163496\n",
      "Nd: 163, N: 67,trainingerror: 0.002046, testerror: 0.178847\n",
      "Nd: 163, N: 78,trainingerror: 0.000000, testerror: 0.492290\n",
      "Nd: 163, N: 90,trainingerror: 0.000036, testerror: 0.243367\n",
      "Nd: 163, N: 104,trainingerror: 0.000103, testerror: 0.070456\n",
      "Nd: 163, N: 121,trainingerror: 0.001264, testerror: 0.242134\n",
      "Nd: 163, N: 141,trainingerror: 0.000108, testerror: 0.187578\n",
      "Nd: 163, N: 163,trainingerror: 0.004290, testerror: 0.159444\n",
      "Nd: 163, N: 190,trainingerror: 0.002410, testerror: 0.199467\n",
      "Nd: 163, N: 220,trainingerror: 0.001943, testerror: 0.157191\n",
      "Nd: 163, N: 256,trainingerror: 0.014723, testerror: 0.154820\n",
      "Nd: 163, N: 297,trainingerror: 0.006854, testerror: 0.098577\n",
      "Nd: 163, N: 345,trainingerror: 0.021189, testerror: 0.043589\n",
      "Nd: 163, N: 400,trainingerror: 0.031956, testerror: 0.155769\n",
      "Nd: 163, N: 465,trainingerror: 0.023365, testerror: 0.072246\n",
      "Nd: 163, N: 540,trainingerror: 0.018844, testerror: 0.098625\n",
      "Nd: 163, N: 627,trainingerror: 0.023326, testerror: 0.174163\n",
      "Nd: 163, N: 729,trainingerror: 0.034130, testerror: 0.043275\n",
      "Nd: 163, N: 846,trainingerror: 0.053285, testerror: 0.070671\n",
      "Nd: 163, N: 983,trainingerror: 0.028204, testerror: 0.048426\n",
      "Nd: 163, N: 1142,trainingerror: 0.032456, testerror: 0.085977\n",
      "Nd: 163, N: 1326,trainingerror: 0.028357, testerror: 0.044779\n",
      "Nd: 163, N: 1541,trainingerror: 0.029497, testerror: 0.075118\n",
      "Nd: 163, N: 1789,trainingerror: 0.031119, testerror: 0.034385\n",
      "Nd: 163, N: 2078,trainingerror: 0.043129, testerror: 0.045813\n",
      "Nd: 163, N: 2414,trainingerror: 0.039065, testerror: 0.051534\n",
      "Nd: 163, N: 2804,trainingerror: 0.027445, testerror: 0.037251\n",
      "Nd: 163, N: 3257,trainingerror: 0.033610, testerror: 0.042384\n",
      "Nd: 163, N: 3783,trainingerror: 0.030597, testerror: 0.061194\n",
      "Nd: 163, N: 4395,trainingerror: 0.030506, testerror: 0.055950\n",
      "Nd: 163, N: 5105,trainingerror: 0.028442, testerror: 0.040299\n",
      "Nd: 163, N: 5930,trainingerror: 0.055629, testerror: 0.049343\n",
      "Nd: 163, N: 6888,trainingerror: 0.034894, testerror: 0.038696\n",
      "Nd: 190, N: 20,trainingerror: 0.000000, testerror: 0.269105\n",
      "Nd: 190, N: 24,trainingerror: 0.000000, testerror: 0.038007\n",
      "Nd: 190, N: 27,trainingerror: 0.000000, testerror: 0.036218\n",
      "Nd: 190, N: 32,trainingerror: 0.000000, testerror: 0.070280\n",
      "Nd: 190, N: 37,trainingerror: 0.000000, testerror: 0.112813\n",
      "Nd: 190, N: 43,trainingerror: 0.000002, testerror: 0.112920\n",
      "Nd: 190, N: 50,trainingerror: 0.000000, testerror: 0.072893\n",
      "Nd: 190, N: 58,trainingerror: 0.000000, testerror: 1.307192\n",
      "Nd: 190, N: 67,trainingerror: 0.000026, testerror: 0.047789\n",
      "Nd: 190, N: 78,trainingerror: 0.000000, testerror: 0.085069\n",
      "Nd: 190, N: 90,trainingerror: 0.000045, testerror: 0.113936\n",
      "Nd: 190, N: 104,trainingerror: 0.000000, testerror: 0.086410\n",
      "Nd: 190, N: 121,trainingerror: 0.000088, testerror: 0.076674\n",
      "Nd: 190, N: 141,trainingerror: 0.000043, testerror: 0.172973\n",
      "Nd: 190, N: 163,trainingerror: 0.000268, testerror: 0.095071\n",
      "Nd: 190, N: 190,trainingerror: 0.000748, testerror: 0.154230\n",
      "Nd: 190, N: 220,trainingerror: 0.004531, testerror: 0.098054\n",
      "Nd: 190, N: 256,trainingerror: 0.011559, testerror: 0.122075\n",
      "Nd: 190, N: 297,trainingerror: 0.008533, testerror: 0.081084\n",
      "Nd: 190, N: 345,trainingerror: 0.008269, testerror: 0.092341\n",
      "Nd: 190, N: 400,trainingerror: 0.011793, testerror: 0.099805\n",
      "Nd: 190, N: 465,trainingerror: 0.015672, testerror: 0.344005\n",
      "Nd: 190, N: 540,trainingerror: 0.018495, testerror: 0.101027\n",
      "Nd: 190, N: 627,trainingerror: 0.027142, testerror: 0.092060\n",
      "Nd: 190, N: 729,trainingerror: 0.017272, testerror: 0.058466\n",
      "Nd: 190, N: 846,trainingerror: 0.023728, testerror: 0.037228\n",
      "Nd: 190, N: 983,trainingerror: 0.027678, testerror: 0.050829\n",
      "Nd: 190, N: 1142,trainingerror: 0.022836, testerror: 0.057071\n",
      "Nd: 190, N: 1326,trainingerror: 0.024203, testerror: 0.040072\n",
      "Nd: 190, N: 1541,trainingerror: 0.042267, testerror: 0.047642\n",
      "Nd: 190, N: 1789,trainingerror: 0.024881, testerror: 0.029473\n",
      "Nd: 190, N: 2078,trainingerror: 0.039248, testerror: 0.034908\n",
      "Nd: 190, N: 2414,trainingerror: 0.028749, testerror: 0.036215\n",
      "Nd: 190, N: 2804,trainingerror: 0.025873, testerror: 0.029306\n",
      "Nd: 190, N: 3257,trainingerror: 0.031125, testerror: 0.033765\n",
      "Nd: 190, N: 3783,trainingerror: 0.030813, testerror: 0.030311\n",
      "Nd: 190, N: 4395,trainingerror: 0.029514, testerror: 0.037699\n",
      "Nd: 190, N: 5105,trainingerror: 0.030558, testerror: 0.033567\n",
      "Nd: 190, N: 5930,trainingerror: 0.026821, testerror: 0.028320\n",
      "Nd: 190, N: 6888,trainingerror: 0.029354, testerror: 0.035865\n",
      "Nd: 220, N: 20,trainingerror: 0.000000, testerror: 0.008338\n",
      "Nd: 220, N: 24,trainingerror: 0.000000, testerror: 0.035159\n",
      "Nd: 220, N: 27,trainingerror: 0.000000, testerror: 0.109837\n",
      "Nd: 220, N: 32,trainingerror: 0.000000, testerror: 0.038479\n",
      "Nd: 220, N: 37,trainingerror: 0.000000, testerror: 0.060485\n",
      "Nd: 220, N: 43,trainingerror: 0.000000, testerror: 0.023914\n",
      "Nd: 220, N: 50,trainingerror: 0.000000, testerror: 0.079734\n",
      "Nd: 220, N: 58,trainingerror: 0.000000, testerror: 0.096530\n",
      "Nd: 220, N: 67,trainingerror: 0.000000, testerror: 0.090968\n",
      "Nd: 220, N: 78,trainingerror: 0.000004, testerror: 0.030911\n",
      "Nd: 220, N: 90,trainingerror: 0.000000, testerror: 0.160813\n",
      "Nd: 220, N: 104,trainingerror: 0.000000, testerror: 0.109109\n",
      "Nd: 220, N: 121,trainingerror: 0.000000, testerror: 0.063397\n",
      "Nd: 220, N: 141,trainingerror: 0.000009, testerror: 0.217510\n",
      "Nd: 220, N: 163,trainingerror: 0.000142, testerror: 0.235892\n",
      "Nd: 220, N: 190,trainingerror: 0.000089, testerror: 0.136911\n",
      "Nd: 220, N: 220,trainingerror: 0.000554, testerror: 0.077303\n",
      "Nd: 220, N: 256,trainingerror: 0.001219, testerror: 0.072134\n",
      "Nd: 220, N: 297,trainingerror: 0.004375, testerror: 0.086905\n",
      "Nd: 220, N: 345,trainingerror: 0.005244, testerror: 0.129264\n",
      "Nd: 220, N: 400,trainingerror: 0.010898, testerror: 0.118520\n",
      "Nd: 220, N: 465,trainingerror: 0.009614, testerror: 0.080534\n",
      "Nd: 220, N: 540,trainingerror: 0.011142, testerror: 0.090948\n",
      "Nd: 220, N: 627,trainingerror: 0.017345, testerror: 0.123378\n",
      "Nd: 220, N: 729,trainingerror: 0.020357, testerror: 0.050626\n",
      "Nd: 220, N: 846,trainingerror: 0.027797, testerror: 0.125711\n",
      "Nd: 220, N: 983,trainingerror: 0.020672, testerror: 0.081932\n",
      "Nd: 220, N: 1142,trainingerror: 0.017787, testerror: 0.033597\n",
      "Nd: 220, N: 1326,trainingerror: 0.020561, testerror: 0.049974\n",
      "Nd: 220, N: 1541,trainingerror: 0.025844, testerror: 0.056897\n",
      "Nd: 220, N: 1789,trainingerror: 0.037241, testerror: 0.033462\n",
      "Nd: 220, N: 2078,trainingerror: 0.026561, testerror: 0.033076\n",
      "Nd: 220, N: 2414,trainingerror: 0.029744, testerror: 0.042061\n",
      "Nd: 220, N: 2804,trainingerror: 0.030042, testerror: 0.038556\n",
      "Nd: 220, N: 3257,trainingerror: 0.022919, testerror: 0.039546\n",
      "Nd: 220, N: 3783,trainingerror: 0.028790, testerror: 0.050573\n",
      "Nd: 220, N: 4395,trainingerror: 0.027053, testerror: 0.033032\n",
      "Nd: 220, N: 5105,trainingerror: 0.026260, testerror: 0.030141\n",
      "Nd: 220, N: 5930,trainingerror: 0.031296, testerror: 0.026977\n",
      "Nd: 220, N: 6888,trainingerror: 0.030132, testerror: 0.029451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 256, N: 20,trainingerror: 0.000000, testerror: 0.519391\n",
      "Nd: 256, N: 24,trainingerror: 0.000000, testerror: 0.057041\n",
      "Nd: 256, N: 27,trainingerror: 0.000000, testerror: 0.059122\n",
      "Nd: 256, N: 32,trainingerror: 0.000000, testerror: 0.031991\n",
      "Nd: 256, N: 37,trainingerror: 0.000000, testerror: 0.119989\n",
      "Nd: 256, N: 43,trainingerror: 0.000000, testerror: 0.076634\n",
      "Nd: 256, N: 50,trainingerror: 0.000000, testerror: 0.201271\n",
      "Nd: 256, N: 58,trainingerror: 0.000000, testerror: 0.102245\n",
      "Nd: 256, N: 67,trainingerror: 0.000000, testerror: 0.029764\n",
      "Nd: 256, N: 78,trainingerror: 0.000000, testerror: 0.040672\n",
      "Nd: 256, N: 90,trainingerror: 0.000788, testerror: 0.188784\n",
      "Nd: 256, N: 104,trainingerror: 0.000000, testerror: 0.168951\n",
      "Nd: 256, N: 121,trainingerror: 0.000050, testerror: 0.085190\n",
      "Nd: 256, N: 141,trainingerror: 0.000002, testerror: 0.074300\n",
      "Nd: 256, N: 163,trainingerror: 0.000056, testerror: 0.136053\n",
      "Nd: 256, N: 190,trainingerror: 0.000091, testerror: 0.199826\n",
      "Nd: 256, N: 220,trainingerror: 0.000266, testerror: 0.185277\n",
      "Nd: 256, N: 256,trainingerror: 0.000600, testerror: 0.145496\n",
      "Nd: 256, N: 297,trainingerror: 0.001217, testerror: 0.097845\n",
      "Nd: 256, N: 345,trainingerror: 0.004839, testerror: 0.076848\n",
      "Nd: 256, N: 400,trainingerror: 0.005478, testerror: 0.139665\n",
      "Nd: 256, N: 465,trainingerror: 0.011149, testerror: 0.113885\n",
      "Nd: 256, N: 540,trainingerror: 0.008248, testerror: 0.084656\n",
      "Nd: 256, N: 627,trainingerror: 0.020247, testerror: 0.078711\n",
      "Nd: 256, N: 729,trainingerror: 0.014393, testerror: 0.092266\n",
      "Nd: 256, N: 846,trainingerror: 0.026564, testerror: 0.102234\n",
      "Nd: 256, N: 983,trainingerror: 0.019478, testerror: 0.077901\n",
      "Nd: 256, N: 1142,trainingerror: 0.024570, testerror: 0.041339\n",
      "Nd: 256, N: 1326,trainingerror: 0.024439, testerror: 0.044249\n",
      "Nd: 256, N: 1541,trainingerror: 0.032943, testerror: 0.049461\n",
      "Nd: 256, N: 1789,trainingerror: 0.022961, testerror: 0.040469\n",
      "Nd: 256, N: 2078,trainingerror: 0.030930, testerror: 0.059807\n",
      "Nd: 256, N: 2414,trainingerror: 0.029781, testerror: 0.042211\n",
      "Nd: 256, N: 2804,trainingerror: 0.029377, testerror: 0.040607\n",
      "Nd: 256, N: 3257,trainingerror: 0.025222, testerror: 0.033073\n",
      "Nd: 256, N: 3783,trainingerror: 0.027792, testerror: 0.051450\n",
      "Nd: 256, N: 4395,trainingerror: 0.028606, testerror: 0.028925\n",
      "Nd: 256, N: 5105,trainingerror: 0.029302, testerror: 0.031562\n",
      "Nd: 256, N: 5930,trainingerror: 0.030413, testerror: 0.044556\n",
      "Nd: 256, N: 6888,trainingerror: 0.027148, testerror: 0.031719\n",
      "Nd: 297, N: 20,trainingerror: 0.000000, testerror: 0.144570\n",
      "Nd: 297, N: 24,trainingerror: 0.000000, testerror: 0.083500\n",
      "Nd: 297, N: 27,trainingerror: 0.000000, testerror: 0.316202\n",
      "Nd: 297, N: 32,trainingerror: 0.000000, testerror: 0.139867\n",
      "Nd: 297, N: 37,trainingerror: 0.000000, testerror: 0.038752\n",
      "Nd: 297, N: 43,trainingerror: 0.000000, testerror: 0.048696\n",
      "Nd: 297, N: 50,trainingerror: 0.000035, testerror: 0.168763\n",
      "Nd: 297, N: 58,trainingerror: 0.000000, testerror: 0.032014\n",
      "Nd: 297, N: 67,trainingerror: 0.000000, testerror: 0.130736\n",
      "Nd: 297, N: 78,trainingerror: 0.000000, testerror: 0.721076\n",
      "Nd: 297, N: 90,trainingerror: 0.000000, testerror: 0.160212\n",
      "Nd: 297, N: 104,trainingerror: 0.000002, testerror: 0.101642\n",
      "Nd: 297, N: 121,trainingerror: 0.000000, testerror: 0.092833\n",
      "Nd: 297, N: 141,trainingerror: 0.000000, testerror: 0.082971\n",
      "Nd: 297, N: 163,trainingerror: 0.000020, testerror: 0.198927\n",
      "Nd: 297, N: 190,trainingerror: 0.000359, testerror: 0.152995\n",
      "Nd: 297, N: 220,trainingerror: 0.000073, testerror: 0.112419\n",
      "Nd: 297, N: 256,trainingerror: 0.000491, testerror: 0.147750\n",
      "Nd: 297, N: 297,trainingerror: 0.014791, testerror: 0.210220\n",
      "Nd: 297, N: 345,trainingerror: 0.004085, testerror: 0.140868\n",
      "Nd: 297, N: 400,trainingerror: 0.004211, testerror: 0.130224\n",
      "Nd: 297, N: 465,trainingerror: 0.010916, testerror: 0.093520\n",
      "Nd: 297, N: 540,trainingerror: 0.008164, testerror: 0.093886\n",
      "Nd: 297, N: 627,trainingerror: 0.013377, testerror: 0.093358\n",
      "Nd: 297, N: 729,trainingerror: 0.013318, testerror: 0.124924\n",
      "Nd: 297, N: 846,trainingerror: 0.016848, testerror: 0.077209\n",
      "Nd: 297, N: 983,trainingerror: 0.023664, testerror: 0.043530\n",
      "Nd: 297, N: 1142,trainingerror: 0.025898, testerror: 0.089570\n",
      "Nd: 297, N: 1326,trainingerror: 0.032138, testerror: 0.057938\n",
      "Nd: 297, N: 1541,trainingerror: 0.025222, testerror: 0.052927\n",
      "Nd: 297, N: 1789,trainingerror: 0.029780, testerror: 0.038460\n",
      "Nd: 297, N: 2078,trainingerror: 0.029568, testerror: 0.065492\n",
      "Nd: 297, N: 2414,trainingerror: 0.025722, testerror: 0.034487\n",
      "Nd: 297, N: 2804,trainingerror: 0.020462, testerror: 0.033009\n",
      "Nd: 297, N: 3257,trainingerror: 0.025594, testerror: 0.038382\n",
      "Nd: 297, N: 3783,trainingerror: 0.037346, testerror: 0.069247\n",
      "Nd: 297, N: 4395,trainingerror: 0.030701, testerror: 0.037540\n",
      "Nd: 297, N: 5105,trainingerror: 0.031245, testerror: 0.032313\n",
      "Nd: 297, N: 5930,trainingerror: 0.025691, testerror: 0.030781\n",
      "Nd: 297, N: 6888,trainingerror: 0.027666, testerror: 0.029318\n",
      "Nd: 345, N: 20,trainingerror: 0.000000, testerror: 0.286359\n",
      "Nd: 345, N: 24,trainingerror: 0.000000, testerror: 0.134040\n",
      "Nd: 345, N: 27,trainingerror: 0.000000, testerror: 0.048553\n",
      "Nd: 345, N: 32,trainingerror: 0.000000, testerror: 0.047807\n",
      "Nd: 345, N: 37,trainingerror: 0.000000, testerror: 0.058394\n",
      "Nd: 345, N: 43,trainingerror: 0.000000, testerror: 0.200114\n",
      "Nd: 345, N: 50,trainingerror: 0.000000, testerror: 0.265376\n",
      "Nd: 345, N: 58,trainingerror: 0.000000, testerror: 0.146001\n",
      "Nd: 345, N: 67,trainingerror: 0.000000, testerror: 0.113982\n",
      "Nd: 345, N: 78,trainingerror: 0.000000, testerror: 0.028389\n",
      "Nd: 345, N: 90,trainingerror: 0.000000, testerror: 0.036414\n",
      "Nd: 345, N: 104,trainingerror: 0.000000, testerror: 0.051324\n",
      "Nd: 345, N: 121,trainingerror: 0.000034, testerror: 0.186639\n",
      "Nd: 345, N: 141,trainingerror: 0.000000, testerror: 0.029837\n",
      "Nd: 345, N: 163,trainingerror: 0.000000, testerror: 0.071769\n",
      "Nd: 345, N: 190,trainingerror: 0.000000, testerror: 0.062275\n",
      "Nd: 345, N: 220,trainingerror: 0.000015, testerror: 0.113653\n",
      "Nd: 345, N: 256,trainingerror: 0.000066, testerror: 0.277670\n",
      "Nd: 345, N: 297,trainingerror: 0.000355, testerror: 0.112751\n",
      "Nd: 345, N: 345,trainingerror: 0.000621, testerror: 0.097191\n",
      "Nd: 345, N: 400,trainingerror: 0.005738, testerror: 0.292920\n",
      "Nd: 345, N: 465,trainingerror: 0.004935, testerror: 0.122050\n",
      "Nd: 345, N: 540,trainingerror: 0.005033, testerror: 0.145833\n",
      "Nd: 345, N: 627,trainingerror: 0.009489, testerror: 0.120701\n",
      "Nd: 345, N: 729,trainingerror: 0.009766, testerror: 0.088058\n",
      "Nd: 345, N: 846,trainingerror: 0.014748, testerror: 0.080116\n",
      "Nd: 345, N: 983,trainingerror: 0.018882, testerror: 0.049607\n",
      "Nd: 345, N: 1142,trainingerror: 0.020244, testerror: 0.065544\n",
      "Nd: 345, N: 1326,trainingerror: 0.018553, testerror: 0.079480\n",
      "Nd: 345, N: 1541,trainingerror: 0.017864, testerror: 0.065604\n",
      "Nd: 345, N: 1789,trainingerror: 0.023697, testerror: 0.054787\n",
      "Nd: 345, N: 2078,trainingerror: 0.024333, testerror: 0.064028\n",
      "Nd: 345, N: 2414,trainingerror: 0.032986, testerror: 0.041576\n",
      "Nd: 345, N: 2804,trainingerror: 0.025473, testerror: 0.039577\n",
      "Nd: 345, N: 3257,trainingerror: 0.025020, testerror: 0.082928\n",
      "Nd: 345, N: 3783,trainingerror: 0.022213, testerror: 0.031045\n",
      "Nd: 345, N: 4395,trainingerror: 0.025206, testerror: 0.032742\n",
      "Nd: 345, N: 5105,trainingerror: 0.030195, testerror: 0.037021\n",
      "Nd: 345, N: 5930,trainingerror: 0.025888, testerror: 0.038237\n",
      "Nd: 345, N: 6888,trainingerror: 0.026543, testerror: 0.034304\n",
      "Nd: 400, N: 20,trainingerror: 0.000000, testerror: 0.036717\n",
      "Nd: 400, N: 24,trainingerror: 0.000000, testerror: 0.132536\n",
      "Nd: 400, N: 27,trainingerror: 0.000000, testerror: 0.049269\n",
      "Nd: 400, N: 32,trainingerror: 0.000000, testerror: 0.363542\n",
      "Nd: 400, N: 37,trainingerror: 0.000000, testerror: 0.326856\n",
      "Nd: 400, N: 43,trainingerror: 0.000000, testerror: 0.094584\n",
      "Nd: 400, N: 50,trainingerror: 0.000000, testerror: 0.059111\n",
      "Nd: 400, N: 58,trainingerror: 0.000000, testerror: 0.736276\n",
      "Nd: 400, N: 67,trainingerror: 0.000000, testerror: 0.064843\n",
      "Nd: 400, N: 78,trainingerror: 0.000035, testerror: 0.101404\n",
      "Nd: 400, N: 90,trainingerror: 0.000000, testerror: 0.061893\n",
      "Nd: 400, N: 104,trainingerror: 0.000000, testerror: 0.092884\n",
      "Nd: 400, N: 121,trainingerror: 0.000000, testerror: 0.030611\n",
      "Nd: 400, N: 141,trainingerror: 0.000000, testerror: 0.143589\n",
      "Nd: 400, N: 163,trainingerror: 0.000000, testerror: 0.282511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 400, N: 190,trainingerror: 0.000228, testerror: 0.121250\n",
      "Nd: 400, N: 220,trainingerror: 0.000000, testerror: 0.124616\n",
      "Nd: 400, N: 256,trainingerror: 0.000006, testerror: 0.073933\n",
      "Nd: 400, N: 297,trainingerror: 0.000063, testerror: 0.117331\n",
      "Nd: 400, N: 345,trainingerror: 0.000023, testerror: 0.180542\n",
      "Nd: 400, N: 400,trainingerror: 0.005107, testerror: 0.085844\n",
      "Nd: 400, N: 465,trainingerror: 0.001371, testerror: 0.134208\n",
      "Nd: 400, N: 540,trainingerror: 0.002212, testerror: 0.075109\n",
      "Nd: 400, N: 627,trainingerror: 0.005572, testerror: 0.080179\n",
      "Nd: 400, N: 729,trainingerror: 0.007915, testerror: 0.083959\n",
      "Nd: 400, N: 846,trainingerror: 0.009955, testerror: 0.085017\n",
      "Nd: 400, N: 983,trainingerror: 0.010824, testerror: 0.068786\n",
      "Nd: 400, N: 1142,trainingerror: 0.013377, testerror: 0.094670\n",
      "Nd: 400, N: 1326,trainingerror: 0.015628, testerror: 0.043503\n",
      "Nd: 400, N: 1541,trainingerror: 0.017346, testerror: 0.042143\n",
      "Nd: 400, N: 1789,trainingerror: 0.018191, testerror: 0.050720\n",
      "Nd: 400, N: 2078,trainingerror: 0.024355, testerror: 0.038186\n",
      "Nd: 400, N: 2414,trainingerror: 0.020955, testerror: 0.048474\n",
      "Nd: 400, N: 2804,trainingerror: 0.021897, testerror: 0.039697\n",
      "Nd: 400, N: 3257,trainingerror: 0.021333, testerror: 0.032789\n",
      "Nd: 400, N: 3783,trainingerror: 0.023038, testerror: 0.031052\n",
      "Nd: 400, N: 4395,trainingerror: 0.025245, testerror: 0.046778\n",
      "Nd: 400, N: 5105,trainingerror: 0.028371, testerror: 0.045796\n",
      "Nd: 400, N: 5930,trainingerror: 0.025595, testerror: 0.031481\n",
      "Nd: 400, N: 6888,trainingerror: 0.024765, testerror: 0.030624\n",
      "Nd: 465, N: 20,trainingerror: 0.000000, testerror: 0.121280\n",
      "Nd: 465, N: 24,trainingerror: 0.000000, testerror: 0.135183\n",
      "Nd: 465, N: 27,trainingerror: 0.000000, testerror: 0.146941\n",
      "Nd: 465, N: 32,trainingerror: 0.000000, testerror: 0.032423\n",
      "Nd: 465, N: 37,trainingerror: 0.000000, testerror: 0.113750\n",
      "Nd: 465, N: 43,trainingerror: 0.000000, testerror: 0.045933\n",
      "Nd: 465, N: 50,trainingerror: 0.000000, testerror: 0.116070\n",
      "Nd: 465, N: 58,trainingerror: 0.000000, testerror: 0.068026\n",
      "Nd: 465, N: 67,trainingerror: 0.000000, testerror: 0.086594\n",
      "Nd: 465, N: 78,trainingerror: 0.000000, testerror: 0.288401\n",
      "Nd: 465, N: 90,trainingerror: 0.000000, testerror: 0.034215\n",
      "Nd: 465, N: 104,trainingerror: 0.000000, testerror: 0.127222\n",
      "Nd: 465, N: 121,trainingerror: 0.000000, testerror: 0.054515\n",
      "Nd: 465, N: 141,trainingerror: 0.000000, testerror: 0.062841\n",
      "Nd: 465, N: 163,trainingerror: 0.000000, testerror: 0.149937\n",
      "Nd: 465, N: 190,trainingerror: 0.000000, testerror: 0.138390\n",
      "Nd: 465, N: 220,trainingerror: 0.000000, testerror: 0.181573\n",
      "Nd: 465, N: 256,trainingerror: 0.000002, testerror: 0.118185\n",
      "Nd: 465, N: 297,trainingerror: 0.000007, testerror: 0.133614\n",
      "Nd: 465, N: 345,trainingerror: 0.000078, testerror: 0.123090\n",
      "Nd: 465, N: 400,trainingerror: 0.000215, testerror: 0.153160\n",
      "Nd: 465, N: 465,trainingerror: 0.000914, testerror: 0.173189\n",
      "Nd: 465, N: 540,trainingerror: 0.002084, testerror: 0.136796\n",
      "Nd: 465, N: 627,trainingerror: 0.003760, testerror: 0.111013\n",
      "Nd: 465, N: 729,trainingerror: 0.005378, testerror: 0.087512\n",
      "Nd: 465, N: 846,trainingerror: 0.007793, testerror: 0.095093\n",
      "Nd: 465, N: 983,trainingerror: 0.014779, testerror: 0.077023\n",
      "Nd: 465, N: 1142,trainingerror: 0.010762, testerror: 0.069798\n",
      "Nd: 465, N: 1326,trainingerror: 0.026064, testerror: 0.073358\n",
      "Nd: 465, N: 1541,trainingerror: 0.016777, testerror: 0.061748\n",
      "Nd: 465, N: 1789,trainingerror: 0.017260, testerror: 0.052756\n",
      "Nd: 465, N: 2078,trainingerror: 0.018251, testerror: 0.045395\n",
      "Nd: 465, N: 2414,trainingerror: 0.021065, testerror: 0.046713\n",
      "Nd: 465, N: 2804,trainingerror: 0.025745, testerror: 0.041295\n",
      "Nd: 465, N: 3257,trainingerror: 0.022294, testerror: 0.034662\n",
      "Nd: 465, N: 3783,trainingerror: 0.022113, testerror: 0.031885\n",
      "Nd: 465, N: 4395,trainingerror: 0.023801, testerror: 0.030212\n",
      "Nd: 465, N: 5105,trainingerror: 0.026440, testerror: 0.033553\n",
      "Nd: 465, N: 5930,trainingerror: 0.023256, testerror: 0.034496\n",
      "Nd: 465, N: 6888,trainingerror: 0.032385, testerror: 0.035103\n",
      "Nd: 540, N: 20,trainingerror: 0.000000, testerror: 0.042270\n",
      "Nd: 540, N: 24,trainingerror: 0.000000, testerror: 0.033963\n",
      "Nd: 540, N: 27,trainingerror: 0.000000, testerror: 0.024651\n",
      "Nd: 540, N: 32,trainingerror: 0.000000, testerror: 0.070599\n",
      "Nd: 540, N: 37,trainingerror: 0.000000, testerror: 0.565911\n",
      "Nd: 540, N: 43,trainingerror: 0.000000, testerror: 0.068158\n",
      "Nd: 540, N: 50,trainingerror: 0.000000, testerror: 0.055419\n",
      "Nd: 540, N: 58,trainingerror: 0.000000, testerror: 0.208762\n",
      "Nd: 540, N: 67,trainingerror: 0.000000, testerror: 0.077013\n",
      "Nd: 540, N: 78,trainingerror: 0.000000, testerror: 0.157956\n",
      "Nd: 540, N: 90,trainingerror: 0.000000, testerror: 0.037451\n",
      "Nd: 540, N: 104,trainingerror: 0.000000, testerror: 0.049787\n",
      "Nd: 540, N: 121,trainingerror: 0.000000, testerror: 0.077752\n",
      "Nd: 540, N: 141,trainingerror: 0.000000, testerror: 0.060371\n",
      "Nd: 540, N: 163,trainingerror: 0.000000, testerror: 0.028043\n",
      "Nd: 540, N: 190,trainingerror: 0.000000, testerror: 0.132309\n",
      "Nd: 540, N: 220,trainingerror: 0.000000, testerror: 0.094616\n",
      "Nd: 540, N: 256,trainingerror: 0.000001, testerror: 0.085699\n",
      "Nd: 540, N: 297,trainingerror: 0.000010, testerror: 0.105762\n",
      "Nd: 540, N: 345,trainingerror: 0.000044, testerror: 0.161033\n",
      "Nd: 540, N: 400,trainingerror: 0.000034, testerror: 0.084650\n",
      "Nd: 540, N: 465,trainingerror: 0.000183, testerror: 0.109281\n",
      "Nd: 540, N: 540,trainingerror: 0.000788, testerror: 0.082251\n",
      "Nd: 540, N: 627,trainingerror: 0.002646, testerror: 0.104780\n",
      "Nd: 540, N: 729,trainingerror: 0.003587, testerror: 0.123306\n",
      "Nd: 540, N: 846,trainingerror: 0.004049, testerror: 0.079389\n",
      "Nd: 540, N: 983,trainingerror: 0.008872, testerror: 0.088476\n",
      "Nd: 540, N: 1142,trainingerror: 0.015805, testerror: 0.137312\n",
      "Nd: 540, N: 1326,trainingerror: 0.010342, testerror: 0.088908\n",
      "Nd: 540, N: 1541,trainingerror: 0.013016, testerror: 0.053271\n",
      "Nd: 540, N: 1789,trainingerror: 0.013956, testerror: 0.064395\n",
      "Nd: 540, N: 2078,trainingerror: 0.017898, testerror: 0.047834\n",
      "Nd: 540, N: 2414,trainingerror: 0.019486, testerror: 0.049218\n",
      "Nd: 540, N: 2804,trainingerror: 0.020949, testerror: 0.038179\n",
      "Nd: 540, N: 3257,trainingerror: 0.020755, testerror: 0.041320\n",
      "Nd: 540, N: 3783,trainingerror: 0.019867, testerror: 0.032815\n",
      "Nd: 540, N: 4395,trainingerror: 0.024378, testerror: 0.036114\n",
      "Nd: 540, N: 5105,trainingerror: 0.022153, testerror: 0.034477\n",
      "Nd: 540, N: 5930,trainingerror: 0.022446, testerror: 0.029541\n",
      "Nd: 540, N: 6888,trainingerror: 0.023076, testerror: 0.030743\n",
      "Nd: 627, N: 20,trainingerror: 0.000000, testerror: 0.030434\n",
      "Nd: 627, N: 24,trainingerror: 0.000000, testerror: 0.049308\n",
      "Nd: 627, N: 27,trainingerror: 0.000000, testerror: 0.039958\n",
      "Nd: 627, N: 32,trainingerror: 0.000000, testerror: 0.082392\n",
      "Nd: 627, N: 37,trainingerror: 0.000000, testerror: 0.050812\n",
      "Nd: 627, N: 43,trainingerror: 0.000000, testerror: 0.032630\n",
      "Nd: 627, N: 50,trainingerror: 0.000000, testerror: 0.047641\n",
      "Nd: 627, N: 58,trainingerror: 0.000000, testerror: 0.078881\n",
      "Nd: 627, N: 67,trainingerror: 0.000000, testerror: 0.163427\n",
      "Nd: 627, N: 78,trainingerror: 0.000000, testerror: 0.065181\n",
      "Nd: 627, N: 90,trainingerror: 0.000000, testerror: 0.073380\n",
      "Nd: 627, N: 104,trainingerror: 0.000000, testerror: 0.077768\n",
      "Nd: 627, N: 121,trainingerror: 0.000000, testerror: 0.041937\n",
      "Nd: 627, N: 141,trainingerror: 0.000000, testerror: 0.151384\n",
      "Nd: 627, N: 163,trainingerror: 0.000000, testerror: 0.126624\n",
      "Nd: 627, N: 190,trainingerror: 0.000000, testerror: 0.062121\n",
      "Nd: 627, N: 220,trainingerror: 0.000000, testerror: 0.094040\n",
      "Nd: 627, N: 256,trainingerror: 0.000000, testerror: 0.104269\n",
      "Nd: 627, N: 297,trainingerror: 0.000000, testerror: 0.094096\n",
      "Nd: 627, N: 345,trainingerror: 0.000001, testerror: 0.085362\n",
      "Nd: 627, N: 400,trainingerror: 0.000001, testerror: 0.100027\n",
      "Nd: 627, N: 465,trainingerror: 0.000109, testerror: 0.083185\n",
      "Nd: 627, N: 540,trainingerror: 0.000135, testerror: 0.162977\n",
      "Nd: 627, N: 627,trainingerror: 0.000734, testerror: 0.130350\n",
      "Nd: 627, N: 729,trainingerror: 0.001175, testerror: 0.104170\n",
      "Nd: 627, N: 846,trainingerror: 0.003205, testerror: 0.113920\n",
      "Nd: 627, N: 983,trainingerror: 0.005304, testerror: 0.089796\n",
      "Nd: 627, N: 1142,trainingerror: 0.005375, testerror: 0.085068\n",
      "Nd: 627, N: 1326,trainingerror: 0.011525, testerror: 0.078411\n",
      "Nd: 627, N: 1541,trainingerror: 0.012920, testerror: 0.061418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 627, N: 1789,trainingerror: 0.014210, testerror: 0.050011\n",
      "Nd: 627, N: 2078,trainingerror: 0.012693, testerror: 0.039153\n",
      "Nd: 627, N: 2414,trainingerror: 0.016758, testerror: 0.052565\n",
      "Nd: 627, N: 2804,trainingerror: 0.017490, testerror: 0.041632\n",
      "Nd: 627, N: 3257,trainingerror: 0.017588, testerror: 0.034764\n",
      "Nd: 627, N: 3783,trainingerror: 0.022259, testerror: 0.035912\n",
      "Nd: 627, N: 4395,trainingerror: 0.031098, testerror: 0.044726\n",
      "Nd: 627, N: 5105,trainingerror: 0.025818, testerror: 0.034952\n",
      "Nd: 627, N: 5930,trainingerror: 0.020734, testerror: 0.027924\n",
      "Nd: 627, N: 6888,trainingerror: 0.022654, testerror: 0.030541\n",
      "Nd: 729, N: 20,trainingerror: 0.000000, testerror: 0.057630\n",
      "Nd: 729, N: 24,trainingerror: 0.000000, testerror: 0.050296\n",
      "Nd: 729, N: 27,trainingerror: 0.000000, testerror: 0.067947\n",
      "Nd: 729, N: 32,trainingerror: 0.000000, testerror: 0.036098\n",
      "Nd: 729, N: 37,trainingerror: 0.000000, testerror: 0.027353\n",
      "Nd: 729, N: 43,trainingerror: 0.000000, testerror: 0.065569\n",
      "Nd: 729, N: 50,trainingerror: 0.000000, testerror: 0.189228\n",
      "Nd: 729, N: 58,trainingerror: 0.000000, testerror: 0.118654\n",
      "Nd: 729, N: 67,trainingerror: 0.000000, testerror: 0.013705\n",
      "Nd: 729, N: 78,trainingerror: 0.000000, testerror: 0.059481\n",
      "Nd: 729, N: 90,trainingerror: 0.000000, testerror: 0.045426\n",
      "Nd: 729, N: 104,trainingerror: 0.000000, testerror: 0.128454\n",
      "Nd: 729, N: 121,trainingerror: 0.000000, testerror: 0.125273\n",
      "Nd: 729, N: 141,trainingerror: 0.000000, testerror: 0.596041\n",
      "Nd: 729, N: 163,trainingerror: 0.000000, testerror: 0.056985\n",
      "Nd: 729, N: 190,trainingerror: 0.000000, testerror: 0.062924\n",
      "Nd: 729, N: 220,trainingerror: 0.000000, testerror: 0.088381\n",
      "Nd: 729, N: 256,trainingerror: 0.000000, testerror: 0.111030\n",
      "Nd: 729, N: 297,trainingerror: 0.000001, testerror: 0.078192\n",
      "Nd: 729, N: 345,trainingerror: 0.000003, testerror: 0.086162\n",
      "Nd: 729, N: 400,trainingerror: 0.000014, testerror: 0.112203\n",
      "Nd: 729, N: 465,trainingerror: 0.000003, testerror: 0.107536\n",
      "Nd: 729, N: 540,trainingerror: 0.000070, testerror: 0.129474\n",
      "Nd: 729, N: 627,trainingerror: 0.000277, testerror: 0.099325\n",
      "Nd: 729, N: 729,trainingerror: 0.000801, testerror: 0.092777\n",
      "Nd: 729, N: 846,trainingerror: 0.001746, testerror: 0.138677\n",
      "Nd: 729, N: 983,trainingerror: 0.002903, testerror: 0.095413\n",
      "Nd: 729, N: 1142,trainingerror: 0.005116, testerror: 0.081331\n",
      "Nd: 729, N: 1326,trainingerror: 0.006679, testerror: 0.100270\n",
      "Nd: 729, N: 1541,trainingerror: 0.010197, testerror: 0.083843\n",
      "Nd: 729, N: 1789,trainingerror: 0.010127, testerror: 0.054585\n",
      "Nd: 729, N: 2078,trainingerror: 0.013863, testerror: 0.047491\n",
      "Nd: 729, N: 2414,trainingerror: 0.017243, testerror: 0.042809\n",
      "Nd: 729, N: 2804,trainingerror: 0.016970, testerror: 0.035415\n",
      "Nd: 729, N: 3257,trainingerror: 0.019200, testerror: 0.047111\n",
      "Nd: 729, N: 3783,trainingerror: 0.020198, testerror: 0.035744\n",
      "Nd: 729, N: 4395,trainingerror: 0.021998, testerror: 0.043235\n",
      "Nd: 729, N: 5105,trainingerror: 0.022302, testerror: 0.043047\n",
      "Nd: 729, N: 5930,trainingerror: 0.020492, testerror: 0.032257\n",
      "Nd: 729, N: 6888,trainingerror: 0.024610, testerror: 0.034277\n",
      "Nd: 846, N: 20,trainingerror: 0.000000, testerror: 0.010084\n",
      "Nd: 846, N: 24,trainingerror: 0.000000, testerror: 0.090175\n",
      "Nd: 846, N: 27,trainingerror: 0.000000, testerror: 0.181118\n",
      "Nd: 846, N: 32,trainingerror: 0.000000, testerror: 0.146900\n",
      "Nd: 846, N: 37,trainingerror: 0.000000, testerror: 0.197324\n",
      "Nd: 846, N: 43,trainingerror: 0.000000, testerror: 0.061315\n",
      "Nd: 846, N: 50,trainingerror: 0.000000, testerror: 0.117974\n",
      "Nd: 846, N: 58,trainingerror: 0.000000, testerror: 0.046466\n",
      "Nd: 846, N: 67,trainingerror: 0.000000, testerror: 0.045949\n",
      "Nd: 846, N: 78,trainingerror: 0.000000, testerror: 0.065265\n",
      "Nd: 846, N: 90,trainingerror: 0.000000, testerror: 0.075914\n",
      "Nd: 846, N: 104,trainingerror: 0.000000, testerror: 0.019785\n",
      "Nd: 846, N: 121,trainingerror: 0.000000, testerror: 0.081712\n",
      "Nd: 846, N: 141,trainingerror: 0.000000, testerror: 0.059858\n",
      "Nd: 846, N: 163,trainingerror: 0.000000, testerror: 0.107287\n",
      "Nd: 846, N: 190,trainingerror: 0.000000, testerror: 0.087041\n",
      "Nd: 846, N: 220,trainingerror: 0.000000, testerror: 0.114590\n",
      "Nd: 846, N: 256,trainingerror: 0.000000, testerror: 0.167520\n",
      "Nd: 846, N: 297,trainingerror: 0.000000, testerror: 0.085365\n",
      "Nd: 846, N: 345,trainingerror: 0.000017, testerror: 0.104073\n",
      "Nd: 846, N: 400,trainingerror: 0.000005, testerror: 0.108853\n",
      "Nd: 846, N: 465,trainingerror: 0.000029, testerror: 0.090575\n",
      "Nd: 846, N: 540,trainingerror: 0.000044, testerror: 0.146429\n",
      "Nd: 846, N: 627,trainingerror: 0.000106, testerror: 0.111488\n",
      "Nd: 846, N: 729,trainingerror: 0.000231, testerror: 0.102482\n",
      "Nd: 846, N: 846,trainingerror: 0.000806, testerror: 0.095748\n",
      "Nd: 846, N: 983,trainingerror: 0.001227, testerror: 0.094823\n",
      "Nd: 846, N: 1142,trainingerror: 0.003516, testerror: 0.102423\n",
      "Nd: 846, N: 1326,trainingerror: 0.004964, testerror: 0.123868\n",
      "Nd: 846, N: 1541,trainingerror: 0.007654, testerror: 0.095520\n",
      "Nd: 846, N: 1789,trainingerror: 0.007931, testerror: 0.059056\n",
      "Nd: 846, N: 2078,trainingerror: 0.016506, testerror: 0.072038\n",
      "Nd: 846, N: 2414,trainingerror: 0.013555, testerror: 0.045378\n",
      "Nd: 846, N: 2804,trainingerror: 0.015950, testerror: 0.055501\n",
      "Nd: 846, N: 3257,trainingerror: 0.016723, testerror: 0.044925\n",
      "Nd: 846, N: 3783,trainingerror: 0.019246, testerror: 0.043256\n",
      "Nd: 846, N: 4395,trainingerror: 0.016880, testerror: 0.036511\n",
      "Nd: 846, N: 5105,trainingerror: 0.025589, testerror: 0.044220\n",
      "Nd: 846, N: 5930,trainingerror: 0.022223, testerror: 0.028195\n",
      "Nd: 846, N: 6888,trainingerror: 0.021073, testerror: 0.033626\n",
      "Nd: 983, N: 20,trainingerror: 0.000000, testerror: 0.109304\n",
      "Nd: 983, N: 24,trainingerror: 0.000000, testerror: 0.011308\n",
      "Nd: 983, N: 27,trainingerror: 0.000000, testerror: 0.163265\n",
      "Nd: 983, N: 32,trainingerror: 0.000000, testerror: 0.220449\n",
      "Nd: 983, N: 37,trainingerror: 0.000000, testerror: 0.013054\n",
      "Nd: 983, N: 43,trainingerror: 0.000000, testerror: 0.132047\n",
      "Nd: 983, N: 50,trainingerror: 0.000000, testerror: 0.024094\n",
      "Nd: 983, N: 58,trainingerror: 0.000000, testerror: 0.020944\n",
      "Nd: 983, N: 67,trainingerror: 0.000000, testerror: 0.103112\n",
      "Nd: 983, N: 78,trainingerror: 0.000000, testerror: 0.057663\n",
      "Nd: 983, N: 90,trainingerror: 0.000000, testerror: 0.030178\n",
      "Nd: 983, N: 104,trainingerror: 0.000000, testerror: 0.099262\n",
      "Nd: 983, N: 121,trainingerror: 0.000000, testerror: 0.068495\n",
      "Nd: 983, N: 141,trainingerror: 0.000000, testerror: 0.076362\n",
      "Nd: 983, N: 163,trainingerror: 0.000000, testerror: 0.091373\n",
      "Nd: 983, N: 190,trainingerror: 0.000000, testerror: 0.108711\n",
      "Nd: 983, N: 220,trainingerror: 0.000000, testerror: 0.103833\n",
      "Nd: 983, N: 256,trainingerror: 0.000000, testerror: 0.066458\n",
      "Nd: 983, N: 297,trainingerror: 0.000000, testerror: 0.115792\n",
      "Nd: 983, N: 345,trainingerror: 0.000000, testerror: 0.093524\n",
      "Nd: 983, N: 400,trainingerror: 0.000009, testerror: 0.173927\n",
      "Nd: 983, N: 465,trainingerror: 0.000016, testerror: 0.154564\n",
      "Nd: 983, N: 540,trainingerror: 0.000013, testerror: 0.094649\n",
      "Nd: 983, N: 627,trainingerror: 0.000008, testerror: 0.121430\n",
      "Nd: 983, N: 729,trainingerror: 0.000075, testerror: 0.098078\n",
      "Nd: 983, N: 846,trainingerror: 0.000258, testerror: 0.089288\n",
      "Nd: 983, N: 983,trainingerror: 0.000720, testerror: 0.075073\n",
      "Nd: 983, N: 1142,trainingerror: 0.001766, testerror: 0.085591\n",
      "Nd: 983, N: 1326,trainingerror: 0.004492, testerror: 0.072275\n",
      "Nd: 983, N: 1541,trainingerror: 0.006028, testerror: 0.099423\n",
      "Nd: 983, N: 1789,trainingerror: 0.005895, testerror: 0.053640\n",
      "Nd: 983, N: 2078,trainingerror: 0.009220, testerror: 0.065873\n",
      "Nd: 983, N: 2414,trainingerror: 0.013045, testerror: 0.063434\n",
      "Nd: 983, N: 2804,trainingerror: 0.009884, testerror: 0.045768\n",
      "Nd: 983, N: 3257,trainingerror: 0.014502, testerror: 0.043570\n",
      "Nd: 983, N: 3783,trainingerror: 0.016018, testerror: 0.053441\n",
      "Nd: 983, N: 4395,trainingerror: 0.016704, testerror: 0.042061\n",
      "Nd: 983, N: 5105,trainingerror: 0.019957, testerror: 0.039531\n",
      "Nd: 983, N: 5930,trainingerror: 0.020769, testerror: 0.034463\n",
      "Nd: 983, N: 6888,trainingerror: 0.020655, testerror: 0.032796\n",
      "Nd: 1142, N: 20,trainingerror: 0.000000, testerror: 0.034459\n",
      "Nd: 1142, N: 24,trainingerror: 0.000000, testerror: 0.113803\n",
      "Nd: 1142, N: 27,trainingerror: 0.000000, testerror: 0.096618\n",
      "Nd: 1142, N: 32,trainingerror: 0.000000, testerror: 0.192495\n",
      "Nd: 1142, N: 37,trainingerror: 0.000000, testerror: 0.044972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 1142, N: 43,trainingerror: 0.000000, testerror: 0.059557\n",
      "Nd: 1142, N: 50,trainingerror: 0.000000, testerror: 0.066750\n",
      "Nd: 1142, N: 58,trainingerror: 0.000000, testerror: 0.073268\n",
      "Nd: 1142, N: 67,trainingerror: 0.000000, testerror: 0.029416\n",
      "Nd: 1142, N: 78,trainingerror: 0.000000, testerror: 0.026670\n",
      "Nd: 1142, N: 90,trainingerror: 0.000000, testerror: 0.268809\n",
      "Nd: 1142, N: 104,trainingerror: 0.000000, testerror: 0.069977\n",
      "Nd: 1142, N: 121,trainingerror: 0.000000, testerror: 0.103122\n",
      "Nd: 1142, N: 141,trainingerror: 0.000000, testerror: 0.175965\n",
      "Nd: 1142, N: 163,trainingerror: 0.000000, testerror: 0.096938\n",
      "Nd: 1142, N: 190,trainingerror: 0.000000, testerror: 0.041546\n",
      "Nd: 1142, N: 220,trainingerror: 0.000000, testerror: 0.077403\n",
      "Nd: 1142, N: 256,trainingerror: 0.000004, testerror: 0.044850\n",
      "Nd: 1142, N: 297,trainingerror: 0.000000, testerror: 0.054485\n",
      "Nd: 1142, N: 345,trainingerror: 0.000000, testerror: 0.075990\n",
      "Nd: 1142, N: 400,trainingerror: 0.000005, testerror: 0.125035\n",
      "Nd: 1142, N: 465,trainingerror: 0.000013, testerror: 0.135382\n",
      "Nd: 1142, N: 540,trainingerror: 0.000008, testerror: 0.077397\n",
      "Nd: 1142, N: 627,trainingerror: 0.000066, testerror: 0.062464\n",
      "Nd: 1142, N: 729,trainingerror: 0.000175, testerror: 0.084417\n",
      "Nd: 1142, N: 846,trainingerror: 0.000118, testerror: 0.106339\n",
      "Nd: 1142, N: 983,trainingerror: 0.000238, testerror: 0.105892\n",
      "Nd: 1142, N: 1142,trainingerror: 0.000768, testerror: 0.091253\n",
      "Nd: 1142, N: 1326,trainingerror: 0.002269, testerror: 0.078722\n",
      "Nd: 1142, N: 1541,trainingerror: 0.003286, testerror: 0.085754\n",
      "Nd: 1142, N: 1789,trainingerror: 0.005768, testerror: 0.070551\n",
      "Nd: 1142, N: 2078,trainingerror: 0.007468, testerror: 0.078099\n",
      "Nd: 1142, N: 2414,trainingerror: 0.007784, testerror: 0.066206\n",
      "Nd: 1142, N: 2804,trainingerror: 0.008760, testerror: 0.059414\n",
      "Nd: 1142, N: 3257,trainingerror: 0.014246, testerror: 0.053696\n",
      "Nd: 1142, N: 3783,trainingerror: 0.013678, testerror: 0.044212\n",
      "Nd: 1142, N: 4395,trainingerror: 0.015382, testerror: 0.039983\n",
      "Nd: 1142, N: 5105,trainingerror: 0.017353, testerror: 0.039424\n",
      "Nd: 1142, N: 5930,trainingerror: 0.018028, testerror: 0.037014\n",
      "Nd: 1142, N: 6888,trainingerror: 0.018486, testerror: 0.037860\n",
      "Nd: 1326, N: 20,trainingerror: 0.000000, testerror: 0.385746\n",
      "Nd: 1326, N: 24,trainingerror: 0.000000, testerror: 0.014884\n",
      "Nd: 1326, N: 27,trainingerror: 0.000000, testerror: 0.061460\n",
      "Nd: 1326, N: 32,trainingerror: 0.000000, testerror: 0.018645\n",
      "Nd: 1326, N: 37,trainingerror: 0.000000, testerror: 0.016020\n",
      "Nd: 1326, N: 43,trainingerror: 0.000000, testerror: 0.162267\n",
      "Nd: 1326, N: 50,trainingerror: 0.000000, testerror: 0.175170\n",
      "Nd: 1326, N: 58,trainingerror: 0.000000, testerror: 0.136797\n",
      "Nd: 1326, N: 67,trainingerror: 0.000000, testerror: 0.073665\n",
      "Nd: 1326, N: 78,trainingerror: 0.000000, testerror: 0.134236\n",
      "Nd: 1326, N: 90,trainingerror: 0.000000, testerror: 0.051113\n",
      "Nd: 1326, N: 104,trainingerror: 0.000000, testerror: 0.035336\n",
      "Nd: 1326, N: 121,trainingerror: 0.000332, testerror: 0.104927\n",
      "Nd: 1326, N: 141,trainingerror: 0.000000, testerror: 0.056947\n",
      "Nd: 1326, N: 163,trainingerror: 0.000000, testerror: 0.081497\n",
      "Nd: 1326, N: 190,trainingerror: 0.000000, testerror: 0.054512\n",
      "Nd: 1326, N: 220,trainingerror: 0.000000, testerror: 0.113970\n",
      "Nd: 1326, N: 256,trainingerror: 0.000048, testerror: 0.060740\n",
      "Nd: 1326, N: 297,trainingerror: 0.000000, testerror: 0.074267\n",
      "Nd: 1326, N: 345,trainingerror: 0.000000, testerror: 0.106664\n",
      "Nd: 1326, N: 400,trainingerror: 0.000000, testerror: 0.095053\n",
      "Nd: 1326, N: 465,trainingerror: 0.000000, testerror: 0.094244\n",
      "Nd: 1326, N: 540,trainingerror: 0.000000, testerror: 0.162331\n",
      "Nd: 1326, N: 627,trainingerror: 0.000001, testerror: 0.104631\n",
      "Nd: 1326, N: 729,trainingerror: 0.000003, testerror: 0.082412\n",
      "Nd: 1326, N: 846,trainingerror: 0.000061, testerror: 0.119095\n",
      "Nd: 1326, N: 983,trainingerror: 0.000142, testerror: 0.147255\n",
      "Nd: 1326, N: 1142,trainingerror: 0.000341, testerror: 0.125614\n",
      "Nd: 1326, N: 1326,trainingerror: 0.001080, testerror: 0.096980\n",
      "Nd: 1326, N: 1541,trainingerror: 0.001823, testerror: 0.085970\n",
      "Nd: 1326, N: 1789,trainingerror: 0.003873, testerror: 0.086810\n",
      "Nd: 1326, N: 2078,trainingerror: 0.007345, testerror: 0.098929\n",
      "Nd: 1326, N: 2414,trainingerror: 0.006115, testerror: 0.060295\n",
      "Nd: 1326, N: 2804,trainingerror: 0.009557, testerror: 0.046068\n",
      "Nd: 1326, N: 3257,trainingerror: 0.009961, testerror: 0.046054\n",
      "Nd: 1326, N: 3783,trainingerror: 0.012806, testerror: 0.040253\n",
      "Nd: 1326, N: 4395,trainingerror: 0.012800, testerror: 0.039911\n",
      "Nd: 1326, N: 5105,trainingerror: 0.015277, testerror: 0.040328\n",
      "Nd: 1326, N: 5930,trainingerror: 0.016198, testerror: 0.038274\n",
      "Nd: 1326, N: 6888,trainingerror: 0.017908, testerror: 0.039232\n",
      "Nd: 1541, N: 20,trainingerror: 0.000000, testerror: 0.059874\n",
      "Nd: 1541, N: 24,trainingerror: 0.000000, testerror: 0.120245\n",
      "Nd: 1541, N: 27,trainingerror: 0.000000, testerror: 0.259838\n",
      "Nd: 1541, N: 32,trainingerror: 0.000000, testerror: 0.052066\n",
      "Nd: 1541, N: 37,trainingerror: 0.000000, testerror: 0.022645\n",
      "Nd: 1541, N: 43,trainingerror: 0.000000, testerror: 0.104378\n",
      "Nd: 1541, N: 50,trainingerror: 0.000000, testerror: 0.045089\n",
      "Nd: 1541, N: 58,trainingerror: 0.000000, testerror: 0.169585\n",
      "Nd: 1541, N: 67,trainingerror: 0.000000, testerror: 0.250083\n",
      "Nd: 1541, N: 78,trainingerror: 0.000000, testerror: 0.086234\n",
      "Nd: 1541, N: 90,trainingerror: 0.000000, testerror: 0.052871\n",
      "Nd: 1541, N: 104,trainingerror: 0.000033, testerror: 0.072293\n",
      "Nd: 1541, N: 121,trainingerror: 0.000000, testerror: 0.085396\n",
      "Nd: 1541, N: 141,trainingerror: 0.000002, testerror: 0.136334\n",
      "Nd: 1541, N: 163,trainingerror: 0.000000, testerror: 0.061597\n",
      "Nd: 1541, N: 190,trainingerror: 0.000048, testerror: 0.097247\n",
      "Nd: 1541, N: 220,trainingerror: 0.000000, testerror: 0.113089\n",
      "Nd: 1541, N: 256,trainingerror: 0.000000, testerror: 0.079719\n",
      "Nd: 1541, N: 297,trainingerror: 0.000000, testerror: 0.047615\n",
      "Nd: 1541, N: 345,trainingerror: 0.000000, testerror: 0.080780\n",
      "Nd: 1541, N: 400,trainingerror: 0.000007, testerror: 0.099170\n",
      "Nd: 1541, N: 465,trainingerror: 0.000000, testerror: 0.115146\n",
      "Nd: 1541, N: 540,trainingerror: 0.000005, testerror: 0.072836\n",
      "Nd: 1541, N: 627,trainingerror: 0.000012, testerror: 0.067502\n",
      "Nd: 1541, N: 729,trainingerror: 0.000002, testerror: 0.124236\n",
      "Nd: 1541, N: 846,trainingerror: 0.000001, testerror: 0.097184\n",
      "Nd: 1541, N: 983,trainingerror: 0.000082, testerror: 0.107207\n",
      "Nd: 1541, N: 1142,trainingerror: 0.000207, testerror: 0.084229\n",
      "Nd: 1541, N: 1326,trainingerror: 0.000385, testerror: 0.076853\n",
      "Nd: 1541, N: 1541,trainingerror: 0.001196, testerror: 0.104671\n",
      "Nd: 1541, N: 1789,trainingerror: 0.002567, testerror: 0.071516\n",
      "Nd: 1541, N: 2078,trainingerror: 0.003903, testerror: 0.059357\n",
      "Nd: 1541, N: 2414,trainingerror: 0.006465, testerror: 0.084550\n",
      "Nd: 1541, N: 2804,trainingerror: 0.008088, testerror: 0.076167\n",
      "Nd: 1541, N: 3257,trainingerror: 0.008371, testerror: 0.050559\n",
      "Nd: 1541, N: 3783,trainingerror: 0.010051, testerror: 0.049188\n",
      "Nd: 1541, N: 4395,trainingerror: 0.012278, testerror: 0.044537\n",
      "Nd: 1541, N: 5105,trainingerror: 0.016079, testerror: 0.043643\n",
      "Nd: 1541, N: 5930,trainingerror: 0.016012, testerror: 0.036458\n",
      "Nd: 1541, N: 6888,trainingerror: 0.017402, testerror: 0.036657\n",
      "Nd: 1789, N: 20,trainingerror: 0.000000, testerror: 0.122477\n",
      "Nd: 1789, N: 24,trainingerror: 0.000000, testerror: 0.037631\n",
      "Nd: 1789, N: 27,trainingerror: 0.000000, testerror: 0.104823\n",
      "Nd: 1789, N: 32,trainingerror: 0.000000, testerror: 0.021746\n",
      "Nd: 1789, N: 37,trainingerror: 0.000000, testerror: 0.016874\n",
      "Nd: 1789, N: 43,trainingerror: 0.000000, testerror: 0.075561\n",
      "Nd: 1789, N: 50,trainingerror: 0.000000, testerror: 0.025034\n",
      "Nd: 1789, N: 58,trainingerror: 0.000000, testerror: 0.030285\n",
      "Nd: 1789, N: 67,trainingerror: 0.000000, testerror: 0.092734\n",
      "Nd: 1789, N: 78,trainingerror: 0.000000, testerror: 0.044888\n",
      "Nd: 1789, N: 90,trainingerror: 0.000001, testerror: 0.097665\n",
      "Nd: 1789, N: 104,trainingerror: 0.000000, testerror: 0.065330\n",
      "Nd: 1789, N: 121,trainingerror: 0.000000, testerror: 0.105434\n",
      "Nd: 1789, N: 141,trainingerror: 0.000000, testerror: 0.111518\n",
      "Nd: 1789, N: 163,trainingerror: 0.000000, testerror: 0.041737\n",
      "Nd: 1789, N: 190,trainingerror: 0.000105, testerror: 0.055631\n",
      "Nd: 1789, N: 220,trainingerror: 0.000001, testerror: 0.074277\n",
      "Nd: 1789, N: 256,trainingerror: 0.000000, testerror: 0.053297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 1789, N: 297,trainingerror: 0.000000, testerror: 0.091266\n",
      "Nd: 1789, N: 345,trainingerror: 0.000001, testerror: 0.062224\n",
      "Nd: 1789, N: 400,trainingerror: 0.000000, testerror: 0.085437\n",
      "Nd: 1789, N: 465,trainingerror: 0.000000, testerror: 0.078262\n",
      "Nd: 1789, N: 540,trainingerror: 0.000000, testerror: 0.163187\n",
      "Nd: 1789, N: 627,trainingerror: 0.000001, testerror: 0.076958\n",
      "Nd: 1789, N: 729,trainingerror: 0.000004, testerror: 0.110409\n",
      "Nd: 1789, N: 846,trainingerror: 0.000002, testerror: 0.106828\n",
      "Nd: 1789, N: 983,trainingerror: 0.000338, testerror: 0.138023\n",
      "Nd: 1789, N: 1142,trainingerror: 0.000041, testerror: 0.109861\n",
      "Nd: 1789, N: 1326,trainingerror: 0.000642, testerror: 0.088091\n",
      "Nd: 1789, N: 1541,trainingerror: 0.000510, testerror: 0.108926\n",
      "Nd: 1789, N: 1789,trainingerror: 0.001168, testerror: 0.084560\n",
      "Nd: 1789, N: 2078,trainingerror: 0.001681, testerror: 0.080611\n",
      "Nd: 1789, N: 2414,trainingerror: 0.004315, testerror: 0.064128\n",
      "Nd: 1789, N: 2804,trainingerror: 0.004960, testerror: 0.058051\n",
      "Nd: 1789, N: 3257,trainingerror: 0.005562, testerror: 0.055056\n",
      "Nd: 1789, N: 3783,trainingerror: 0.008723, testerror: 0.052940\n",
      "Nd: 1789, N: 4395,trainingerror: 0.011038, testerror: 0.046080\n",
      "Nd: 1789, N: 5105,trainingerror: 0.011763, testerror: 0.041662\n",
      "Nd: 1789, N: 5930,trainingerror: 0.013672, testerror: 0.038747\n",
      "Nd: 1789, N: 6888,trainingerror: 0.015440, testerror: 0.037260\n",
      "Nd: 2078, N: 20,trainingerror: 0.000000, testerror: 0.054444\n",
      "Nd: 2078, N: 24,trainingerror: 0.000000, testerror: 0.165956\n",
      "Nd: 2078, N: 27,trainingerror: 0.000000, testerror: 0.023285\n",
      "Nd: 2078, N: 32,trainingerror: 0.000000, testerror: 0.102985\n",
      "Nd: 2078, N: 37,trainingerror: 0.000000, testerror: 0.029407\n",
      "Nd: 2078, N: 43,trainingerror: 0.000000, testerror: 0.050578\n",
      "Nd: 2078, N: 50,trainingerror: 0.000000, testerror: 0.014238\n",
      "Nd: 2078, N: 58,trainingerror: 0.000000, testerror: 0.049212\n",
      "Nd: 2078, N: 67,trainingerror: 0.000000, testerror: 0.148338\n",
      "Nd: 2078, N: 78,trainingerror: 0.000013, testerror: 0.055133\n",
      "Nd: 2078, N: 90,trainingerror: 0.000000, testerror: 0.054372\n",
      "Nd: 2078, N: 104,trainingerror: 0.000000, testerror: 0.039315\n",
      "Nd: 2078, N: 121,trainingerror: 0.000030, testerror: 0.036717\n",
      "Nd: 2078, N: 141,trainingerror: 0.000053, testerror: 0.154879\n",
      "Nd: 2078, N: 163,trainingerror: 0.000000, testerror: 0.070251\n",
      "Nd: 2078, N: 190,trainingerror: 0.000000, testerror: 0.054052\n",
      "Nd: 2078, N: 220,trainingerror: 0.000000, testerror: 0.078194\n",
      "Nd: 2078, N: 256,trainingerror: 0.000000, testerror: 0.068397\n",
      "Nd: 2078, N: 297,trainingerror: 0.000000, testerror: 0.152995\n",
      "Nd: 2078, N: 345,trainingerror: 0.000059, testerror: 0.086019\n",
      "Nd: 2078, N: 400,trainingerror: 0.000080, testerror: 0.154787\n",
      "Nd: 2078, N: 465,trainingerror: 0.000000, testerror: 0.054520\n",
      "Nd: 2078, N: 540,trainingerror: 0.000001, testerror: 0.080409\n",
      "Nd: 2078, N: 627,trainingerror: 0.000000, testerror: 0.058531\n",
      "Nd: 2078, N: 729,trainingerror: 0.000000, testerror: 0.074756\n",
      "Nd: 2078, N: 846,trainingerror: 0.000151, testerror: 0.065106\n",
      "Nd: 2078, N: 983,trainingerror: 0.000008, testerror: 0.101606\n",
      "Nd: 2078, N: 1142,trainingerror: 0.000288, testerror: 0.061849\n",
      "Nd: 2078, N: 1326,trainingerror: 0.000132, testerror: 0.069526\n",
      "Nd: 2078, N: 1541,trainingerror: 0.000222, testerror: 0.084546\n",
      "Nd: 2078, N: 1789,trainingerror: 0.000590, testerror: 0.093625\n",
      "Nd: 2078, N: 2078,trainingerror: 0.001077, testerror: 0.071742\n",
      "Nd: 2078, N: 2414,trainingerror: 0.002948, testerror: 0.056516\n",
      "Nd: 2078, N: 2804,trainingerror: 0.003425, testerror: 0.063118\n",
      "Nd: 2078, N: 3257,trainingerror: 0.005524, testerror: 0.053078\n",
      "Nd: 2078, N: 3783,trainingerror: 0.005701, testerror: 0.055749\n",
      "Nd: 2078, N: 4395,trainingerror: 0.009442, testerror: 0.045982\n",
      "Nd: 2078, N: 5105,trainingerror: 0.009754, testerror: 0.045417\n",
      "Nd: 2078, N: 5930,trainingerror: 0.012420, testerror: 0.039240\n",
      "Nd: 2078, N: 6888,trainingerror: 0.015085, testerror: 0.044882\n",
      "Nd: 2414, N: 20,trainingerror: 0.000000, testerror: 0.055388\n",
      "Nd: 2414, N: 24,trainingerror: 0.000000, testerror: 0.042251\n",
      "Nd: 2414, N: 27,trainingerror: 0.000000, testerror: 0.100431\n",
      "Nd: 2414, N: 32,trainingerror: 0.000000, testerror: 0.055272\n",
      "Nd: 2414, N: 37,trainingerror: 0.000000, testerror: 0.070426\n",
      "Nd: 2414, N: 43,trainingerror: 0.000000, testerror: 0.413912\n",
      "Nd: 2414, N: 50,trainingerror: 0.000000, testerror: 0.214930\n",
      "Nd: 2414, N: 58,trainingerror: 0.000000, testerror: 0.094572\n",
      "Nd: 2414, N: 67,trainingerror: 0.000000, testerror: 0.095279\n",
      "Nd: 2414, N: 78,trainingerror: 0.000000, testerror: 0.074104\n",
      "Nd: 2414, N: 90,trainingerror: 0.000000, testerror: 0.195702\n",
      "Nd: 2414, N: 104,trainingerror: 0.000000, testerror: 0.045096\n",
      "Nd: 2414, N: 121,trainingerror: 0.000131, testerror: 0.087420\n",
      "Nd: 2414, N: 141,trainingerror: 0.000000, testerror: 0.043151\n",
      "Nd: 2414, N: 163,trainingerror: 0.000000, testerror: 0.059818\n",
      "Nd: 2414, N: 190,trainingerror: 0.000000, testerror: 0.065025\n",
      "Nd: 2414, N: 220,trainingerror: 0.000005, testerror: 0.050893\n",
      "Nd: 2414, N: 256,trainingerror: 0.000001, testerror: 0.141997\n",
      "Nd: 2414, N: 297,trainingerror: 0.000000, testerror: 0.121163\n",
      "Nd: 2414, N: 345,trainingerror: 0.000000, testerror: 0.422168\n",
      "Nd: 2414, N: 400,trainingerror: 0.000892, testerror: 0.089076\n",
      "Nd: 2414, N: 465,trainingerror: 0.000001, testerror: 0.045561\n",
      "Nd: 2414, N: 540,trainingerror: 0.000001, testerror: 0.062634\n",
      "Nd: 2414, N: 627,trainingerror: 0.000120, testerror: 0.108537\n",
      "Nd: 2414, N: 729,trainingerror: 0.000001, testerror: 0.085941\n",
      "Nd: 2414, N: 846,trainingerror: 0.000001, testerror: 0.114822\n",
      "Nd: 2414, N: 983,trainingerror: 0.000000, testerror: 0.069625\n",
      "Nd: 2414, N: 1142,trainingerror: 0.000232, testerror: 0.113408\n",
      "Nd: 2414, N: 1326,trainingerror: 0.000017, testerror: 0.089502\n",
      "Nd: 2414, N: 1541,trainingerror: 0.000138, testerror: 0.069795\n",
      "Nd: 2414, N: 1789,trainingerror: 0.000398, testerror: 0.084353\n",
      "Nd: 2414, N: 2078,trainingerror: 0.000585, testerror: 0.062511\n",
      "Nd: 2414, N: 2414,trainingerror: 0.001465, testerror: 0.069277\n",
      "Nd: 2414, N: 2804,trainingerror: 0.002118, testerror: 0.061437\n",
      "Nd: 2414, N: 3257,trainingerror: 0.005280, testerror: 0.068737\n",
      "Nd: 2414, N: 3783,trainingerror: 0.005486, testerror: 0.055324\n",
      "Nd: 2414, N: 4395,trainingerror: 0.006548, testerror: 0.046282\n",
      "Nd: 2414, N: 5105,trainingerror: 0.008382, testerror: 0.043795\n",
      "Nd: 2414, N: 5930,trainingerror: 0.009942, testerror: 0.041559\n",
      "Nd: 2414, N: 6888,trainingerror: 0.011637, testerror: 0.041257\n",
      "Nd: 2804, N: 20,trainingerror: 0.000000, testerror: 0.048677\n",
      "Nd: 2804, N: 24,trainingerror: 0.000000, testerror: 0.030205\n",
      "Nd: 2804, N: 27,trainingerror: 0.000000, testerror: 0.046390\n",
      "Nd: 2804, N: 32,trainingerror: 0.000000, testerror: 0.079899\n",
      "Nd: 2804, N: 37,trainingerror: 0.000000, testerror: 0.032782\n",
      "Nd: 2804, N: 43,trainingerror: 0.000000, testerror: 0.038764\n",
      "Nd: 2804, N: 50,trainingerror: 0.000000, testerror: 0.076452\n",
      "Nd: 2804, N: 58,trainingerror: 0.000000, testerror: 0.140283\n",
      "Nd: 2804, N: 67,trainingerror: 0.000001, testerror: 0.153090\n",
      "Nd: 2804, N: 78,trainingerror: 0.000000, testerror: 0.079107\n",
      "Nd: 2804, N: 90,trainingerror: 0.000000, testerror: 0.247903\n",
      "Nd: 2804, N: 104,trainingerror: 0.000000, testerror: 0.035706\n",
      "Nd: 2804, N: 121,trainingerror: 0.000000, testerror: 0.182327\n",
      "Nd: 2804, N: 141,trainingerror: 0.000000, testerror: 0.118024\n",
      "Nd: 2804, N: 163,trainingerror: 0.000001, testerror: 0.187684\n",
      "Nd: 2804, N: 190,trainingerror: 0.000000, testerror: 0.078487\n",
      "Nd: 2804, N: 220,trainingerror: 0.000000, testerror: 0.047738\n",
      "Nd: 2804, N: 256,trainingerror: 0.000028, testerror: 0.176512\n",
      "Nd: 2804, N: 297,trainingerror: 0.000000, testerror: 0.074175\n",
      "Nd: 2804, N: 345,trainingerror: 0.000000, testerror: 0.116491\n",
      "Nd: 2804, N: 400,trainingerror: 0.000000, testerror: 0.135514\n",
      "Nd: 2804, N: 465,trainingerror: 0.000000, testerror: 0.061723\n",
      "Nd: 2804, N: 540,trainingerror: 0.000000, testerror: 0.081099\n",
      "Nd: 2804, N: 627,trainingerror: 0.000011, testerror: 0.068582\n",
      "Nd: 2804, N: 729,trainingerror: 0.000000, testerror: 0.076194\n",
      "Nd: 2804, N: 846,trainingerror: 0.000000, testerror: 0.095992\n",
      "Nd: 2804, N: 983,trainingerror: 0.000007, testerror: 0.095147\n",
      "Nd: 2804, N: 1142,trainingerror: 0.000010, testerror: 0.103173\n",
      "Nd: 2804, N: 1326,trainingerror: 0.000002, testerror: 0.078502\n",
      "Nd: 2804, N: 1541,trainingerror: 0.000031, testerror: 0.079320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 2804, N: 1789,trainingerror: 0.000470, testerror: 0.072889\n",
      "Nd: 2804, N: 2078,trainingerror: 0.000583, testerror: 0.108992\n",
      "Nd: 2804, N: 2414,trainingerror: 0.000880, testerror: 0.110081\n",
      "Nd: 2804, N: 2804,trainingerror: 0.001424, testerror: 0.062788\n",
      "Nd: 2804, N: 3257,trainingerror: 0.002749, testerror: 0.065688\n",
      "Nd: 2804, N: 3783,trainingerror: 0.004056, testerror: 0.051450\n",
      "Nd: 2804, N: 4395,trainingerror: 0.005644, testerror: 0.050816\n",
      "Nd: 2804, N: 5105,trainingerror: 0.007652, testerror: 0.045929\n",
      "Nd: 2804, N: 5930,trainingerror: 0.009662, testerror: 0.041792\n",
      "Nd: 2804, N: 6888,trainingerror: 0.010330, testerror: 0.041374\n",
      "Nd: 3257, N: 20,trainingerror: 0.000000, testerror: 0.191750\n",
      "Nd: 3257, N: 24,trainingerror: 0.000000, testerror: 0.113021\n",
      "Nd: 3257, N: 27,trainingerror: 0.000000, testerror: 0.033046\n",
      "Nd: 3257, N: 32,trainingerror: 0.000000, testerror: 0.144901\n",
      "Nd: 3257, N: 37,trainingerror: 0.000000, testerror: 0.220251\n",
      "Nd: 3257, N: 43,trainingerror: 0.000000, testerror: 0.065270\n",
      "Nd: 3257, N: 50,trainingerror: 0.000000, testerror: 0.028982\n",
      "Nd: 3257, N: 58,trainingerror: 0.000000, testerror: 0.043274\n",
      "Nd: 3257, N: 67,trainingerror: 0.000000, testerror: 0.085131\n",
      "Nd: 3257, N: 78,trainingerror: 0.000000, testerror: 0.224294\n",
      "Nd: 3257, N: 90,trainingerror: 0.000001, testerror: 0.046483\n",
      "Nd: 3257, N: 104,trainingerror: 0.000002, testerror: 0.182456\n",
      "Nd: 3257, N: 121,trainingerror: 0.000000, testerror: 0.108992\n",
      "Nd: 3257, N: 141,trainingerror: 0.000009, testerror: 0.055784\n",
      "Nd: 3257, N: 163,trainingerror: 0.000000, testerror: 0.059663\n",
      "Nd: 3257, N: 190,trainingerror: 0.000000, testerror: 0.062554\n",
      "Nd: 3257, N: 220,trainingerror: 0.000000, testerror: 0.075097\n",
      "Nd: 3257, N: 256,trainingerror: 0.000000, testerror: 0.164633\n",
      "Nd: 3257, N: 297,trainingerror: 0.000000, testerror: 0.068439\n",
      "Nd: 3257, N: 345,trainingerror: 0.000000, testerror: 0.086460\n",
      "Nd: 3257, N: 400,trainingerror: 0.000000, testerror: 0.058734\n",
      "Nd: 3257, N: 465,trainingerror: 0.000090, testerror: 0.045481\n",
      "Nd: 3257, N: 540,trainingerror: 0.000116, testerror: 0.068319\n",
      "Nd: 3257, N: 627,trainingerror: 0.000003, testerror: 0.183696\n",
      "Nd: 3257, N: 729,trainingerror: 0.000000, testerror: 0.072315\n",
      "Nd: 3257, N: 846,trainingerror: 0.000013, testerror: 0.088959\n",
      "Nd: 3257, N: 983,trainingerror: 0.000152, testerror: 0.058137\n",
      "Nd: 3257, N: 1142,trainingerror: 0.000833, testerror: 0.085601\n",
      "Nd: 3257, N: 1326,trainingerror: 0.000016, testerror: 0.085040\n",
      "Nd: 3257, N: 1541,trainingerror: 0.000007, testerror: 0.060514\n",
      "Nd: 3257, N: 1789,trainingerror: 0.000069, testerror: 0.084842\n",
      "Nd: 3257, N: 2078,trainingerror: 0.000162, testerror: 0.084799\n",
      "Nd: 3257, N: 2414,trainingerror: 0.000366, testerror: 0.064233\n",
      "Nd: 3257, N: 2804,trainingerror: 0.002157, testerror: 0.059707\n",
      "Nd: 3257, N: 3257,trainingerror: 0.002239, testerror: 0.055713\n",
      "Nd: 3257, N: 3783,trainingerror: 0.002653, testerror: 0.050753\n",
      "Nd: 3257, N: 4395,trainingerror: 0.004155, testerror: 0.057746\n",
      "Nd: 3257, N: 5105,trainingerror: 0.005920, testerror: 0.048353\n",
      "Nd: 3257, N: 5930,trainingerror: 0.006590, testerror: 0.049016\n",
      "Nd: 3257, N: 6888,trainingerror: 0.009384, testerror: 0.044692\n",
      "Nd: 3783, N: 20,trainingerror: 0.000000, testerror: 0.042250\n",
      "Nd: 3783, N: 24,trainingerror: 0.000000, testerror: 0.161810\n",
      "Nd: 3783, N: 27,trainingerror: 0.000000, testerror: 0.016686\n",
      "Nd: 3783, N: 32,trainingerror: 0.000005, testerror: 0.022942\n",
      "Nd: 3783, N: 37,trainingerror: 0.000000, testerror: 0.047208\n",
      "Nd: 3783, N: 43,trainingerror: 0.000000, testerror: 0.062511\n",
      "Nd: 3783, N: 50,trainingerror: 0.000002, testerror: 0.217143\n",
      "Nd: 3783, N: 58,trainingerror: 0.000000, testerror: 0.036139\n",
      "Nd: 3783, N: 67,trainingerror: 0.000000, testerror: 0.067668\n",
      "Nd: 3783, N: 78,trainingerror: 0.000000, testerror: 0.078304\n",
      "Nd: 3783, N: 90,trainingerror: 0.000000, testerror: 0.139220\n",
      "Nd: 3783, N: 104,trainingerror: 0.000000, testerror: 0.071707\n",
      "Nd: 3783, N: 121,trainingerror: 0.000000, testerror: 0.021813\n",
      "Nd: 3783, N: 141,trainingerror: 0.000000, testerror: 0.070024\n",
      "Nd: 3783, N: 163,trainingerror: 0.000000, testerror: 0.086090\n",
      "Nd: 3783, N: 190,trainingerror: 0.000001, testerror: 0.208727\n",
      "Nd: 3783, N: 220,trainingerror: 0.000005, testerror: 0.057346\n",
      "Nd: 3783, N: 256,trainingerror: 0.000142, testerror: 0.082748\n",
      "Nd: 3783, N: 297,trainingerror: 0.000000, testerror: 0.133391\n",
      "Nd: 3783, N: 345,trainingerror: 0.000000, testerror: 0.073450\n",
      "Nd: 3783, N: 400,trainingerror: 0.000000, testerror: 0.078067\n",
      "Nd: 3783, N: 465,trainingerror: 0.000017, testerror: 0.058583\n",
      "Nd: 3783, N: 540,trainingerror: 0.000000, testerror: 0.058847\n",
      "Nd: 3783, N: 627,trainingerror: 0.000019, testerror: 0.109401\n",
      "Nd: 3783, N: 729,trainingerror: 0.000000, testerror: 0.072155\n",
      "Nd: 3783, N: 846,trainingerror: 0.000007, testerror: 0.082614\n",
      "Nd: 3783, N: 983,trainingerror: 0.000000, testerror: 0.082439\n",
      "Nd: 3783, N: 1142,trainingerror: 0.000001, testerror: 0.096899\n",
      "Nd: 3783, N: 1326,trainingerror: 0.000001, testerror: 0.069272\n",
      "Nd: 3783, N: 1541,trainingerror: 0.000419, testerror: 0.062763\n",
      "Nd: 3783, N: 1789,trainingerror: 0.000073, testerror: 0.065236\n",
      "Nd: 3783, N: 2078,trainingerror: 0.000050, testerror: 0.066757\n",
      "Nd: 3783, N: 2414,trainingerror: 0.000200, testerror: 0.060187\n",
      "Nd: 3783, N: 2804,trainingerror: 0.000466, testerror: 0.068228\n",
      "Nd: 3783, N: 3257,trainingerror: 0.001076, testerror: 0.053773\n",
      "Nd: 3783, N: 3783,trainingerror: 0.001491, testerror: 0.056220\n",
      "Nd: 3783, N: 4395,trainingerror: 0.003002, testerror: 0.057375\n",
      "Nd: 3783, N: 5105,trainingerror: 0.004574, testerror: 0.048399\n",
      "Nd: 3783, N: 5930,trainingerror: 0.005623, testerror: 0.048881\n",
      "Nd: 3783, N: 6888,trainingerror: 0.006618, testerror: 0.044204\n",
      "Nd: 4395, N: 20,trainingerror: 0.000000, testerror: 0.007111\n",
      "Nd: 4395, N: 24,trainingerror: 0.000000, testerror: 0.038178\n",
      "Nd: 4395, N: 27,trainingerror: 0.000000, testerror: 0.096315\n",
      "Nd: 4395, N: 32,trainingerror: 0.000000, testerror: 0.023713\n",
      "Nd: 4395, N: 37,trainingerror: 0.000000, testerror: 0.035337\n",
      "Nd: 4395, N: 43,trainingerror: 0.000001, testerror: 0.054214\n",
      "Nd: 4395, N: 50,trainingerror: 0.000000, testerror: 0.031395\n",
      "Nd: 4395, N: 58,trainingerror: 0.000000, testerror: 0.048890\n",
      "Nd: 4395, N: 67,trainingerror: 0.000000, testerror: 0.030694\n",
      "Nd: 4395, N: 78,trainingerror: 0.000000, testerror: 0.055999\n",
      "Nd: 4395, N: 90,trainingerror: 0.000000, testerror: 0.103376\n",
      "Nd: 4395, N: 104,trainingerror: 0.000000, testerror: 0.103894\n",
      "Nd: 4395, N: 121,trainingerror: 0.000000, testerror: 0.101059\n",
      "Nd: 4395, N: 141,trainingerror: 0.000004, testerror: 0.035686\n",
      "Nd: 4395, N: 163,trainingerror: 0.000000, testerror: 0.080453\n",
      "Nd: 4395, N: 190,trainingerror: 0.000000, testerror: 0.217902\n",
      "Nd: 4395, N: 220,trainingerror: 0.000186, testerror: 0.218336\n",
      "Nd: 4395, N: 256,trainingerror: 0.000000, testerror: 0.158836\n",
      "Nd: 4395, N: 297,trainingerror: 0.000000, testerror: 0.088594\n",
      "Nd: 4395, N: 345,trainingerror: 0.000000, testerror: 0.062095\n",
      "Nd: 4395, N: 400,trainingerror: 0.000000, testerror: 0.095372\n",
      "Nd: 4395, N: 465,trainingerror: 0.000000, testerror: 0.062629\n",
      "Nd: 4395, N: 540,trainingerror: 0.000000, testerror: 0.090396\n",
      "Nd: 4395, N: 627,trainingerror: 0.000004, testerror: 0.076831\n",
      "Nd: 4395, N: 729,trainingerror: 0.000000, testerror: 0.067089\n",
      "Nd: 4395, N: 846,trainingerror: 0.000000, testerror: 0.085626\n",
      "Nd: 4395, N: 983,trainingerror: 0.000008, testerror: 0.114338\n",
      "Nd: 4395, N: 1142,trainingerror: 0.000002, testerror: 0.147698\n",
      "Nd: 4395, N: 1326,trainingerror: 0.000001, testerror: 0.079972\n",
      "Nd: 4395, N: 1541,trainingerror: 0.000008, testerror: 0.063318\n",
      "Nd: 4395, N: 1789,trainingerror: 0.000005, testerror: 0.072083\n",
      "Nd: 4395, N: 2078,trainingerror: 0.000053, testerror: 0.063698\n",
      "Nd: 4395, N: 2414,trainingerror: 0.000131, testerror: 0.081933\n",
      "Nd: 4395, N: 2804,trainingerror: 0.000165, testerror: 0.054375\n",
      "Nd: 4395, N: 3257,trainingerror: 0.000850, testerror: 0.070581\n",
      "Nd: 4395, N: 3783,trainingerror: 0.001148, testerror: 0.061762\n",
      "Nd: 4395, N: 4395,trainingerror: 0.002438, testerror: 0.054274\n",
      "Nd: 4395, N: 5105,trainingerror: 0.003599, testerror: 0.053896\n",
      "Nd: 4395, N: 5930,trainingerror: 0.004606, testerror: 0.048370\n",
      "Nd: 4395, N: 6888,trainingerror: 0.006961, testerror: 0.044161\n",
      "Nd: 5105, N: 20,trainingerror: 0.000000, testerror: 0.033838\n",
      "Nd: 5105, N: 24,trainingerror: 0.000000, testerror: 0.307352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 5105, N: 27,trainingerror: 0.000000, testerror: 0.897727\n",
      "Nd: 5105, N: 32,trainingerror: 0.000000, testerror: 0.267843\n",
      "Nd: 5105, N: 37,trainingerror: 0.000004, testerror: 0.014154\n",
      "Nd: 5105, N: 43,trainingerror: 0.000000, testerror: 0.147876\n",
      "Nd: 5105, N: 50,trainingerror: 0.000000, testerror: 0.181039\n",
      "Nd: 5105, N: 58,trainingerror: 0.000000, testerror: 0.045823\n",
      "Nd: 5105, N: 67,trainingerror: 0.000000, testerror: 0.053909\n",
      "Nd: 5105, N: 78,trainingerror: 0.000000, testerror: 0.110281\n",
      "Nd: 5105, N: 90,trainingerror: 0.000000, testerror: 0.162364\n",
      "Nd: 5105, N: 104,trainingerror: 0.000000, testerror: 0.129206\n",
      "Nd: 5105, N: 121,trainingerror: 0.000005, testerror: 0.121382\n",
      "Nd: 5105, N: 141,trainingerror: 0.000013, testerror: 0.046198\n",
      "Nd: 5105, N: 163,trainingerror: 0.000001, testerror: 0.079709\n",
      "Nd: 5105, N: 190,trainingerror: 0.000006, testerror: 0.153685\n",
      "Nd: 5105, N: 220,trainingerror: 0.000000, testerror: 0.060875\n",
      "Nd: 5105, N: 256,trainingerror: 0.000004, testerror: 0.095697\n",
      "Nd: 5105, N: 297,trainingerror: 0.000003, testerror: 0.058867\n",
      "Nd: 5105, N: 345,trainingerror: 0.000000, testerror: 0.104727\n",
      "Nd: 5105, N: 400,trainingerror: 0.000000, testerror: 0.077083\n",
      "Nd: 5105, N: 465,trainingerror: 0.000000, testerror: 0.086285\n",
      "Nd: 5105, N: 540,trainingerror: 0.000000, testerror: 0.089361\n",
      "Nd: 5105, N: 627,trainingerror: 0.000029, testerror: 0.134245\n",
      "Nd: 5105, N: 729,trainingerror: 0.000033, testerror: 0.088605\n",
      "Nd: 5105, N: 846,trainingerror: 0.000000, testerror: 0.081164\n",
      "Nd: 5105, N: 983,trainingerror: 0.000001, testerror: 0.127863\n",
      "Nd: 5105, N: 1142,trainingerror: 0.000000, testerror: 0.063162\n",
      "Nd: 5105, N: 1326,trainingerror: 0.000007, testerror: 0.087266\n",
      "Nd: 5105, N: 1541,trainingerror: 0.000000, testerror: 0.064802\n",
      "Nd: 5105, N: 1789,trainingerror: 0.000001, testerror: 0.068508\n",
      "Nd: 5105, N: 2078,trainingerror: 0.000132, testerror: 0.075014\n",
      "Nd: 5105, N: 2414,trainingerror: 0.000059, testerror: 0.055513\n",
      "Nd: 5105, N: 2804,trainingerror: 0.000236, testerror: 0.051114\n",
      "Nd: 5105, N: 3257,trainingerror: 0.001136, testerror: 0.061952\n",
      "Nd: 5105, N: 3783,trainingerror: 0.001150, testerror: 0.054969\n",
      "Nd: 5105, N: 4395,trainingerror: 0.001786, testerror: 0.054472\n",
      "Nd: 5105, N: 5105,trainingerror: 0.002674, testerror: 0.048096\n",
      "Nd: 5105, N: 5930,trainingerror: 0.003635, testerror: 0.045877\n",
      "Nd: 5105, N: 6888,trainingerror: 0.005078, testerror: 0.043441\n",
      "Nd: 5930, N: 20,trainingerror: 0.000000, testerror: 0.101683\n",
      "Nd: 5930, N: 24,trainingerror: 0.000000, testerror: 0.040756\n",
      "Nd: 5930, N: 27,trainingerror: 0.000000, testerror: 0.188827\n",
      "Nd: 5930, N: 32,trainingerror: 0.000000, testerror: 0.316144\n",
      "Nd: 5930, N: 37,trainingerror: 0.000000, testerror: 0.059483\n",
      "Nd: 5930, N: 43,trainingerror: 0.000000, testerror: 0.072225\n",
      "Nd: 5930, N: 50,trainingerror: 0.000000, testerror: 0.179633\n",
      "Nd: 5930, N: 58,trainingerror: 0.000000, testerror: 0.041595\n",
      "Nd: 5930, N: 67,trainingerror: 0.000000, testerror: 0.031200\n",
      "Nd: 5930, N: 78,trainingerror: 0.000000, testerror: 0.089599\n",
      "Nd: 5930, N: 90,trainingerror: 0.000000, testerror: 0.089902\n",
      "Nd: 5930, N: 104,trainingerror: 0.000000, testerror: 0.034263\n",
      "Nd: 5930, N: 121,trainingerror: 0.000005, testerror: 0.129183\n",
      "Nd: 5930, N: 141,trainingerror: 0.000016, testerror: 0.095389\n",
      "Nd: 5930, N: 163,trainingerror: 0.000000, testerror: 0.055229\n",
      "Nd: 5930, N: 190,trainingerror: 0.000000, testerror: 0.110330\n",
      "Nd: 5930, N: 220,trainingerror: 0.000000, testerror: 0.125445\n",
      "Nd: 5930, N: 256,trainingerror: 0.000000, testerror: 0.092273\n",
      "Nd: 5930, N: 297,trainingerror: 0.000000, testerror: 0.096487\n",
      "Nd: 5930, N: 345,trainingerror: 0.000000, testerror: 0.048132\n",
      "Nd: 5930, N: 400,trainingerror: 0.000000, testerror: 0.093488\n",
      "Nd: 5930, N: 465,trainingerror: 0.000000, testerror: 0.080597\n",
      "Nd: 5930, N: 540,trainingerror: 0.000000, testerror: 0.113531\n",
      "Nd: 5930, N: 627,trainingerror: 0.000000, testerror: 0.145743\n",
      "Nd: 5930, N: 729,trainingerror: 0.000000, testerror: 0.066992\n",
      "Nd: 5930, N: 846,trainingerror: 0.000000, testerror: 0.068761\n",
      "Nd: 5930, N: 983,trainingerror: 0.000003, testerror: 0.068155\n",
      "Nd: 5930, N: 1142,trainingerror: 0.000057, testerror: 0.123234\n",
      "Nd: 5930, N: 1326,trainingerror: 0.000000, testerror: 0.061432\n",
      "Nd: 5930, N: 1541,trainingerror: 0.000024, testerror: 0.066629\n",
      "Nd: 5930, N: 1789,trainingerror: 0.000000, testerror: 0.063340\n",
      "Nd: 5930, N: 2078,trainingerror: 0.000003, testerror: 0.089782\n",
      "Nd: 5930, N: 2414,trainingerror: 0.000123, testerror: 0.069496\n",
      "Nd: 5930, N: 2804,trainingerror: 0.000698, testerror: 0.054239\n",
      "Nd: 5930, N: 3257,trainingerror: 0.000371, testerror: 0.052888\n",
      "Nd: 5930, N: 3783,trainingerror: 0.000528, testerror: 0.053503\n",
      "Nd: 5930, N: 4395,trainingerror: 0.001276, testerror: 0.051991\n",
      "Nd: 5930, N: 5105,trainingerror: 0.001729, testerror: 0.046967\n",
      "Nd: 5930, N: 5930,trainingerror: 0.004082, testerror: 0.052053\n",
      "Nd: 5930, N: 6888,trainingerror: 0.004015, testerror: 0.046312\n",
      "Nd: 6888, N: 20,trainingerror: 0.000000, testerror: 0.014005\n",
      "Nd: 6888, N: 24,trainingerror: 0.000000, testerror: 0.066140\n",
      "Nd: 6888, N: 27,trainingerror: 0.000001, testerror: 0.247464\n",
      "Nd: 6888, N: 32,trainingerror: 0.000000, testerror: 0.096581\n",
      "Nd: 6888, N: 37,trainingerror: 0.000000, testerror: 0.078842\n",
      "Nd: 6888, N: 43,trainingerror: 0.000000, testerror: 0.042706\n",
      "Nd: 6888, N: 50,trainingerror: 0.000000, testerror: 0.030032\n",
      "Nd: 6888, N: 58,trainingerror: 0.000000, testerror: 0.455994\n",
      "Nd: 6888, N: 67,trainingerror: 0.000000, testerror: 0.128661\n",
      "Nd: 6888, N: 78,trainingerror: 0.000000, testerror: 0.040728\n",
      "Nd: 6888, N: 90,trainingerror: 0.000000, testerror: 0.131589\n",
      "Nd: 6888, N: 104,trainingerror: 0.000000, testerror: 0.048689\n",
      "Nd: 6888, N: 121,trainingerror: 0.000038, testerror: 0.018234\n",
      "Nd: 6888, N: 141,trainingerror: 0.000000, testerror: 0.044483\n",
      "Nd: 6888, N: 163,trainingerror: 0.000188, testerror: 0.086676\n",
      "Nd: 6888, N: 190,trainingerror: 0.000000, testerror: 0.041910\n",
      "Nd: 6888, N: 220,trainingerror: 0.000000, testerror: 0.107036\n",
      "Nd: 6888, N: 256,trainingerror: 0.000000, testerror: 0.078405\n",
      "Nd: 6888, N: 297,trainingerror: 0.000000, testerror: 0.057545\n",
      "Nd: 6888, N: 345,trainingerror: 0.000000, testerror: 0.323650\n",
      "Nd: 6888, N: 400,trainingerror: 0.000002, testerror: 0.071878\n",
      "Nd: 6888, N: 465,trainingerror: 0.000001, testerror: 0.094252\n",
      "Nd: 6888, N: 540,trainingerror: 0.000001, testerror: 0.061357\n",
      "Nd: 6888, N: 627,trainingerror: 0.000001, testerror: 0.079902\n",
      "Nd: 6888, N: 729,trainingerror: 0.000000, testerror: 0.065594\n",
      "Nd: 6888, N: 846,trainingerror: 0.000000, testerror: 0.075004\n",
      "Nd: 6888, N: 983,trainingerror: 0.000223, testerror: 0.074933\n",
      "Nd: 6888, N: 1142,trainingerror: 0.000000, testerror: 0.058218\n",
      "Nd: 6888, N: 1326,trainingerror: 0.000000, testerror: 0.086203\n",
      "Nd: 6888, N: 1541,trainingerror: 0.000000, testerror: 0.112745\n",
      "Nd: 6888, N: 1789,trainingerror: 0.000001, testerror: 0.052790\n",
      "Nd: 6888, N: 2078,trainingerror: 0.000001, testerror: 0.059568\n",
      "Nd: 6888, N: 2414,trainingerror: 0.000007, testerror: 0.081305\n",
      "Nd: 6888, N: 2804,trainingerror: 0.000066, testerror: 0.059962\n",
      "Nd: 6888, N: 3257,trainingerror: 0.000091, testerror: 0.059656\n",
      "Nd: 6888, N: 3783,trainingerror: 0.000813, testerror: 0.053542\n",
      "Nd: 6888, N: 4395,trainingerror: 0.000490, testerror: 0.054878\n",
      "Nd: 6888, N: 5105,trainingerror: 0.001113, testerror: 0.049128\n",
      "Nd: 6888, N: 5930,trainingerror: 0.002205, testerror: 0.049276\n",
      "Nd: 6888, N: 6888,trainingerror: 0.003420, testerror: 0.048850\n",
      "Nd: 8000, N: 20,trainingerror: 0.000006, testerror: 0.102561\n",
      "Nd: 8000, N: 24,trainingerror: 0.000000, testerror: 0.183676\n",
      "Nd: 8000, N: 27,trainingerror: 0.000000, testerror: 0.067121\n",
      "Nd: 8000, N: 32,trainingerror: 0.000000, testerror: 0.065847\n",
      "Nd: 8000, N: 37,trainingerror: 0.000000, testerror: 0.020451\n",
      "Nd: 8000, N: 43,trainingerror: 0.000000, testerror: 0.035946\n",
      "Nd: 8000, N: 50,trainingerror: 0.000000, testerror: 0.049536\n",
      "Nd: 8000, N: 58,trainingerror: 0.000000, testerror: 0.075631\n",
      "Nd: 8000, N: 67,trainingerror: 0.000000, testerror: 0.023621\n",
      "Nd: 8000, N: 78,trainingerror: 0.000000, testerror: 0.080272\n",
      "Nd: 8000, N: 90,trainingerror: 0.000000, testerror: 0.031366\n",
      "Nd: 8000, N: 104,trainingerror: 0.000241, testerror: 0.055787\n",
      "Nd: 8000, N: 121,trainingerror: 0.000000, testerror: 0.151816\n",
      "Nd: 8000, N: 141,trainingerror: 0.000000, testerror: 0.042191\n",
      "Nd: 8000, N: 163,trainingerror: 0.000000, testerror: 0.308026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 8000, N: 190,trainingerror: 0.000000, testerror: 0.108062\n",
      "Nd: 8000, N: 220,trainingerror: 0.000000, testerror: 0.081436\n",
      "Nd: 8000, N: 256,trainingerror: 0.000000, testerror: 0.066099\n",
      "Nd: 8000, N: 297,trainingerror: 0.000000, testerror: 0.075195\n",
      "Nd: 8000, N: 345,trainingerror: 0.000000, testerror: 0.193032\n",
      "Nd: 8000, N: 400,trainingerror: 0.000000, testerror: 0.130585\n",
      "Nd: 8000, N: 465,trainingerror: 0.000001, testerror: 0.108255\n",
      "Nd: 8000, N: 540,trainingerror: 0.000000, testerror: 0.083923\n",
      "Nd: 8000, N: 627,trainingerror: 0.000000, testerror: 0.062988\n",
      "Nd: 8000, N: 729,trainingerror: 0.000001, testerror: 0.058770\n",
      "Nd: 8000, N: 846,trainingerror: 0.000011, testerror: 0.129523\n",
      "Nd: 8000, N: 983,trainingerror: 0.000000, testerror: 0.054388\n",
      "Nd: 8000, N: 1142,trainingerror: 0.000000, testerror: 0.088049\n",
      "Nd: 8000, N: 1326,trainingerror: 0.000005, testerror: 0.068278\n",
      "Nd: 8000, N: 1541,trainingerror: 0.000534, testerror: 0.058932\n",
      "Nd: 8000, N: 1789,trainingerror: 0.000000, testerror: 0.065180\n",
      "Nd: 8000, N: 2078,trainingerror: 0.000281, testerror: 0.053894\n",
      "Nd: 8000, N: 2414,trainingerror: 0.000014, testerror: 0.053366\n",
      "Nd: 8000, N: 2804,trainingerror: 0.000007, testerror: 0.058309\n",
      "Nd: 8000, N: 3257,trainingerror: 0.000077, testerror: 0.068577\n",
      "Nd: 8000, N: 3783,trainingerror: 0.000397, testerror: 0.058551\n",
      "Nd: 8000, N: 4395,trainingerror: 0.000288, testerror: 0.055115\n",
      "Nd: 8000, N: 5105,trainingerror: 0.001118, testerror: 0.049628\n",
      "Nd: 8000, N: 5930,trainingerror: 0.001537, testerror: 0.047339\n",
      "Nd: 8000, N: 6888,trainingerror: 0.003416, testerror: 0.054936\n",
      "Nd: 9293, N: 20,trainingerror: 0.000000, testerror: 0.011729\n",
      "Nd: 9293, N: 24,trainingerror: 0.000000, testerror: 0.012636\n",
      "Nd: 9293, N: 27,trainingerror: 0.000000, testerror: 0.036273\n",
      "Nd: 9293, N: 32,trainingerror: 0.000000, testerror: 0.168479\n",
      "Nd: 9293, N: 37,trainingerror: 0.000000, testerror: 0.136387\n",
      "Nd: 9293, N: 43,trainingerror: 0.000000, testerror: 0.938868\n",
      "Nd: 9293, N: 50,trainingerror: 0.000000, testerror: 0.361744\n",
      "Nd: 9293, N: 58,trainingerror: 0.000000, testerror: 0.018871\n",
      "Nd: 9293, N: 67,trainingerror: 0.000000, testerror: 0.056760\n",
      "Nd: 9293, N: 78,trainingerror: 0.000005, testerror: 0.095431\n",
      "Nd: 9293, N: 90,trainingerror: 0.000000, testerror: 0.117626\n",
      "Nd: 9293, N: 104,trainingerror: 0.000001, testerror: 0.448733\n",
      "Nd: 9293, N: 121,trainingerror: 0.000000, testerror: 0.042710\n",
      "Nd: 9293, N: 141,trainingerror: 0.000000, testerror: 0.060989\n",
      "Nd: 9293, N: 163,trainingerror: 0.000000, testerror: 0.066498\n",
      "Nd: 9293, N: 190,trainingerror: 0.000000, testerror: 0.094445\n",
      "Nd: 9293, N: 220,trainingerror: 0.000000, testerror: 0.074018\n",
      "Nd: 9293, N: 256,trainingerror: 0.000000, testerror: 0.063984\n",
      "Nd: 9293, N: 297,trainingerror: 0.000003, testerror: 0.114818\n",
      "Nd: 9293, N: 345,trainingerror: 0.000001, testerror: 0.065769\n",
      "Nd: 9293, N: 400,trainingerror: 0.000000, testerror: 0.075165\n",
      "Nd: 9293, N: 465,trainingerror: 0.000101, testerror: 0.180125\n",
      "Nd: 9293, N: 540,trainingerror: 0.000000, testerror: 0.089130\n",
      "Nd: 9293, N: 627,trainingerror: 0.000000, testerror: 0.066469\n",
      "Nd: 9293, N: 729,trainingerror: 0.000007, testerror: 0.109666\n",
      "Nd: 9293, N: 846,trainingerror: 0.000000, testerror: 0.081371\n",
      "Nd: 9293, N: 983,trainingerror: 0.000168, testerror: 0.072367\n",
      "Nd: 9293, N: 1142,trainingerror: 0.000001, testerror: 0.052497\n",
      "Nd: 9293, N: 1326,trainingerror: 0.000000, testerror: 0.071791\n",
      "Nd: 9293, N: 1541,trainingerror: 0.000003, testerror: 0.057143\n",
      "Nd: 9293, N: 1789,trainingerror: 0.000074, testerror: 0.063211\n",
      "Nd: 9293, N: 2078,trainingerror: 0.000000, testerror: 0.063195\n",
      "Nd: 9293, N: 2414,trainingerror: 0.000034, testerror: 0.072115\n",
      "Nd: 9293, N: 2804,trainingerror: 0.000014, testerror: 0.052352\n",
      "Nd: 9293, N: 3257,trainingerror: 0.000064, testerror: 0.052806\n",
      "Nd: 9293, N: 3783,trainingerror: 0.000368, testerror: 0.049991\n",
      "Nd: 9293, N: 4395,trainingerror: 0.000493, testerror: 0.049302\n",
      "Nd: 9293, N: 5105,trainingerror: 0.000680, testerror: 0.048079\n",
      "Nd: 9293, N: 5930,trainingerror: 0.001150, testerror: 0.047958\n",
      "Nd: 9293, N: 6888,trainingerror: 0.002074, testerror: 0.041891\n",
      "Nd: 10795, N: 20,trainingerror: 0.000000, testerror: 0.071942\n",
      "Nd: 10795, N: 24,trainingerror: 0.000000, testerror: 0.070091\n",
      "Nd: 10795, N: 27,trainingerror: 0.000001, testerror: 0.081753\n",
      "Nd: 10795, N: 32,trainingerror: 0.000000, testerror: 0.139559\n",
      "Nd: 10795, N: 37,trainingerror: 0.000000, testerror: 0.130998\n",
      "Nd: 10795, N: 43,trainingerror: 0.000015, testerror: 0.042043\n",
      "Nd: 10795, N: 50,trainingerror: 0.000000, testerror: 0.072212\n",
      "Nd: 10795, N: 58,trainingerror: 0.000000, testerror: 0.059604\n",
      "Nd: 10795, N: 67,trainingerror: 0.000000, testerror: 0.058914\n",
      "Nd: 10795, N: 78,trainingerror: 0.000000, testerror: 0.088525\n",
      "Nd: 10795, N: 90,trainingerror: 0.000000, testerror: 0.305608\n",
      "Nd: 10795, N: 104,trainingerror: 0.000892, testerror: 0.076502\n",
      "Nd: 10795, N: 121,trainingerror: 0.000000, testerror: 0.090612\n",
      "Nd: 10795, N: 141,trainingerror: 0.000000, testerror: 0.048114\n",
      "Nd: 10795, N: 163,trainingerror: 0.000000, testerror: 0.053502\n",
      "Nd: 10795, N: 190,trainingerror: 0.001314, testerror: 0.059878\n",
      "Nd: 10795, N: 220,trainingerror: 0.000000, testerror: 0.097268\n",
      "Nd: 10795, N: 256,trainingerror: 0.000000, testerror: 0.125113\n",
      "Nd: 10795, N: 297,trainingerror: 0.000000, testerror: 0.068723\n",
      "Nd: 10795, N: 345,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 400,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 465,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 540,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 627,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 729,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 846,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 983,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 1142,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 1326,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 1541,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 1789,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 2078,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 2414,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 2804,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 3257,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 3783,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 4395,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 5105,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 5930,trainingerror: nan, testerror: nan\n",
      "Nd: 10795, N: 6888,trainingerror: nan, testerror: nan\n",
      "Nd: 12539, N: 20,trainingerror: 0.000000, testerror: 0.094624\n",
      "Nd: 12539, N: 24,trainingerror: 0.000000, testerror: 0.013581\n",
      "Nd: 12539, N: 27,trainingerror: 0.000000, testerror: 0.052810\n",
      "Nd: 12539, N: 32,trainingerror: 0.000000, testerror: 0.038194\n",
      "Nd: 12539, N: 37,trainingerror: 0.000000, testerror: 0.040350\n",
      "Nd: 12539, N: 43,trainingerror: 0.000000, testerror: 0.109329\n",
      "Nd: 12539, N: 50,trainingerror: 0.000000, testerror: 0.060583\n",
      "Nd: 12539, N: 58,trainingerror: 0.000000, testerror: 0.068155\n",
      "Nd: 12539, N: 67,trainingerror: 0.000000, testerror: 0.057944\n",
      "Nd: 12539, N: 78,trainingerror: 0.000000, testerror: 0.030656\n",
      "Nd: 12539, N: 90,trainingerror: 0.000000, testerror: 0.064426\n",
      "Nd: 12539, N: 104,trainingerror: 0.000008, testerror: 0.073532\n",
      "Nd: 12539, N: 121,trainingerror: 0.000000, testerror: 0.085433\n",
      "Nd: 12539, N: 141,trainingerror: 0.000000, testerror: 0.058314\n",
      "Nd: 12539, N: 163,trainingerror: 0.000000, testerror: 0.050828\n",
      "Nd: 12539, N: 190,trainingerror: 0.000000, testerror: 0.055951\n",
      "Nd: 12539, N: 220,trainingerror: 0.000000, testerror: 0.032968\n",
      "Nd: 12539, N: 256,trainingerror: 0.000000, testerror: 0.072325\n",
      "Nd: 12539, N: 297,trainingerror: 0.000058, testerror: 0.095864\n",
      "Nd: 12539, N: 345,trainingerror: 0.000000, testerror: 0.093708\n",
      "Nd: 12539, N: 400,trainingerror: 0.000000, testerror: 0.056013\n",
      "Nd: 12539, N: 465,trainingerror: 0.000732, testerror: 0.065268\n",
      "Nd: 12539, N: 540,trainingerror: 0.000000, testerror: 0.077922\n",
      "Nd: 12539, N: 627,trainingerror: 0.000000, testerror: 0.062270\n",
      "Nd: 12539, N: 729,trainingerror: 0.000000, testerror: 0.064484\n",
      "Nd: 12539, N: 846,trainingerror: 0.000002, testerror: 0.061504\n",
      "Nd: 12539, N: 983,trainingerror: 0.000000, testerror: 0.094801\n",
      "Nd: 12539, N: 1142,trainingerror: 0.001721, testerror: 0.134917\n",
      "Nd: 12539, N: 1326,trainingerror: 0.000000, testerror: 0.068999\n",
      "Nd: 12539, N: 1541,trainingerror: 0.000000, testerror: 0.058874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 12539, N: 1789,trainingerror: 0.000000, testerror: 0.064306\n",
      "Nd: 12539, N: 2078,trainingerror: 0.000444, testerror: 0.049545\n",
      "Nd: 12539, N: 2414,trainingerror: 0.000231, testerror: 0.061773\n",
      "Nd: 12539, N: 2804,trainingerror: 0.000483, testerror: 0.048236\n",
      "Nd: 12539, N: 3257,trainingerror: 0.001379, testerror: 0.058631\n",
      "Nd: 12539, N: 3783,trainingerror: 0.000026, testerror: 0.046527\n",
      "Nd: 12539, N: 4395,trainingerror: 0.000136, testerror: 0.053030\n",
      "Nd: 12539, N: 5105,trainingerror: 0.000311, testerror: 0.046682\n",
      "Nd: 12539, N: 5930,trainingerror: 0.000467, testerror: 0.044138\n",
      "Nd: 12539, N: 6888,trainingerror: 0.003847, testerror: 0.050347\n",
      "Nd: 14565, N: 20,trainingerror: 0.000000, testerror: 0.065226\n",
      "Nd: 14565, N: 24,trainingerror: 0.000000, testerror: 0.074712\n",
      "Nd: 14565, N: 27,trainingerror: 0.000000, testerror: 0.054087\n",
      "Nd: 14565, N: 32,trainingerror: 0.000000, testerror: 0.017406\n",
      "Nd: 14565, N: 37,trainingerror: 0.000000, testerror: 0.115278\n",
      "Nd: 14565, N: 43,trainingerror: 0.000000, testerror: 0.140278\n",
      "Nd: 14565, N: 50,trainingerror: 0.000000, testerror: 0.228002\n",
      "Nd: 14565, N: 58,trainingerror: 0.000000, testerror: 0.066014\n",
      "Nd: 14565, N: 67,trainingerror: 0.000000, testerror: 0.045255\n",
      "Nd: 14565, N: 78,trainingerror: 0.000000, testerror: 0.037365\n",
      "Nd: 14565, N: 90,trainingerror: 0.000000, testerror: 0.099417\n",
      "Nd: 14565, N: 104,trainingerror: 0.000000, testerror: 0.043518\n",
      "Nd: 14565, N: 121,trainingerror: 0.000000, testerror: 0.039450\n",
      "Nd: 14565, N: 141,trainingerror: 0.000001, testerror: 0.083448\n",
      "Nd: 14565, N: 163,trainingerror: 0.000000, testerror: 0.051526\n",
      "Nd: 14565, N: 190,trainingerror: 0.000000, testerror: 0.320562\n",
      "Nd: 14565, N: 220,trainingerror: 0.000004, testerror: 0.126164\n",
      "Nd: 14565, N: 256,trainingerror: 0.000000, testerror: 0.187761\n",
      "Nd: 14565, N: 297,trainingerror: 0.000154, testerror: 0.062880\n",
      "Nd: 14565, N: 345,trainingerror: 0.000005, testerror: 0.051652\n",
      "Nd: 14565, N: 400,trainingerror: 0.000010, testerror: 0.057840\n",
      "Nd: 14565, N: 465,trainingerror: 0.000000, testerror: 0.059759\n",
      "Nd: 14565, N: 540,trainingerror: 0.000001, testerror: 0.110479\n",
      "Nd: 14565, N: 627,trainingerror: 0.000023, testerror: 0.101762\n",
      "Nd: 14565, N: 729,trainingerror: 0.000000, testerror: 0.142105\n",
      "Nd: 14565, N: 846,trainingerror: 0.000004, testerror: 0.082773\n",
      "Nd: 14565, N: 983,trainingerror: 0.000301, testerror: 0.073818\n",
      "Nd: 14565, N: 1142,trainingerror: 0.000011, testerror: 0.058050\n",
      "Nd: 14565, N: 1326,trainingerror: 0.000000, testerror: 0.098368\n",
      "Nd: 14565, N: 1541,trainingerror: 0.000000, testerror: 0.077504\n",
      "Nd: 14565, N: 1789,trainingerror: 0.000000, testerror: 0.061338\n",
      "Nd: 14565, N: 2078,trainingerror: 0.000000, testerror: 0.072202\n",
      "Nd: 14565, N: 2414,trainingerror: 0.000078, testerror: 0.052875\n",
      "Nd: 14565, N: 2804,trainingerror: 0.000000, testerror: 0.052002\n",
      "Nd: 14565, N: 3257,trainingerror: 0.000057, testerror: 0.073006\n",
      "Nd: 14565, N: 3783,trainingerror: 0.000012, testerror: 0.061169\n",
      "Nd: 14565, N: 4395,trainingerror: 0.012229, testerror: 0.067232\n",
      "Nd: 14565, N: 5105,trainingerror: 0.001906, testerror: 0.047939\n",
      "Nd: 14565, N: 5930,trainingerror: 0.001486, testerror: 0.052103\n",
      "Nd: 14565, N: 6888,trainingerror: 0.006689, testerror: 0.053590\n",
      "Nd: 16918, N: 20,trainingerror: 0.000000, testerror: 0.166068\n",
      "Nd: 16918, N: 24,trainingerror: 0.000000, testerror: 0.091711\n",
      "Nd: 16918, N: 27,trainingerror: 0.000000, testerror: 0.057554\n",
      "Nd: 16918, N: 32,trainingerror: 0.000000, testerror: 0.027709\n",
      "Nd: 16918, N: 37,trainingerror: 0.000000, testerror: 0.046885\n",
      "Nd: 16918, N: 43,trainingerror: 0.000000, testerror: 0.118141\n",
      "Nd: 16918, N: 50,trainingerror: 0.000006, testerror: 0.105489\n",
      "Nd: 16918, N: 58,trainingerror: 0.000000, testerror: 0.112449\n",
      "Nd: 16918, N: 67,trainingerror: 0.000002, testerror: 0.065243\n",
      "Nd: 16918, N: 78,trainingerror: 0.000000, testerror: 0.101291\n",
      "Nd: 16918, N: 90,trainingerror: 0.001634, testerror: 0.049605\n",
      "Nd: 16918, N: 104,trainingerror: 0.000000, testerror: 0.017830\n",
      "Nd: 16918, N: 121,trainingerror: 0.000000, testerror: 0.123624\n",
      "Nd: 16918, N: 141,trainingerror: 0.000000, testerror: 0.052226\n",
      "Nd: 16918, N: 163,trainingerror: 0.000000, testerror: 0.080787\n",
      "Nd: 16918, N: 190,trainingerror: 0.000000, testerror: 0.047421\n",
      "Nd: 16918, N: 220,trainingerror: 0.000003, testerror: 0.084942\n",
      "Nd: 16918, N: 256,trainingerror: 0.000000, testerror: 0.138708\n",
      "Nd: 16918, N: 297,trainingerror: 0.000000, testerror: 0.085671\n",
      "Nd: 16918, N: 345,trainingerror: 0.000000, testerror: 0.057303\n",
      "Nd: 16918, N: 400,trainingerror: 0.000000, testerror: 0.074824\n",
      "Nd: 16918, N: 465,trainingerror: 0.000005, testerror: 0.064411\n",
      "Nd: 16918, N: 540,trainingerror: 0.000003, testerror: 0.075470\n",
      "Nd: 16918, N: 627,trainingerror: 0.000000, testerror: 0.104333\n",
      "Nd: 16918, N: 729,trainingerror: 0.000583, testerror: 0.052031\n",
      "Nd: 16918, N: 846,trainingerror: 0.000000, testerror: 0.101002\n",
      "Nd: 16918, N: 983,trainingerror: 0.000000, testerror: 0.076176\n",
      "Nd: 16918, N: 1142,trainingerror: 0.000004, testerror: 0.083764\n",
      "Nd: 16918, N: 1326,trainingerror: 0.000000, testerror: 0.056701\n",
      "Nd: 16918, N: 1541,trainingerror: 0.000000, testerror: 0.105576\n",
      "Nd: 16918, N: 1789,trainingerror: 0.000725, testerror: 0.079453\n",
      "Nd: 16918, N: 2078,trainingerror: 0.000000, testerror: 0.070947\n",
      "Nd: 16918, N: 2414,trainingerror: 0.000000, testerror: 0.053725\n",
      "Nd: 16918, N: 2804,trainingerror: 0.000000, testerror: 0.076077\n",
      "Nd: 16918, N: 3257,trainingerror: 0.000001, testerror: 0.051496\n",
      "Nd: 16918, N: 3783,trainingerror: 0.001140, testerror: 0.051662\n",
      "Nd: 16918, N: 4395,trainingerror: 0.000218, testerror: 0.053327\n",
      "Nd: 16918, N: 5105,trainingerror: 0.000110, testerror: 0.049753\n",
      "Nd: 16918, N: 5930,trainingerror: 0.000345, testerror: 0.045911\n",
      "Nd: 16918, N: 6888,trainingerror: 0.001456, testerror: 0.043597\n",
      "Nd: 19652, N: 20,trainingerror: 0.000000, testerror: 0.109782\n",
      "Nd: 19652, N: 24,trainingerror: 0.000000, testerror: 0.047532\n",
      "Nd: 19652, N: 27,trainingerror: 0.000000, testerror: 0.059285\n",
      "Nd: 19652, N: 32,trainingerror: 0.000000, testerror: 0.046902\n",
      "Nd: 19652, N: 37,trainingerror: 0.000000, testerror: 0.047992\n",
      "Nd: 19652, N: 43,trainingerror: 0.000000, testerror: 0.067547\n",
      "Nd: 19652, N: 50,trainingerror: 0.000000, testerror: 0.074693\n",
      "Nd: 19652, N: 58,trainingerror: 0.000000, testerror: 0.047873\n",
      "Nd: 19652, N: 67,trainingerror: 0.000000, testerror: 0.098109\n",
      "Nd: 19652, N: 78,trainingerror: 0.000000, testerror: 0.181884\n",
      "Nd: 19652, N: 90,trainingerror: 0.000000, testerror: 0.054764\n",
      "Nd: 19652, N: 104,trainingerror: 0.000000, testerror: 0.049737\n",
      "Nd: 19652, N: 121,trainingerror: 0.000000, testerror: 0.071756\n",
      "Nd: 19652, N: 141,trainingerror: 0.000000, testerror: 0.023835\n",
      "Nd: 19652, N: 163,trainingerror: 0.000000, testerror: 0.120037\n",
      "Nd: 19652, N: 190,trainingerror: 0.000001, testerror: 0.081700\n",
      "Nd: 19652, N: 220,trainingerror: 0.000000, testerror: 0.057488\n",
      "Nd: 19652, N: 256,trainingerror: 0.000000, testerror: 0.111269\n",
      "Nd: 19652, N: 297,trainingerror: 0.000000, testerror: 0.121319\n",
      "Nd: 19652, N: 345,trainingerror: 0.000000, testerror: 0.086148\n",
      "Nd: 19652, N: 400,trainingerror: 0.000000, testerror: 0.081885\n",
      "Nd: 19652, N: 465,trainingerror: 0.000000, testerror: 0.065408\n",
      "Nd: 19652, N: 540,trainingerror: 0.000002, testerror: 0.059460\n",
      "Nd: 19652, N: 627,trainingerror: 0.000000, testerror: 0.102232\n",
      "Nd: 19652, N: 729,trainingerror: 0.000000, testerror: 0.069679\n",
      "Nd: 19652, N: 846,trainingerror: 0.000001, testerror: 0.067232\n",
      "Nd: 19652, N: 983,trainingerror: 0.000000, testerror: 0.102855\n",
      "Nd: 19652, N: 1142,trainingerror: 0.000000, testerror: 0.081863\n",
      "Nd: 19652, N: 1326,trainingerror: 0.000000, testerror: 0.105443\n",
      "Nd: 19652, N: 1541,trainingerror: 0.000000, testerror: 0.102814\n",
      "Nd: 19652, N: 1789,trainingerror: 0.000000, testerror: 0.077321\n",
      "Nd: 19652, N: 2078,trainingerror: 0.000000, testerror: 0.123991\n",
      "Nd: 19652, N: 2414,trainingerror: 0.000000, testerror: 0.069213\n",
      "Nd: 19652, N: 2804,trainingerror: 0.000002, testerror: 0.062225\n",
      "Nd: 19652, N: 3257,trainingerror: 0.000101, testerror: 0.052299\n",
      "Nd: 19652, N: 3783,trainingerror: 0.000064, testerror: 0.053876\n",
      "Nd: 19652, N: 4395,trainingerror: 0.000012, testerror: 0.044578\n",
      "Nd: 19652, N: 5105,trainingerror: 0.000078, testerror: 0.047727\n",
      "Nd: 19652, N: 5930,trainingerror: 0.004936, testerror: 0.047381\n",
      "Nd: 19652, N: 6888,trainingerror: 0.000359, testerror: 0.046170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 22828, N: 20,trainingerror: 0.000000, testerror: 0.245367\n",
      "Nd: 22828, N: 24,trainingerror: 0.000000, testerror: 0.042219\n",
      "Nd: 22828, N: 27,trainingerror: 0.000000, testerror: 0.490727\n",
      "Nd: 22828, N: 32,trainingerror: 0.000000, testerror: 0.034643\n",
      "Nd: 22828, N: 37,trainingerror: 0.000000, testerror: 0.108646\n",
      "Nd: 22828, N: 43,trainingerror: 0.000000, testerror: 0.139161\n",
      "Nd: 22828, N: 50,trainingerror: 0.000000, testerror: 0.032913\n",
      "Nd: 22828, N: 58,trainingerror: 0.000000, testerror: 0.093931\n",
      "Nd: 22828, N: 67,trainingerror: 0.000000, testerror: 0.041948\n",
      "Nd: 22828, N: 78,trainingerror: 0.000000, testerror: 0.085967\n",
      "Nd: 22828, N: 90,trainingerror: 0.000000, testerror: 0.085997\n",
      "Nd: 22828, N: 104,trainingerror: 0.000000, testerror: 0.065563\n",
      "Nd: 22828, N: 121,trainingerror: 0.000000, testerror: 0.046401\n",
      "Nd: 22828, N: 141,trainingerror: 0.000000, testerror: 0.077805\n",
      "Nd: 22828, N: 163,trainingerror: 0.000000, testerror: 0.045376\n",
      "Nd: 22828, N: 190,trainingerror: 0.000000, testerror: 0.051798\n",
      "Nd: 22828, N: 220,trainingerror: 0.000389, testerror: 0.045361\n",
      "Nd: 22828, N: 256,trainingerror: 0.000000, testerror: 0.068747\n",
      "Nd: 22828, N: 297,trainingerror: 0.000000, testerror: 0.072069\n",
      "Nd: 22828, N: 345,trainingerror: 0.000000, testerror: 0.101143\n",
      "Nd: 22828, N: 400,trainingerror: 0.000828, testerror: 0.070316\n",
      "Nd: 22828, N: 465,trainingerror: 0.000000, testerror: 0.065283\n",
      "Nd: 22828, N: 540,trainingerror: 0.000000, testerror: 0.065276\n",
      "Nd: 22828, N: 627,trainingerror: 0.000000, testerror: 0.055458\n",
      "Nd: 22828, N: 729,trainingerror: 0.000000, testerror: 0.059700\n",
      "Nd: 22828, N: 846,trainingerror: 0.002032, testerror: 0.066910\n",
      "Nd: 22828, N: 983,trainingerror: 0.000000, testerror: 0.097644\n",
      "Nd: 22828, N: 1142,trainingerror: 0.000000, testerror: 0.139193\n",
      "Nd: 22828, N: 1326,trainingerror: 0.000002, testerror: 0.063570\n",
      "Nd: 22828, N: 1541,trainingerror: 0.000000, testerror: 0.063733\n",
      "Nd: 22828, N: 1789,trainingerror: 0.000026, testerror: 0.059671\n",
      "Nd: 22828, N: 2078,trainingerror: 0.000000, testerror: 0.055756\n",
      "Nd: 22828, N: 2414,trainingerror: 0.000000, testerror: 0.077152\n",
      "Nd: 22828, N: 2804,trainingerror: 0.000017, testerror: 0.045932\n",
      "Nd: 22828, N: 3257,trainingerror: 0.000420, testerror: 0.058324\n",
      "Nd: 22828, N: 3783,trainingerror: 0.005447, testerror: 0.053958\n",
      "Nd: 22828, N: 4395,trainingerror: 0.000309, testerror: 0.051720\n",
      "Nd: 22828, N: 5105,trainingerror: 0.000109, testerror: 0.042385\n",
      "Nd: 22828, N: 5930,trainingerror: 0.000196, testerror: 0.043046\n",
      "Nd: 22828, N: 6888,trainingerror: 0.000352, testerror: 0.044883\n",
      "Nd: 26516, N: 20,trainingerror: 0.000000, testerror: 0.040982\n",
      "Nd: 26516, N: 24,trainingerror: 0.000000, testerror: 0.262164\n",
      "Nd: 26516, N: 27,trainingerror: 0.000000, testerror: 0.241134\n",
      "Nd: 26516, N: 32,trainingerror: 0.000000, testerror: 0.042638\n",
      "Nd: 26516, N: 37,trainingerror: 0.000000, testerror: 0.043986\n",
      "Nd: 26516, N: 43,trainingerror: 0.000000, testerror: 0.171318\n",
      "Nd: 26516, N: 50,trainingerror: 0.000000, testerror: 0.125941\n",
      "Nd: 26516, N: 58,trainingerror: 0.000000, testerror: 0.045010\n",
      "Nd: 26516, N: 67,trainingerror: 0.000000, testerror: 0.227127\n",
      "Nd: 26516, N: 78,trainingerror: 0.000445, testerror: 0.119251\n",
      "Nd: 26516, N: 90,trainingerror: 0.000000, testerror: 0.156306\n",
      "Nd: 26516, N: 104,trainingerror: 0.000000, testerror: 0.086269\n",
      "Nd: 26516, N: 121,trainingerror: 0.000000, testerror: 0.463262\n",
      "Nd: 26516, N: 141,trainingerror: 0.000000, testerror: 0.098090\n",
      "Nd: 26516, N: 163,trainingerror: 0.000000, testerror: 0.090787\n",
      "Nd: 26516, N: 190,trainingerror: 0.000000, testerror: 0.080112\n",
      "Nd: 26516, N: 220,trainingerror: 0.000000, testerror: 0.112376\n",
      "Nd: 26516, N: 256,trainingerror: 0.000000, testerror: 0.055784\n",
      "Nd: 26516, N: 297,trainingerror: 0.000054, testerror: 0.047807\n",
      "Nd: 26516, N: 345,trainingerror: 0.000000, testerror: 0.117682\n",
      "Nd: 26516, N: 400,trainingerror: 0.000000, testerror: 0.069036\n",
      "Nd: 26516, N: 465,trainingerror: 0.000000, testerror: 0.040870\n",
      "Nd: 26516, N: 540,trainingerror: 0.000011, testerror: 0.072518\n",
      "Nd: 26516, N: 627,trainingerror: 0.000000, testerror: 0.068810\n",
      "Nd: 26516, N: 729,trainingerror: 0.000000, testerror: 0.089536\n",
      "Nd: 26516, N: 846,trainingerror: 0.000000, testerror: 0.086849\n",
      "Nd: 26516, N: 983,trainingerror: 0.000030, testerror: 0.110543\n",
      "Nd: 26516, N: 1142,trainingerror: 0.000000, testerror: 0.059365\n",
      "Nd: 26516, N: 1326,trainingerror: 0.000000, testerror: 0.053375\n",
      "Nd: 26516, N: 1541,trainingerror: 0.000000, testerror: 0.059132\n",
      "Nd: 26516, N: 1789,trainingerror: 0.000000, testerror: 0.057614\n",
      "Nd: 26516, N: 2078,trainingerror: 0.000000, testerror: 0.068741\n",
      "Nd: 26516, N: 2414,trainingerror: 0.000137, testerror: 0.062437\n",
      "Nd: 26516, N: 2804,trainingerror: 0.004582, testerror: 0.062702\n",
      "Nd: 26516, N: 3257,trainingerror: 0.000002, testerror: 0.061375\n",
      "Nd: 26516, N: 3783,trainingerror: 0.000038, testerror: 0.051128\n",
      "Nd: 26516, N: 4395,trainingerror: 0.000008, testerror: 0.047844\n",
      "Nd: 26516, N: 5105,trainingerror: 0.000227, testerror: 0.049224\n",
      "Nd: 26516, N: 5930,trainingerror: 0.000078, testerror: 0.047011\n",
      "Nd: 26516, N: 6888,trainingerror: 0.000167, testerror: 0.043325\n",
      "Nd: 30801, N: 20,trainingerror: 0.000000, testerror: 0.089647\n",
      "Nd: 30801, N: 24,trainingerror: 0.000173, testerror: 0.842002\n",
      "Nd: 30801, N: 27,trainingerror: 0.000000, testerror: 0.303372\n",
      "Nd: 30801, N: 32,trainingerror: 0.000000, testerror: 0.019689\n",
      "Nd: 30801, N: 37,trainingerror: 0.000000, testerror: 0.062254\n",
      "Nd: 30801, N: 43,trainingerror: 0.000000, testerror: 0.073128\n",
      "Nd: 30801, N: 50,trainingerror: 0.000000, testerror: 0.055740\n",
      "Nd: 30801, N: 58,trainingerror: 0.000000, testerror: 0.046504\n",
      "Nd: 30801, N: 67,trainingerror: 0.000000, testerror: 0.077768\n",
      "Nd: 30801, N: 78,trainingerror: 0.000000, testerror: 0.557565\n",
      "Nd: 30801, N: 90,trainingerror: 0.000000, testerror: 0.047536\n",
      "Nd: 30801, N: 104,trainingerror: 0.000000, testerror: 0.047730\n",
      "Nd: 30801, N: 121,trainingerror: 0.000000, testerror: 0.049057\n",
      "Nd: 30801, N: 141,trainingerror: 0.000000, testerror: 0.092497\n",
      "Nd: 30801, N: 163,trainingerror: 0.000000, testerror: 0.232436\n",
      "Nd: 30801, N: 190,trainingerror: 0.000000, testerror: 0.115739\n",
      "Nd: 30801, N: 220,trainingerror: 0.000000, testerror: 0.099572\n",
      "Nd: 30801, N: 256,trainingerror: 0.000000, testerror: 0.235476\n",
      "Nd: 30801, N: 297,trainingerror: 0.000000, testerror: 0.073561\n",
      "Nd: 30801, N: 345,trainingerror: 0.000000, testerror: 0.117130\n",
      "Nd: 30801, N: 400,trainingerror: 0.000000, testerror: 0.072291\n",
      "Nd: 30801, N: 465,trainingerror: 0.000000, testerror: 0.116519\n",
      "Nd: 30801, N: 540,trainingerror: 0.000002, testerror: 0.090848\n",
      "Nd: 30801, N: 627,trainingerror: 0.000000, testerror: 0.060752\n",
      "Nd: 30801, N: 729,trainingerror: 0.000000, testerror: 0.086912\n",
      "Nd: 30801, N: 846,trainingerror: 0.000000, testerror: 0.105853\n",
      "Nd: 30801, N: 983,trainingerror: 0.000000, testerror: 0.084296\n",
      "Nd: 30801, N: 1142,trainingerror: 0.000001, testerror: 0.102032\n",
      "Nd: 30801, N: 1326,trainingerror: nan, testerror: nan\n",
      "Nd: 30801, N: 1541,trainingerror: 0.000000, testerror: 0.065001\n",
      "Nd: 30801, N: 1789,trainingerror: 0.000000, testerror: 0.098431\n",
      "Nd: 30801, N: 2078,trainingerror: 0.000098, testerror: 0.068783\n",
      "Nd: 30801, N: 2414,trainingerror: 0.000158, testerror: 0.048794\n",
      "Nd: 30801, N: 2804,trainingerror: 0.000010, testerror: 0.057348\n",
      "Nd: 30801, N: 3257,trainingerror: 0.000125, testerror: 0.050371\n",
      "Nd: 30801, N: 3783,trainingerror: 0.000001, testerror: 0.047886\n",
      "Nd: 30801, N: 4395,trainingerror: 0.000149, testerror: 0.047953\n",
      "Nd: 30801, N: 5105,trainingerror: 0.000186, testerror: 0.043395\n",
      "Nd: 30801, N: 5930,trainingerror: 0.000052, testerror: 0.044415\n",
      "Nd: 30801, N: 6888,trainingerror: 0.000212, testerror: 0.043765\n",
      "Nd: 35778, N: 20,trainingerror: 0.000000, testerror: 0.024615\n",
      "Nd: 35778, N: 24,trainingerror: 0.000000, testerror: 0.235631\n",
      "Nd: 35778, N: 27,trainingerror: 0.000000, testerror: 0.120431\n",
      "Nd: 35778, N: 32,trainingerror: 0.000000, testerror: 0.086181\n",
      "Nd: 35778, N: 37,trainingerror: 0.000000, testerror: 0.068562\n",
      "Nd: 35778, N: 43,trainingerror: 0.000000, testerror: 0.062259\n",
      "Nd: 35778, N: 50,trainingerror: 0.000000, testerror: 0.042774\n",
      "Nd: 35778, N: 58,trainingerror: 0.000000, testerror: 0.038810\n",
      "Nd: 35778, N: 67,trainingerror: 0.000000, testerror: 0.063571\n",
      "Nd: 35778, N: 78,trainingerror: 0.000000, testerror: 0.075650\n",
      "Nd: 35778, N: 90,trainingerror: 0.000000, testerror: 0.111264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 35778, N: 104,trainingerror: 0.000000, testerror: 0.052889\n",
      "Nd: 35778, N: 121,trainingerror: 0.000000, testerror: 0.184048\n",
      "Nd: 35778, N: 141,trainingerror: 0.000000, testerror: 0.086379\n",
      "Nd: 35778, N: 163,trainingerror: 0.000000, testerror: 0.042713\n",
      "Nd: 35778, N: 190,trainingerror: 0.000000, testerror: 0.046971\n",
      "Nd: 35778, N: 220,trainingerror: 0.000000, testerror: 0.134415\n",
      "Nd: 35778, N: 256,trainingerror: 0.000000, testerror: 0.132067\n",
      "Nd: 35778, N: 297,trainingerror: 0.000000, testerror: 0.050190\n",
      "Nd: 35778, N: 345,trainingerror: 0.000000, testerror: 0.075687\n",
      "Nd: 35778, N: 400,trainingerror: 0.000000, testerror: 0.050706\n",
      "Nd: 35778, N: 465,trainingerror: 0.000000, testerror: 0.090066\n",
      "Nd: 35778, N: 540,trainingerror: 0.000000, testerror: 0.113712\n",
      "Nd: 35778, N: 627,trainingerror: 0.000000, testerror: 0.071596\n",
      "Nd: 35778, N: 729,trainingerror: 0.000327, testerror: 0.055555\n",
      "Nd: 35778, N: 846,trainingerror: 0.000014, testerror: 0.107477\n",
      "Nd: 35778, N: 983,trainingerror: 0.000104, testerror: 0.077777\n",
      "Nd: 35778, N: 1142,trainingerror: 0.000000, testerror: 0.058516\n",
      "Nd: 35778, N: 1326,trainingerror: 0.000081, testerror: 0.084054\n",
      "Nd: 35778, N: 1541,trainingerror: 0.000001, testerror: 0.080566\n",
      "Nd: 35778, N: 1789,trainingerror: 0.000000, testerror: 0.055282\n",
      "Nd: 35778, N: 2078,trainingerror: 0.000001, testerror: 0.061300\n",
      "Nd: 35778, N: 2414,trainingerror: 0.000000, testerror: 0.049445\n",
      "Nd: 35778, N: 2804,trainingerror: 0.000000, testerror: 0.052550\n",
      "Nd: 35778, N: 3257,trainingerror: 0.000000, testerror: 0.050214\n",
      "Nd: 35778, N: 3783,trainingerror: 0.000013, testerror: 0.050709\n",
      "Nd: 35778, N: 4395,trainingerror: 0.000021, testerror: 0.059794\n",
      "Nd: 35778, N: 5105,trainingerror: 0.000025, testerror: 0.043653\n",
      "Nd: 35778, N: 5930,trainingerror: 0.000029, testerror: 0.048132\n",
      "Nd: 35778, N: 6888,trainingerror: 0.000094, testerror: 0.043280\n",
      "Nd: 41559, N: 20,trainingerror: 0.000000, testerror: 0.023769\n",
      "Nd: 41559, N: 24,trainingerror: 0.000000, testerror: 0.088953\n",
      "Nd: 41559, N: 27,trainingerror: 0.000000, testerror: 0.054213\n",
      "Nd: 41559, N: 32,trainingerror: 0.000416, testerror: 1.397660\n",
      "Nd: 41559, N: 37,trainingerror: 0.000000, testerror: 0.087630\n",
      "Nd: 41559, N: 43,trainingerror: 0.000000, testerror: 0.029215\n",
      "Nd: 41559, N: 50,trainingerror: 0.000000, testerror: 0.034358\n",
      "Nd: 41559, N: 58,trainingerror: 0.000000, testerror: 0.065381\n",
      "Nd: 41559, N: 67,trainingerror: 0.000000, testerror: 0.039021\n",
      "Nd: 41559, N: 78,trainingerror: 0.000000, testerror: 0.053625\n",
      "Nd: 41559, N: 90,trainingerror: 0.000000, testerror: 0.096715\n",
      "Nd: 41559, N: 104,trainingerror: 0.000000, testerror: 0.040032\n",
      "Nd: 41559, N: 121,trainingerror: 0.000000, testerror: 0.039026\n",
      "Nd: 41559, N: 141,trainingerror: 0.000000, testerror: 0.090528\n",
      "Nd: 41559, N: 163,trainingerror: 0.000000, testerror: 0.040840\n",
      "Nd: 41559, N: 190,trainingerror: 0.000000, testerror: 0.164384\n",
      "Nd: 41559, N: 220,trainingerror: 0.000000, testerror: 0.062251\n",
      "Nd: 41559, N: 256,trainingerror: 0.000000, testerror: 0.059991\n",
      "Nd: 41559, N: 297,trainingerror: 0.000000, testerror: 0.032275\n",
      "Nd: 41559, N: 345,trainingerror: 0.000000, testerror: 0.055444\n",
      "Nd: 41559, N: 400,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 465,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 540,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 627,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 729,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 846,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 983,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 1142,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 1326,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 1541,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 1789,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 2078,trainingerror: 0.000000, testerror: 0.050050\n",
      "Nd: 41559, N: 2414,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 2804,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 3257,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 3783,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 4395,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 5105,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 5930,trainingerror: nan, testerror: nan\n",
      "Nd: 41559, N: 6888,trainingerror: nan, testerror: nan\n",
      "Nd: 48274, N: 20,trainingerror: 0.000000, testerror: 0.112890\n",
      "Nd: 48274, N: 24,trainingerror: 0.000000, testerror: 0.085043\n",
      "Nd: 48274, N: 27,trainingerror: 0.000000, testerror: 0.047313\n",
      "Nd: 48274, N: 32,trainingerror: 0.000000, testerror: 0.057619\n",
      "Nd: 48274, N: 37,trainingerror: 0.000000, testerror: 0.038650\n",
      "Nd: 48274, N: 43,trainingerror: 0.000000, testerror: 0.047734\n",
      "Nd: 48274, N: 50,trainingerror: 0.000000, testerror: 0.033345\n",
      "Nd: 48274, N: 58,trainingerror: 0.000000, testerror: 0.037577\n",
      "Nd: 48274, N: 67,trainingerror: 0.000000, testerror: 0.175914\n",
      "Nd: 48274, N: 78,trainingerror: 0.000000, testerror: 0.240358\n",
      "Nd: 48274, N: 90,trainingerror: 0.000000, testerror: 0.217923\n",
      "Nd: 48274, N: 104,trainingerror: 0.000000, testerror: 0.182373\n",
      "Nd: 48274, N: 121,trainingerror: 0.000000, testerror: 0.127802\n",
      "Nd: 48274, N: 141,trainingerror: 0.000000, testerror: 0.051664\n",
      "Nd: 48274, N: 163,trainingerror: 0.000000, testerror: 0.031047\n",
      "Nd: 48274, N: 190,trainingerror: 0.000000, testerror: 0.175885\n",
      "Nd: 48274, N: 220,trainingerror: 0.000000, testerror: 0.067246\n",
      "Nd: 48274, N: 256,trainingerror: 0.000000, testerror: 0.081528\n",
      "Nd: 48274, N: 297,trainingerror: 0.000000, testerror: 0.088488\n",
      "Nd: 48274, N: 345,trainingerror: 0.000000, testerror: 0.105616\n",
      "Nd: 48274, N: 400,trainingerror: 0.000000, testerror: 0.058147\n",
      "Nd: 48274, N: 465,trainingerror: 0.000000, testerror: 0.064351\n",
      "Nd: 48274, N: 540,trainingerror: 0.000000, testerror: 0.066492\n",
      "Nd: 48274, N: 627,trainingerror: 0.000000, testerror: 0.108195\n",
      "Nd: 48274, N: 729,trainingerror: 0.000031, testerror: 0.083890\n",
      "Nd: 48274, N: 846,trainingerror: 0.000000, testerror: 0.115717\n",
      "Nd: 48274, N: 983,trainingerror: 0.000003, testerror: 0.050803\n",
      "Nd: 48274, N: 1142,trainingerror: 0.000003, testerror: 0.090051\n",
      "Nd: 48274, N: 1326,trainingerror: 0.000038, testerror: 0.052737\n",
      "Nd: 48274, N: 1541,trainingerror: 0.000005, testerror: 0.047790\n",
      "Nd: 48274, N: 1789,trainingerror: 0.001644, testerror: 0.062651\n",
      "Nd: 48274, N: 2078,trainingerror: 0.000000, testerror: 0.052602\n",
      "Nd: 48274, N: 2414,trainingerror: 0.000000, testerror: 0.049401\n",
      "Nd: 48274, N: 2804,trainingerror: 0.000056, testerror: 0.059631\n",
      "Nd: 48274, N: 3257,trainingerror: 0.000000, testerror: 0.047094\n",
      "Nd: 48274, N: 3783,trainingerror: 0.000000, testerror: 0.050996\n",
      "Nd: 48274, N: 4395,trainingerror: 0.000002, testerror: 0.050147\n",
      "Nd: 48274, N: 5105,trainingerror: 0.000041, testerror: 0.045644\n",
      "Nd: 48274, N: 5930,trainingerror: 0.000019, testerror: 0.048238\n",
      "Nd: 48274, N: 6888,trainingerror: 0.000050, testerror: 0.042016\n",
      "Nd: 56074, N: 20,trainingerror: 0.000000, testerror: 0.020616\n",
      "Nd: 56074, N: 24,trainingerror: 0.000000, testerror: 0.089370\n",
      "Nd: 56074, N: 27,trainingerror: 0.000000, testerror: 0.204550\n",
      "Nd: 56074, N: 32,trainingerror: 0.000000, testerror: 0.677017\n",
      "Nd: 56074, N: 37,trainingerror: 0.000000, testerror: 0.247112\n",
      "Nd: 56074, N: 43,trainingerror: 0.000000, testerror: 0.070962\n",
      "Nd: 56074, N: 50,trainingerror: 0.000000, testerror: 0.089956\n",
      "Nd: 56074, N: 58,trainingerror: 0.002039, testerror: 0.488898\n",
      "Nd: 56074, N: 67,trainingerror: 0.000000, testerror: 0.321030\n",
      "Nd: 56074, N: 78,trainingerror: 0.000000, testerror: 0.041791\n",
      "Nd: 56074, N: 90,trainingerror: 0.000000, testerror: 0.051433\n",
      "Nd: 56074, N: 104,trainingerror: 0.000000, testerror: 0.062424\n",
      "Nd: 56074, N: 121,trainingerror: 0.000000, testerror: 0.059357\n",
      "Nd: 56074, N: 141,trainingerror: 0.000000, testerror: 0.105394\n",
      "Nd: 56074, N: 163,trainingerror: 0.000000, testerror: 0.060946\n",
      "Nd: 56074, N: 190,trainingerror: 0.000000, testerror: 0.075102\n",
      "Nd: 56074, N: 220,trainingerror: 0.000000, testerror: 0.134449\n",
      "Nd: 56074, N: 256,trainingerror: 0.000000, testerror: 0.045221\n",
      "Nd: 56074, N: 297,trainingerror: 0.000000, testerror: 0.090713\n",
      "Nd: 56074, N: 345,trainingerror: 0.000000, testerror: 0.222559\n",
      "Nd: 56074, N: 400,trainingerror: 0.000361, testerror: 0.058915\n",
      "Nd: 56074, N: 465,trainingerror: 0.000000, testerror: 0.052788\n",
      "Nd: 56074, N: 540,trainingerror: 0.000000, testerror: 0.071426\n",
      "Nd: 56074, N: 627,trainingerror: 0.000000, testerror: 0.089266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 56074, N: 729,trainingerror: 0.000000, testerror: 0.442150\n",
      "Nd: 56074, N: 846,trainingerror: 0.000000, testerror: 0.054973\n",
      "Nd: 56074, N: 983,trainingerror: 0.000000, testerror: 0.076779\n",
      "Nd: 56074, N: 1142,trainingerror: 0.000000, testerror: 0.058293\n",
      "Nd: 56074, N: 1326,trainingerror: 0.000003, testerror: 0.066400\n",
      "Nd: 56074, N: 1541,trainingerror: 0.000004, testerror: 0.128232\n",
      "Nd: 56074, N: 1789,trainingerror: 0.000000, testerror: 0.059973\n",
      "Nd: 56074, N: 2078,trainingerror: 0.000000, testerror: 0.050414\n",
      "Nd: 56074, N: 2414,trainingerror: 0.000005, testerror: 0.047582\n",
      "Nd: 56074, N: 2804,trainingerror: 0.000004, testerror: 0.051494\n",
      "Nd: 56074, N: 3257,trainingerror: 0.000039, testerror: 0.048382\n",
      "Nd: 56074, N: 3783,trainingerror: 0.000102, testerror: 0.045647\n",
      "Nd: 56074, N: 4395,trainingerror: 0.000005, testerror: 0.045544\n",
      "Nd: 56074, N: 5105,trainingerror: 0.000009, testerror: 0.049455\n",
      "Nd: 56074, N: 5930,trainingerror: 0.000032, testerror: 0.046059\n",
      "Nd: 56074, N: 6888,trainingerror: 0.000137, testerror: 0.050744\n",
      "Nd: 65135, N: 20,trainingerror: 0.000000, testerror: 0.109980\n",
      "Nd: 65135, N: 24,trainingerror: 0.000000, testerror: 0.080025\n",
      "Nd: 65135, N: 27,trainingerror: 0.000000, testerror: 0.075522\n",
      "Nd: 65135, N: 32,trainingerror: 0.000000, testerror: 0.048932\n",
      "Nd: 65135, N: 37,trainingerror: 0.000000, testerror: 1.050927\n",
      "Nd: 65135, N: 43,trainingerror: 0.000000, testerror: 0.121289\n",
      "Nd: 65135, N: 50,trainingerror: 0.000000, testerror: 0.031959\n",
      "Nd: 65135, N: 58,trainingerror: 0.000000, testerror: 0.038237\n",
      "Nd: 65135, N: 67,trainingerror: 0.000000, testerror: 0.030770\n",
      "Nd: 65135, N: 78,trainingerror: 0.000000, testerror: 0.034348\n",
      "Nd: 65135, N: 90,trainingerror: 0.000000, testerror: 0.081064\n",
      "Nd: 65135, N: 104,trainingerror: 0.000000, testerror: 0.038158\n",
      "Nd: 65135, N: 121,trainingerror: 0.000000, testerror: 0.050534\n",
      "Nd: 65135, N: 141,trainingerror: 0.000000, testerror: 0.049690\n",
      "Nd: 65135, N: 163,trainingerror: 0.000000, testerror: 0.050500\n",
      "Nd: 65135, N: 190,trainingerror: 0.000000, testerror: 0.034501\n",
      "Nd: 65135, N: 220,trainingerror: 0.000000, testerror: 0.099761\n",
      "Nd: 65135, N: 256,trainingerror: 0.000000, testerror: 0.052539\n",
      "Nd: 65135, N: 297,trainingerror: 0.000000, testerror: 0.054956\n",
      "Nd: 65135, N: 345,trainingerror: 0.000000, testerror: 0.057931\n",
      "Nd: 65135, N: 400,trainingerror: 0.000000, testerror: 0.049628\n",
      "Nd: 65135, N: 465,trainingerror: 0.000000, testerror: 0.084621\n",
      "Nd: 65135, N: 540,trainingerror: 0.000000, testerror: 0.063699\n",
      "Nd: 65135, N: 627,trainingerror: 0.000028, testerror: 0.079809\n",
      "Nd: 65135, N: 729,trainingerror: 0.000000, testerror: 0.185281\n",
      "Nd: 65135, N: 846,trainingerror: 0.000000, testerror: 0.057729\n",
      "Nd: 65135, N: 983,trainingerror: 0.000000, testerror: 0.062696\n",
      "Nd: 65135, N: 1142,trainingerror: 0.000001, testerror: 0.074716\n",
      "Nd: 65135, N: 1326,trainingerror: 0.000164, testerror: 0.051748\n",
      "Nd: 65135, N: 1541,trainingerror: 0.000000, testerror: 0.082030\n",
      "Nd: 65135, N: 1789,trainingerror: 0.000007, testerror: 0.053912\n",
      "Nd: 65135, N: 2078,trainingerror: 0.000001, testerror: 0.057939\n",
      "Nd: 65135, N: 2414,trainingerror: 0.000000, testerror: 0.056401\n",
      "Nd: 65135, N: 2804,trainingerror: 0.000001, testerror: 0.048465\n",
      "Nd: 65135, N: 3257,trainingerror: 0.000033, testerror: 0.048416\n",
      "Nd: 65135, N: 3783,trainingerror: 0.000006, testerror: 0.049764\n",
      "Nd: 65135, N: 4395,trainingerror: 0.000159, testerror: 0.046997\n",
      "Nd: 65135, N: 5105,trainingerror: 0.000002, testerror: 0.045013\n",
      "Nd: 65135, N: 5930,trainingerror: 0.000083, testerror: 0.046718\n",
      "Nd: 65135, N: 6888,trainingerror: 0.000062, testerror: 0.047862\n",
      "Nd: 75660, N: 20,trainingerror: 0.000000, testerror: 0.094126\n",
      "Nd: 75660, N: 24,trainingerror: 0.000000, testerror: 0.092879\n",
      "Nd: 75660, N: 27,trainingerror: 0.000000, testerror: 0.044191\n",
      "Nd: 75660, N: 32,trainingerror: 0.000000, testerror: 0.123229\n",
      "Nd: 75660, N: 37,trainingerror: 0.000000, testerror: 0.021416\n",
      "Nd: 75660, N: 43,trainingerror: 0.000000, testerror: 0.015425\n",
      "Nd: 75660, N: 50,trainingerror: 0.000000, testerror: 0.038897\n",
      "Nd: 75660, N: 58,trainingerror: 0.000000, testerror: 0.044363\n",
      "Nd: 75660, N: 67,trainingerror: 0.000000, testerror: 0.065302\n",
      "Nd: 75660, N: 78,trainingerror: 0.000000, testerror: 0.084095\n",
      "Nd: 75660, N: 90,trainingerror: 0.000000, testerror: 0.156073\n",
      "Nd: 75660, N: 104,trainingerror: 0.000000, testerror: 0.027034\n",
      "Nd: 75660, N: 121,trainingerror: 0.000000, testerror: 0.056100\n",
      "Nd: 75660, N: 141,trainingerror: 0.000000, testerror: 0.042377\n",
      "Nd: 75660, N: 163,trainingerror: 0.000000, testerror: 0.096570\n",
      "Nd: 75660, N: 190,trainingerror: 0.000000, testerror: 0.082004\n",
      "Nd: 75660, N: 220,trainingerror: 0.000000, testerror: 0.080602\n",
      "Nd: 75660, N: 256,trainingerror: 0.000000, testerror: 0.071956\n",
      "Nd: 75660, N: 297,trainingerror: 0.000000, testerror: 0.081056\n",
      "Nd: 75660, N: 345,trainingerror: 0.000000, testerror: 0.072900\n",
      "Nd: 75660, N: 400,trainingerror: 0.000000, testerror: 0.097351\n",
      "Nd: 75660, N: 465,trainingerror: 0.000000, testerror: 0.098540\n",
      "Nd: 75660, N: 540,trainingerror: 0.000000, testerror: 0.085457\n",
      "Nd: 75660, N: 627,trainingerror: 0.000000, testerror: 0.064195\n",
      "Nd: 75660, N: 729,trainingerror: 0.000000, testerror: 0.063486\n",
      "Nd: 75660, N: 846,trainingerror: 0.000000, testerror: 0.046918\n",
      "Nd: 75660, N: 983,trainingerror: 0.000068, testerror: 0.054212\n",
      "Nd: 75660, N: 1142,trainingerror: 0.000329, testerror: 0.047814\n",
      "Nd: 75660, N: 1326,trainingerror: 0.000002, testerror: 0.053681\n",
      "Nd: 75660, N: 1541,trainingerror: 0.000000, testerror: 0.044605\n",
      "Nd: 75660, N: 1789,trainingerror: 0.000001, testerror: 0.057729\n",
      "Nd: 75660, N: 2078,trainingerror: 0.000085, testerror: 0.049996\n",
      "Nd: 75660, N: 2414,trainingerror: 0.000003, testerror: 0.052080\n",
      "Nd: 75660, N: 2804,trainingerror: 0.000000, testerror: 0.076354\n",
      "Nd: 75660, N: 3257,trainingerror: 0.000001, testerror: 0.048767\n",
      "Nd: 75660, N: 3783,trainingerror: 0.000105, testerror: 0.049661\n",
      "Nd: 75660, N: 4395,trainingerror: 0.000023, testerror: 0.045651\n",
      "Nd: 75660, N: 5105,trainingerror: 0.000017, testerror: 0.051939\n",
      "Nd: 75660, N: 5930,trainingerror: 0.000009, testerror: 0.047617\n",
      "Nd: 75660, N: 6888,trainingerror: 0.000287, testerror: 0.043414\n",
      "Nd: 87885, N: 20,trainingerror: 0.000000, testerror: 0.051148\n",
      "Nd: 87885, N: 24,trainingerror: 0.000000, testerror: 0.223864\n",
      "Nd: 87885, N: 27,trainingerror: 0.000000, testerror: 0.004861\n",
      "Nd: 87885, N: 32,trainingerror: 0.000000, testerror: 0.036583\n",
      "Nd: 87885, N: 37,trainingerror: 0.000000, testerror: 0.078246\n",
      "Nd: 87885, N: 43,trainingerror: 0.000000, testerror: 0.093166\n",
      "Nd: 87885, N: 50,trainingerror: 0.000000, testerror: 0.055451\n",
      "Nd: 87885, N: 58,trainingerror: 0.000000, testerror: 0.198348\n",
      "Nd: 87885, N: 67,trainingerror: 0.000000, testerror: 0.098622\n",
      "Nd: 87885, N: 78,trainingerror: 0.000000, testerror: 0.037957\n",
      "Nd: 87885, N: 90,trainingerror: 0.000000, testerror: 0.081254\n",
      "Nd: 87885, N: 104,trainingerror: 0.000000, testerror: 0.030086\n",
      "Nd: 87885, N: 121,trainingerror: 0.000000, testerror: 0.277779\n",
      "Nd: 87885, N: 141,trainingerror: 0.000000, testerror: 0.038745\n",
      "Nd: 87885, N: 163,trainingerror: 0.000000, testerror: 0.068870\n",
      "Nd: 87885, N: 190,trainingerror: 0.000000, testerror: 0.099373\n",
      "Nd: 87885, N: 220,trainingerror: 0.000000, testerror: 0.059519\n",
      "Nd: 87885, N: 256,trainingerror: 0.000000, testerror: 0.052662\n",
      "Nd: 87885, N: 297,trainingerror: 0.000000, testerror: 0.127507\n",
      "Nd: 87885, N: 345,trainingerror: 0.000000, testerror: 0.023788\n",
      "Nd: 87885, N: 400,trainingerror: 0.000000, testerror: 0.054110\n",
      "Nd: 87885, N: 465,trainingerror: 0.000000, testerror: 0.048948\n",
      "Nd: 87885, N: 540,trainingerror: 0.000000, testerror: 0.080245\n",
      "Nd: 87885, N: 627,trainingerror: 0.000000, testerror: 0.078128\n",
      "Nd: 87885, N: 729,trainingerror: 0.000000, testerror: 0.055349\n",
      "Nd: 87885, N: 846,trainingerror: 0.000000, testerror: 0.064999\n",
      "Nd: 87885, N: 983,trainingerror: 0.000000, testerror: 0.060770\n",
      "Nd: 87885, N: 1142,trainingerror: 0.000024, testerror: 0.057055\n",
      "Nd: 87885, N: 1326,trainingerror: 0.000530, testerror: 0.057199\n",
      "Nd: 87885, N: 1541,trainingerror: 0.000001, testerror: 0.050525\n",
      "Nd: 87885, N: 1789,trainingerror: 0.000000, testerror: 0.049032\n",
      "Nd: 87885, N: 2078,trainingerror: 0.000000, testerror: 0.078081\n",
      "Nd: 87885, N: 2414,trainingerror: 0.000000, testerror: 0.051083\n",
      "Nd: 87885, N: 2804,trainingerror: 0.000035, testerror: 0.052384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 87885, N: 3257,trainingerror: 0.000002, testerror: 0.045637\n",
      "Nd: 87885, N: 3783,trainingerror: 0.000280, testerror: 0.049205\n",
      "Nd: 87885, N: 4395,trainingerror: 0.000003, testerror: 0.045338\n",
      "Nd: 87885, N: 5105,trainingerror: 0.000102, testerror: 0.047421\n",
      "Nd: 87885, N: 5930,trainingerror: 0.000166, testerror: 0.047204\n",
      "Nd: 87885, N: 6888,trainingerror: 0.000052, testerror: 0.044893\n",
      "Nd: 102086, N: 20,trainingerror: 0.000000, testerror: 0.205585\n",
      "Nd: 102086, N: 24,trainingerror: 0.000000, testerror: 0.142592\n",
      "Nd: 102086, N: 27,trainingerror: 0.000000, testerror: 0.027233\n",
      "Nd: 102086, N: 32,trainingerror: 0.000000, testerror: 0.138649\n",
      "Nd: 102086, N: 37,trainingerror: 0.000000, testerror: 0.027581\n",
      "Nd: 102086, N: 43,trainingerror: 0.000000, testerror: 0.033353\n",
      "Nd: 102086, N: 50,trainingerror: 0.000000, testerror: 0.130848\n",
      "Nd: 102086, N: 58,trainingerror: 0.000000, testerror: 0.020269\n",
      "Nd: 102086, N: 67,trainingerror: 0.000000, testerror: 0.029160\n",
      "Nd: 102086, N: 78,trainingerror: 0.000000, testerror: 0.028588\n",
      "Nd: 102086, N: 90,trainingerror: 0.000000, testerror: 0.048653\n",
      "Nd: 102086, N: 104,trainingerror: 0.000000, testerror: 0.038110\n",
      "Nd: 102086, N: 121,trainingerror: 0.000000, testerror: 0.176290\n",
      "Nd: 102086, N: 141,trainingerror: 0.000000, testerror: 0.043862\n",
      "Nd: 102086, N: 163,trainingerror: 0.000000, testerror: 0.081775\n",
      "Nd: 102086, N: 190,trainingerror: 0.000000, testerror: 0.089915\n",
      "Nd: 102086, N: 220,trainingerror: 0.000000, testerror: 0.038313\n",
      "Nd: 102086, N: 256,trainingerror: 0.000000, testerror: 0.049840\n",
      "Nd: 102086, N: 297,trainingerror: 0.000000, testerror: 0.045042\n",
      "Nd: 102086, N: 345,trainingerror: 0.000000, testerror: 0.045965\n",
      "Nd: 102086, N: 400,trainingerror: 0.000000, testerror: 0.051344\n",
      "Nd: 102086, N: 465,trainingerror: 0.000000, testerror: 0.052501\n",
      "Nd: 102086, N: 540,trainingerror: 0.000000, testerror: 0.095351\n",
      "Nd: 102086, N: 627,trainingerror: 0.000000, testerror: 0.069429\n",
      "Nd: 102086, N: 729,trainingerror: 0.000000, testerror: 0.082391\n",
      "Nd: 102086, N: 846,trainingerror: 0.000000, testerror: 0.051237\n",
      "Nd: 102086, N: 983,trainingerror: 0.000000, testerror: 0.059467\n",
      "Nd: 102086, N: 1142,trainingerror: 0.000000, testerror: 0.122468\n",
      "Nd: 102086, N: 1326,trainingerror: 0.000000, testerror: 0.053678\n",
      "Nd: 102086, N: 1541,trainingerror: 0.000013, testerror: 0.050317\n",
      "Nd: 102086, N: 1789,trainingerror: 0.000000, testerror: 0.056359\n",
      "Nd: 102086, N: 2078,trainingerror: 0.000028, testerror: 0.059577\n",
      "Nd: 102086, N: 2414,trainingerror: 0.000000, testerror: 0.045618\n",
      "Nd: 102086, N: 2804,trainingerror: 0.000000, testerror: 0.048814\n",
      "Nd: 102086, N: 3257,trainingerror: 0.000100, testerror: 0.048120\n",
      "Nd: 102086, N: 3783,trainingerror: 0.000003, testerror: 0.052486\n",
      "Nd: 102086, N: 4395,trainingerror: 0.000000, testerror: 0.045219\n",
      "Nd: 102086, N: 5105,trainingerror: 0.000004, testerror: 0.045693\n",
      "Nd: 102086, N: 5930,trainingerror: 0.000011, testerror: 0.043067\n",
      "Nd: 102086, N: 6888,trainingerror: 0.000103, testerror: 0.044820\n",
      "Nd: 118582, N: 20,trainingerror: 0.000000, testerror: 0.042729\n",
      "Nd: 118582, N: 24,trainingerror: 0.000000, testerror: 0.117634\n",
      "Nd: 118582, N: 27,trainingerror: 0.000000, testerror: 0.027526\n",
      "Nd: 118582, N: 32,trainingerror: 0.000000, testerror: 0.024812\n",
      "Nd: 118582, N: 37,trainingerror: 0.000000, testerror: 0.073461\n",
      "Nd: 118582, N: 43,trainingerror: 0.000000, testerror: 0.095177\n",
      "Nd: 118582, N: 50,trainingerror: 0.000000, testerror: 0.052255\n",
      "Nd: 118582, N: 58,trainingerror: 0.000000, testerror: 0.146946\n",
      "Nd: 118582, N: 67,trainingerror: 0.000000, testerror: 0.112356\n",
      "Nd: 118582, N: 78,trainingerror: 0.000000, testerror: 0.058499\n",
      "Nd: 118582, N: 90,trainingerror: 0.000000, testerror: 1.402851\n",
      "Nd: 118582, N: 104,trainingerror: 0.000000, testerror: 0.054763\n",
      "Nd: 118582, N: 121,trainingerror: 0.000000, testerror: 0.041207\n",
      "Nd: 118582, N: 141,trainingerror: 0.000000, testerror: 0.098850\n",
      "Nd: 118582, N: 163,trainingerror: 0.000000, testerror: 0.191357\n",
      "Nd: 118582, N: 190,trainingerror: 0.000000, testerror: 0.048822\n",
      "Nd: 118582, N: 220,trainingerror: 0.000000, testerror: 0.067795\n",
      "Nd: 118582, N: 256,trainingerror: 0.000000, testerror: 0.046884\n",
      "Nd: 118582, N: 297,trainingerror: 0.000000, testerror: 0.059331\n",
      "Nd: 118582, N: 345,trainingerror: 0.000000, testerror: 0.127968\n",
      "Nd: 118582, N: 400,trainingerror: 0.000000, testerror: 0.070254\n",
      "Nd: 118582, N: 465,trainingerror: 0.000000, testerror: 0.041979\n",
      "Nd: 118582, N: 540,trainingerror: 0.000000, testerror: 0.055957\n",
      "Nd: 118582, N: 627,trainingerror: 0.000000, testerror: 0.048712\n",
      "Nd: 118582, N: 729,trainingerror: 0.000000, testerror: 0.057621\n",
      "Nd: 118582, N: 846,trainingerror: 0.000000, testerror: 0.073772\n",
      "Nd: 118582, N: 983,trainingerror: 0.000000, testerror: 0.050508\n",
      "Nd: 118582, N: 1142,trainingerror: 0.000000, testerror: 0.066749\n",
      "Nd: 118582, N: 1326,trainingerror: 0.000000, testerror: 0.049619\n",
      "Nd: 118582, N: 1541,trainingerror: 0.000000, testerror: 0.048699\n",
      "Nd: 118582, N: 1789,trainingerror: 0.000035, testerror: 0.058833\n",
      "Nd: 118582, N: 2078,trainingerror: 0.000000, testerror: 0.055463\n",
      "Nd: 118582, N: 2414,trainingerror: 0.000000, testerror: 0.047734\n",
      "Nd: 118582, N: 2804,trainingerror: 0.000001, testerror: 0.049048\n",
      "Nd: 118582, N: 3257,trainingerror: 0.000000, testerror: 0.055458\n",
      "Nd: 118582, N: 3783,trainingerror: 0.000674, testerror: 0.048445\n",
      "Nd: 118582, N: 4395,trainingerror: 0.000557, testerror: 0.044702\n",
      "Nd: 118582, N: 5105,trainingerror: 0.000165, testerror: 0.051273\n",
      "Nd: 118582, N: 5930,trainingerror: 0.000007, testerror: 0.047959\n",
      "Nd: 118582, N: 6888,trainingerror: 0.000139, testerror: 0.044999\n",
      "Nd: 137743, N: 20,trainingerror: 0.000000, testerror: 0.058281\n",
      "Nd: 137743, N: 24,trainingerror: 0.000000, testerror: 0.246387\n",
      "Nd: 137743, N: 27,trainingerror: 0.000000, testerror: 0.041612\n",
      "Nd: 137743, N: 32,trainingerror: 0.000000, testerror: 0.021715\n",
      "Nd: 137743, N: 37,trainingerror: 0.000000, testerror: 0.043491\n",
      "Nd: 137743, N: 43,trainingerror: 0.000000, testerror: 0.129639\n",
      "Nd: 137743, N: 50,trainingerror: 0.000000, testerror: 0.055157\n",
      "Nd: 137743, N: 58,trainingerror: 0.000000, testerror: 1.322802\n",
      "Nd: 137743, N: 67,trainingerror: 0.000000, testerror: 0.053799\n",
      "Nd: 137743, N: 78,trainingerror: 0.000000, testerror: 0.052707\n",
      "Nd: 137743, N: 90,trainingerror: 0.000000, testerror: 0.100428\n",
      "Nd: 137743, N: 104,trainingerror: 0.000000, testerror: 0.044657\n",
      "Nd: 137743, N: 121,trainingerror: 0.000000, testerror: 0.090933\n",
      "Nd: 137743, N: 141,trainingerror: 0.000000, testerror: 0.092960\n",
      "Nd: 137743, N: 163,trainingerror: 0.000000, testerror: 0.078409\n",
      "Nd: 137743, N: 190,trainingerror: 0.000000, testerror: 0.054584\n",
      "Nd: 137743, N: 220,trainingerror: 0.000000, testerror: 0.101363\n",
      "Nd: 137743, N: 256,trainingerror: 0.000000, testerror: 0.024287\n",
      "Nd: 137743, N: 297,trainingerror: 0.000000, testerror: 0.128708\n",
      "Nd: 137743, N: 345,trainingerror: 0.000000, testerror: 0.070688\n",
      "Nd: 137743, N: 400,trainingerror: 0.000000, testerror: 0.051610\n",
      "Nd: 137743, N: 465,trainingerror: 0.000000, testerror: 0.070601\n",
      "Nd: 137743, N: 540,trainingerror: 0.000000, testerror: 0.081834\n",
      "Nd: 137743, N: 627,trainingerror: 0.000000, testerror: 0.102385\n",
      "Nd: 137743, N: 729,trainingerror: 0.000000, testerror: 0.046844\n",
      "Nd: 137743, N: 846,trainingerror: 0.000000, testerror: 0.053657\n",
      "Nd: 137743, N: 983,trainingerror: 0.000000, testerror: 0.123642\n",
      "Nd: 137743, N: 1142,trainingerror: 0.000000, testerror: 0.058252\n",
      "Nd: 137743, N: 1326,trainingerror: 0.000000, testerror: 0.053925\n",
      "Nd: 137743, N: 1541,trainingerror: 0.000000, testerror: 0.082268\n",
      "Nd: 137743, N: 1789,trainingerror: 0.000006, testerror: 0.056610\n",
      "Nd: 137743, N: 2078,trainingerror: 0.000000, testerror: 0.053309\n",
      "Nd: 137743, N: 2414,trainingerror: 0.000000, testerror: 0.050868\n",
      "Nd: 137743, N: 2804,trainingerror: 0.000014, testerror: 0.046431\n",
      "Nd: 137743, N: 3257,trainingerror: 0.000002, testerror: 0.055068\n",
      "Nd: 137743, N: 3783,trainingerror: 0.000000, testerror: 0.048890\n",
      "Nd: 137743, N: 4395,trainingerror: 0.000002, testerror: 0.050104\n",
      "Nd: 137743, N: 5105,trainingerror: 0.000180, testerror: 0.050819\n",
      "Nd: 137743, N: 5930,trainingerror: 0.000023, testerror: 0.049236\n",
      "Nd: 137743, N: 6888,trainingerror: 0.000314, testerror: 0.046041\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_trainingerror = np.zeros((60,40))\n",
    "result_testerror = np.zeros((60,40))    \n",
    "\n",
    "for i in range(20,80):\n",
    "    x_id = i /20\n",
    "    for j in range(20,60):\n",
    "        y_id = j/20\n",
    "        \n",
    "        N = int(np.ceil(np.e**(y_id * np.log(20))))\n",
    "        Nd = int(np.ceil(np.e**(x_id* np.log(20))))\n",
    "        \n",
    "        for nrepitition in range(nrep):\n",
    "            x = getRandomSamplesOnNSphere(d,N)\n",
    "            y = generate_y(x,beta)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,shuffle = True)\n",
    "            x_train = torch.FloatTensor(x_train)\n",
    "            x_test = torch.FloatTensor(x_test)\n",
    "            y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "            y_test = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "\n",
    "            train_dataset = dataset(x_train, y_train)\n",
    "            test_dataset = dataset(x_test, y_test)\n",
    "            train_dataloader = DataLoader(dataset= train_dataset, \n",
    "                                        batch_size = len(x_train), \n",
    "                                        shuffle= True, \n",
    "                                        drop_last= False)\n",
    "            test_dataloader = DataLoader(dataset= test_dataset, \n",
    "                                        batch_size = len(x_test), \n",
    "                                        shuffle= True, \n",
    "                                        drop_last= False)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            lr = 0.01\n",
    "\n",
    "            device = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n",
    "            model = Model_1(input_dim= d, Nd = Nd,drop_rate= 0.0).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr)\n",
    "            LOSS = 0\n",
    "            LOSS2 = 0\n",
    "            model.train()\n",
    "            \n",
    "            for epoch in range(500):\n",
    "\n",
    "                for index, (x, y) in enumerate(train_dataloader):\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.to(device)\n",
    "                        y = y.to(device)\n",
    "                    y_pred = model(x)\n",
    "                    loss = criterion(y_pred,y)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            #         for p in model.parameters():\n",
    "            #             # print(p.grad.norm())                 \n",
    "            #             torch.nn.utils.clip_grad_norm_(p, 10)  \n",
    "            #         optimizer.step()\n",
    "            LOSS += loss\n",
    "            model.eval()\n",
    "            loss2 = criterion(model(x_test), y_test)\n",
    "            \n",
    "            LOSS2 += loss2\n",
    "            \n",
    "        training_error = LOSS /nrep\n",
    "        test_error = LOSS2 /nrep\n",
    "        \n",
    "        result_trainingerror[i-20][j-20] = training_error\n",
    "        result_testerror[i-20][j-20] = test_error\n",
    "        \n",
    "        print('Nd: %d, N: %d,trainingerror: %f, testerror: %f'%(Nd,N, training_error, test_error))\n",
    "        \n",
    "    np.save('./result/trainingerror2.npy',result_trainingerror)\n",
    "    np.save('./result/testerror2.npy',result_testerror)    \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "faa48dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_trainingerror = np.load('./result/trainingerror2.npy')\n",
    "result_testerror = np.load('./result/testerror2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c88fc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_trainingerror[np.isnan(result_trainingerror)] = 0\n",
    "result_testerror[np.isnan(result_testerror)] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a94a8812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'training error')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import ticker\n",
    "cmap = seaborn.diverging_palette(220, 10, as_cmap=True)\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "xxs = pd.DataFrame(result_trainingerror.T,index = [x/20+1 for x in list(range(result_trainingerror.shape[1]))],\n",
    "            columns = [x/20+1 for x in list(range(result_trainingerror.shape[0]))])\n",
    "\n",
    "seaborn.heatmap(xxs, cmap=cmap,vmin = 0,vmax = 0.2,\n",
    "            linewidths=.0001, cbar_kws={\"shrink\": 0.6},xticklabels=10,yticklabels=10)\n",
    "\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_ylabel('log(N)/log(d)',fontsize=20, color='k')\n",
    "\n",
    "ax.set_xlabel('log(Nd)/log(d)',fontsize=20, color='k')\n",
    "\n",
    "plt.title('training error', fontsize = 24,color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1ee9c0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'test error')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import ticker\n",
    "cmap = seaborn.diverging_palette(220, 10, as_cmap=True)\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "xxss = pd.DataFrame(result_testerror.T,index = [x/20+1 for x in list(range(result_testerror.shape[1]))],\n",
    "            columns = [x/20+1 for x in list(range(result_trainingerror.shape[0]))])\n",
    "\n",
    "seaborn.heatmap(xxss, cmap=cmap,vmin = 0,vmax = 0.35,\n",
    "            linewidths=.0001, cbar_kws={\"shrink\": 0.6},xticklabels=10,yticklabels=10)\n",
    "\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_ylabel('log(N)/log(d)',fontsize=20, color='k')\n",
    "\n",
    "ax.set_xlabel('log(Nd)/log(d)',fontsize=20, color='k')\n",
    "\n",
    "plt.title('test error', fontsize = 24,color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "583ffe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.heatmap(xxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3720141",
   "metadata": {},
   "outputs": [],
   "source": [
    "?ax.xaxis.set_major_locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7dbaceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40,60):\n",
    "    for j in range(40):\n",
    "        if result_testerror[i][j]>0.15:\n",
    "            result_testerror[i][j] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "838a7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13,40):\n",
    "    for j in range(40):\n",
    "        if j< i-13:\n",
    "            if result_testerror[i][j]>0.15:\n",
    "                result_testerror[i][j] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d741f939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_testerror[:,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd9d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd: 21, N: 444,trainingerror: 0.430390, testerror: 0.164855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_trainingerror2 = np.zeros((200,1))\n",
    "result_testerror2 = np.zeros((200,1))    \n",
    "n_list = [444]\n",
    "for i in range(60,240):\n",
    "    x_id = i /20\n",
    "    for j in range(1):\n",
    "        \n",
    "        N = n_list[j]\n",
    "        Nd = int(np.ceil(np.e**(x_id)))\n",
    "        \n",
    "        for nrepitition in range(nrep):\n",
    "            x = getRandomSamplesOnNSphere(d,N)\n",
    "            y = generate_y(x,beta)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,shuffle = True)\n",
    "            x_train = torch.FloatTensor(x_train)\n",
    "            x_test = torch.FloatTensor(x_test)\n",
    "            y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "            y_test = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "\n",
    "            train_dataset = dataset(x_train, y_train)\n",
    "            test_dataset = dataset(x_test, y_test)\n",
    "            train_dataloader = DataLoader(dataset= train_dataset, \n",
    "                                        batch_size = len(x_train), \n",
    "                                        shuffle= True, \n",
    "                                        drop_last= False)\n",
    "            test_dataloader = DataLoader(dataset= test_dataset, \n",
    "                                        batch_size = len(x_test), \n",
    "                                        shuffle= True, \n",
    "                                        drop_last= False)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            lr = 0.01\n",
    "\n",
    "            device = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n",
    "            model = Model_1(input_dim= d, Nd = Nd,drop_rate= 0.0).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr)\n",
    "            LOSS = 0\n",
    "            LOSS2 = 0\n",
    "            model.train()\n",
    "            \n",
    "            for epoch in range(500):\n",
    "\n",
    "                for index, (x, y) in enumerate(train_dataloader):\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.to(device)\n",
    "                        y = y.to(device)\n",
    "                    y_pred = model(x)\n",
    "                    loss = criterion(y_pred,y)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            #         for p in model.parameters():\n",
    "            #             # print(p.grad.norm())                 \n",
    "            #             torch.nn.utils.clip_grad_norm_(p, 10)  \n",
    "            #         optimizer.step()\n",
    "            LOSS += loss\n",
    "            model.eval()\n",
    "            loss2 = criterion(model(x_test), y_test)\n",
    "            \n",
    "            LOSS2 += loss2\n",
    "            \n",
    "        training_error = LOSS /nrep\n",
    "        test_error = LOSS2 /nrep\n",
    "        \n",
    "        result_trainingerror2[i-40][j] = training_error\n",
    "        result_testerror2[i-40][j] = test_error\n",
    "        \n",
    "        print('Nd: %d, N: %d,trainingerror: %f, testerror: %f'%(Nd,N, training_error, test_error))\n",
    "        \n",
    "    np.save('./result1/trainingerror2.npy',result_trainingerror2)\n",
    "    np.save('./result1/testerror2.npy',result_testerror2)    \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "04958518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "087c0b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.55249753e-03, 1.44158979e-03, 7.52650797e-02, ...,\n",
       "        8.16754401e-02, 8.37643072e-02, 7.15659857e-02],\n",
       "       [6.35459274e-02, 2.04691030e-02, 1.36507645e-01, ...,\n",
       "        5.32738343e-02, 1.04697391e-01, 1.04651690e-01],\n",
       "       [3.37138842e-03, 1.32026123e-02, 1.73560716e-02, ...,\n",
       "        7.87840188e-02, 6.46702275e-02, 6.29779771e-02],\n",
       "       ...,\n",
       "       [9.02083339e-17, 9.34924659e-17, 1.35605819e-16, ...,\n",
       "        3.65336746e-06, 1.14787954e-05, 1.02914637e-04],\n",
       "       [5.55111521e-18, 7.01193478e-18, 8.57118595e-17, ...,\n",
       "        1.64825164e-04, 6.69850215e-06, 1.39008029e-04],\n",
       "       [6.66188038e-17, 2.62947565e-18, 7.11071388e-17, ...,\n",
       "        1.80096031e-04, 2.29380257e-05, 3.14147357e-04]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./result/trainingerror2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d5bd6a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b096a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
